{
	"nodes":[
		{"id":"2533fe92317ddba1","type":"group","x":3360,"y":-720,"width":5440,"height":2867,"label":"Jak wykonać narzedzie  Failure-Driven"},
		{"id":"84dac183e176d275","type":"group","x":1854,"y":-2880,"width":2866,"height":2000,"label":"Grupa bez nazwy"},
		{"id":"b8f217c826c8eb87","type":"group","x":0,"y":-720,"width":3360,"height":1266,"label":"Szablon: Definition of Ready i Definition of Ready"},
		{"id":"96c48e47a0e54a34","type":"group","x":54,"y":660,"width":1374,"height":1789,"label":"Satelitarne artefakty dokumentacyjne "},
		{"id":"01115cb6b10abb1b","type":"group","x":362,"y":-2182,"width":1318,"height":1202,"label":"Grupa bez nazwy"},
		{"id":"b5fcb36dbe13bf74","type":"group","x":-1280,"y":-720,"width":1198,"height":1264,"label":"Szablony Todo"},
		{"id":"27486be834123d58","type":"group","x":1520,"y":660,"width":760,"height":1340,"label":"Grupa bez nazwy"},
		{"id":"f49b421deb7d436b","type":"group","x":2500,"y":660,"width":740,"height":1340,"label":"Grupa bez nazwy"},
		{"id":"9813b092802f3f63","type":"text","text":"---\nid: \"TODO-<DOC>-NNN\"\ntitle: \"<Krótki tytuł zadania>\"\ndocument: \"<Nazwa dokumentu>\"\nowner: \"<Imię Nazwisko / zespół>\"\npriority: \"P0\" # P0 (krytyczne) | P1 (wysokie) | P2 (średnie) | P3 (niska)\neffort_days: 2    # estymacja w dniach roboczych\nstatus: \"todo\"    # todo | in-progress | review | done | blocked\ncreated: \"YYYY-MM-DD\"\ndue: \"YYYY-MM-DD\"\ndependencies:\n  - \"TODO-<DOC>-012\"\nrelated_docs:\n  - \"PRD.md\"\n  - \"TDD.md\"\ntags:\n  - \"dokumentacja\"\n  - \"przedprodukcyjne\"\n---\n\n# TODO: {{ title }}\n\n## Opis\nKrótki, jasny opis zadania — co trzeba zrobić, jaki efekt końcowy.\n\n## Cel / wartość biznesowa\nDlaczego zadanie jest potrzebne (inwestor/zgodność/ryzyko).\n\n## Kryteria akceptacji\n- [ ] Kryterium 1 (konkretne, mierzalne)\n- [ ] Kryterium 2 (np. zatwierdzone przez X)\n- [ ] Dokument gotowy w formacie .md i opublikowany w `docs/<client>/`\n\n## Kroki / checklist\n1. Zebrać dane wejściowe (lista źródeł)\n2. Wstępna wersja (draft)\n3. Review techniczny / prawny\n4. Finalizacja i sign-off (podpis elektroniczny)\n5. Publikacja i wersjonowanie\n\n## Notatki\nDowolne dodatkowe informacje, linki do materiałów, osoby do kontaktu.\n","x":-1262,"y":-706,"width":360,"height":354},
		{"id":"e7925a5b0aee050a","type":"text","text":"---\nid: \"TODO-EXSUM-001\"\ntitle: \"Przygotowanie Executive Summary dla klienta X\"\ndocument: \"Executive_Summary.md\"\nowner: \"Jan Kowalski\"\npriority: \"P0\"\neffort_days: 1\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2025-12-26\"\ndependencies: []\nrelated_docs:\n  - \"Business_Case.md\"\n  - \"Pitch_Deck.md\"\ntags:\n  - \"pitch\"\n  - \"inwestor\"\n---\n\n# TODO: Przygotowanie Executive Summary dla klienta X\n\n## Opis\nSkomponować 1-2 stronicowy Executive Summary do aplikacji o grant/inwestora: problem, rozwiązanie, rynek, model biznesowy, potrzeba finansowania.\n\n## Cel / wartość biznesowa\nSzybkie narzędzie sprzedażowe dla rozmów z inwestorami — kluczowy dokument aplikacyjny.\n\n## Kryteria akceptacji\n- [ ] Draft zaakceptowany przez Product Ownera.\n- [ ] Zawiera kluczowe liczby z Business Case.\n- [ ] Finalny plik w `docs/clientX/Executive_Summary.md` z front-matter.\n\n## Kroki / checklist\n1. Pobranie Business Case i Financial Plan.\n2. Skonstruowanie wersji A (max 1 strona).\n3. Review z CEO/PO.\n4. Finalizacja i zapis wersji `v1.0.0`.\n\n## Notatki\nZałącznik: skrócony wykres przychodów (png).\n","x":-862,"y":-706,"width":360,"height":354},
		{"id":"90ed1fa384bc7868","type":"text","text":"---\nid: \"TODO-TDD-001\"\ntitle: \"Przygotowanie TDD dla modułu auth\"\ndocument: \"TDD.md\"\nowner: \"Lead Architect\"\npriority: \"P0\"\neffort_days: 5\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2026-01-07\"\ndependencies:\n  - \"TODO-PRD-001\"\nrelated_docs:\n  - \"PRD.md\"\n  - \"Security_Plan.md\"\ntags:\n  - \"architecture\"\n  - \"security\"\n---\n\n# TODO: Przygotowanie TDD dla modułu auth\n\n## Opis\nSzczegółowy projekt techniczny modułu uwierzytelniania (architektura, API, przepływy, schemat DB, wymagania skalowalnościowe).\n\n## Cel / wartość biznesowa\nDostarcza deweloperom jednoznaczne specyfikacje implementacyjne; podstawowy dowód do code review.\n\n## Kryteria akceptacji\n- [ ] Diagramy architektury (component + sequence).\n- [ ] Schemat bazy danych i migracje opisane.\n- [ ] Specyfikacja API z przykładami request/response.\n- [ ] Review i akcept przez Lead Dev i Security Lead.\n\n## Kroki / checklist\n1. Analiza PRD → zidentyfikować wymagania techniczne.\n2. Przygotować diagramy i specyfikacje.\n3. Konsultacja z DevOps (CI/CD, infra).\n4. Review + finalizacja.\n\n## Notatki\nDołączyć przykładowe payloady i testy integracyjne.\n","x":-1262,"y":-296,"width":360,"height":354},
		{"id":"e40fc9c22156de6c","type":"text","text":"---\nid: \"TODO-SEC-001\"\ntitle: \"Sporządzenie Security Plan (wymagania i kontrola)\"\ndocument: \"Security_Plan.md\"\nowner: \"Security Lead\"\npriority: \"P0\"\neffort_days: 5\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2026-01-08\"\ndependencies:\n  - \"TODO-TDD-001\"\nrelated_docs:\n  - \"DPIA.md\"\n  - \"SIRP.md\"\ntags:\n  - \"security\"\n  - \"compliance\"\n---\n\n# TODO: Sporządzenie Security Plan\n\n## Opis\nOkreślić polityki bezpieczeństwa, mechanizmy kontroli, audyty i procedury reagowania.\n\n## Kryteria akceptacji\n- [ ] Lista kontrol (baseline) zgodna z ISO27001/rodo (jeśli wymagane).\n- [ ] Plan audytów + harmonogram.\n- [ ] Zatwierdzenie przez Security Officer.\n\n## Kroki / checklist\n1. Mapowanie danych i punktów ryzyka.\n2. Definicja kontroli dostępu i szyfrowania.\n3. Przygotowanie procedur SIRP i DRP.\n4. Review compliance przez DPO.\n\n## Notatki\nPowiązane z wymaganiami prawnymi klienta.\n","x":-1262,"y":104,"width":360,"height":354},
		{"id":"2c66a81f870fcd1e","type":"text","text":"\n\n\n---\n\n## A. Dokumenty przedprodukcyjne\n\n| **Nazwa dokumentu**                      | **Zawiera**                                                    | **Czego nie zawiera**           | **Strony (suger.)** | **Punkty (suger.)** | **Kategoria**                |\n| ---------------------------------------- | -------------------------------------------------------------- | ------------------------------- | ------------------- | ------------------- | ---------------------------- |\n| Executive Summary                        | Skrót projektu, problem, rozwiązanie, wezwanie do działania    | Detali technicznych, backlogów  | 1–2                 | 5–7                 | Wymagane (przedprod.)        |\n| Business Case                            | ROI, korzyści, alternatywy, NPV/ROI, scenariusze               | Szczegółowych planów kodowania  | 3–6                 | 8–12                | Wymagane (przedprod.)        |\n| Pitch Deck                               | Kluczowe slajdy: problem, rozwiązanie, model, zespół, finansy  | Architektury systemu, kodu      | 10–15 slajdów       | ~1 slajd / punkt    | Wymagane (przedprod.)        |\n| Market Analysis                          | Wielkość rynku, trendy, konkurencja, TAM/SAM/SOM               | Kodu, surowych formuł           | 5–8                 | 6–10                | Wymagane (przedprod.)        |\n| Financial Plan / Projections             | Budżet, projekcje przychodów/kosztów, scenariusze              | Planów technicznych             | 3–6                 | 6–10                | Wymagane (przedprod.)        |\n| Feasibility Study                        | Ocena wykonalności technicznej i ekonomicznej, rekomendacje    | Detali sprintów                 | 4–8                 | 8–12                | Wymagane (przedprod.)        |\n| Stakeholder Map                          | Interesariusze, wpływ/zaangażowanie, matryca interesów         | Szczegółowych ocen personalnych | 1–2                 | 5–8                 | Przydatne (przedprod.)       |\n| Go‑To‑Market Strategy                    | Kanały, pricing, partnerstwa, plan wejścia na rynek            | Specyfikacji kodu               | 4–6                 | 8–10                | Przydatne (przedprod.)       |\n| Research Plan                            | Pytania badawcze, metodologia, harmonogram                     | Implementacji kodu, backlogów   | 3–5                 | 6–10                | Przydatne (przedprod.)       |\n| Vision Document (Extended)               | Wizja 2–3 lata, kierunki rozwoju, scenariusze strategiczne     | Szczegółowych planów sprintów   | 4–6                 | 7–10                | Nice‑to‑Have (przedprod.)    |\n| Impact Assessment                        | Wpływ społeczny, regulacyjny, środowiskowy                     | Detali finansowych              | 2–4                 | 5–7                 | Nice‑to‑Have (przedprod.)    |\n| Innovation Roadmap                       | Kierunki R&D, eksperymenty, kamienie milowe                    | Kodów źródłowych                | 2–4                 | 5–8                 | Nice‑to‑Have (przedprod.)    |\n| Funding Application Budget Justification | Szczegółowe rozbicie kosztów dla grantów                       | Szerszych analiz rynkowych      | 2–6                 | 6–10                | Wymagane (granty)            |\n| Letters of Support / Partner Commitments | Listy intencyjne, zobowiązania partnerów                       | Pełnych kontraktów              | 1–3                 | 3–6                 | Wymagane (granty/inwestorzy) |\n| Cap Table / Valuation Memo               | Struktura udziałów, scenariusze rozwodnienia, założenia wyceny | Szczegółowych planów produktu   | 1–4                 | 4–8                 | Przydatne (inwestorzy)       |\n\n---\n\n## B. Dokumenty produkcyjne / inżynierskie\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Product Requirements Document (PRD)|Funkcje, user stories, acceptance criteria, priorytety, kontekst biznesowy|Luźnych pomysłów|8–20|20–40|Wymagane (prod.)|\n|Basic Requirements Document (BRD)|Minimalne wymagania funkcjonalne i niefunkcjonalne, zakres MVP|Nadmiarowych detali|5–8|10–18|Wymagane (prod.)|\n|High‑Level Architecture (HLA)|Schemat systemu, moduły, integracje, zależności|Kod źródłowy|3–6|6–10|Wymagane (prod.)|\n|Technical Design Document (TDD)|Moduły, klasy, API, sekwencje, diagramy, migracje|Strategii sprzedaży|10–30|25–50|Wymagane (prod.)|\n|Architecture Decision Records (ADR)|Decyzje architektoniczne, kontekst, trade‑offs, konsekwencje|Długie opisy implementacji (kod)|1–3 / entry|3–6 / entry|Ciągłe (prod.)|\n|Test Plan / QA Strategy|Typy testów, scenariusze, środowiska, kryteria akceptacji|Raportów finansowych|5–10|10–20|Wymagane (prod.)|\n|Requirements Traceability Matrix (RTM)|Mapowanie wymagań → testy → user stories → implementacja|Kodu implementacji|1–3|10–20|Przydatne (prod.)|\n|Runbook / Operations Manual|Procedury uruchomienia, CI/CD, playbooks, runbooks dla SRE|Slajdów inwestorskich|5–15|15–30|Przydatne (prod./ops)|\n|Release Management Plan|Kryteria release, rollback, cutover plan, harmonogram|Strategii biznesowych|2–6|6–12|Przydatne (prod.)|\n|UAT Plan|Scenariusze akceptacyjne, testy end‑to‑end, kryteria sukcesu|Raportów technicznych niepowiązanych z akceptacją|2–6|6–12|Przydatne (prod.)|\n|Migration Plan|Plan migracji danych/systemów, rollback, walidacja danych|Materiałów marketingowych|2–6|6–10|Przydatne (prod.)|\n|Integration Plan|Schematy integracji, kontrakty API, SLA integracyjne|Treści marketingowe|2–6|6–12|Przydatne (prod.)|\n|API Documentation (machine‑readable)|Endpoints, request/response, auth, przykłady, wersjonowanie|Strategii sprzedaży|3–20|8–30|Wymagane / Przydatne (prod.)|\n|Performance Test Report|Wyniki obciążeniowe, bottlenecks, rekomendacje, wykresy|Raportów finansowych|3–8|8–16|Przydatne (prod.)|\n|Monitoring & Observability Plan|Metryki, alerty, SLO/SLI, dashboardy, metryki business|Treści marketingowe|2–6|6–12|Przydatne (ops.)|\n|SIRP / Security Incident Response Plan|Procedury reagowania, komunikacja, role, eskalacje|Surowych danych analitycznych (bez podsumowania)|3–8|8–14|Wymagane / Przydatne (ops./security)|\n|DRP / BCP|Disaster recovery, RTO/RPO, procedury awaryjne, checklists|Planów rozwoju produktu|3–8|8–16|Wymagane (ops.)|\n|SLA / Service Catalog|Oferta usług, poziomy usług, KPI, odpowiedzialności|Kodów źródłowych|1–4|4–10|Przydatne (ops./biz)|\n\n---\n\n## C. Compliance, bezpieczeństwo i zarządzanie danymi\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Data Management Plan|Schematy danych, retencja, lineage, polityki backupowe|Szczegółów implementacji kodu|2–6|6–12|Wymagane / Przydatne (data)|\n|Data Governance Policy|Role, klasyfikacja danych, polityki dostępu, właściciele danych|Szczegółów kodu|2–6|6–10|Przydatne (governance)|\n|DPIA (Data Privacy Impact Assessment)|Mapy przepływu danych, ocena ryzyka PII/PHI, rekomendacje|Materiałów marketingowych|3–6|6–10|Wymagane (compliance)|\n|HIPAA Compliance Report|Polityki PHI, audyty, procedury breach, kontrola dostępu|Szczegółowych implementacji kodu|3–8|6–12|Wymagane (medycyna, US)|\n|PCI DSS Compliance Report|Audyty płatności, szyfrowanie, testy penetracyjne, konfiguracje|Planów sprzedaży|5–12|8–16|Wymagane (fintech)|\n|SOX Compliance Report|Kontrole wewnętrzne, raporty finansowe, procedury audytu|Kodu aplikacji|3–8|6–12|Wymagane (finanse/korpo)|\n|Third‑Party Risk Assessment / SSQ|Ocena dostawców, kontrola bezpieczeństwa, wymagania SLA|Pełnych kontraktów|2–6|6–12|Wymagane (compliance)|\n|Breach Notification Procedure|Kroki notyfikacji, timeline, komunikacja z regulatorami/klientami|Strategii marketingowych|1–4|4–8|Wymagane (security/compliance)|\n|Secrets Inventory & Key Rotation Plan|Lista sekretów, harmonogram rotacji, właściciele|Kodów źródłowych (sekrety nie przechowywać w repo)|1–3|4–6|Przydatne (security)|\n|Supplier Qualification Pack / Audit Report|Wyniki audytów dostawców, rekomendacje, oceny ryzyka|Planów produktowych|3–8|6–12|Wymagane (hardware/medical)|\n\n---\n\n## D. ML / Research / Reproducibility\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Computational Environment Spec / Repro Pack|Specyfikacja środowiska (Docker/Conda), seed data, instrukcje uruchomienia|Materiałów marketingowych|1–4|4–8|Wymagane (R&D)|\n|Model Risk Assessment / Model Governance Policy|Polityki retrainingu, walidacja modelu, monitorowanie driftu|Szczegółów planów sprzedaży|2–6|6–12|Wymagane (AI‑critical)|\n|Data Lineage & Provenance Diagrams|Źródła danych, transformacje, właściciele danych|Kodów implementacji|1–4|4–8|Przydatne (data/compliance)|\n|Experimentation Plan / Feature Flag Strategy|Hipotezy, metryki sukcesu, rollback, flagi funkcji|Pełnej implementacji|2–4|4–8|Przydatne (product/ops)|\n|Test Data Management Plan|Anonimizacja, provisioning, seedy testowe, polityki|Materiałów marketingowych|2–4|4–8|Wymagane (QA/integration)|\n\n---\n\n## E. Ops / DevOps / SRE\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Cutover / Go‑Live Checklist (detailed)|Krok po kroku cutover, testy rollback, checklists pre/post|Materiałów marketingowych|1–3|6–12|Wymagane (release)|\n|Service Decommission / Sunsetting Plan|Plan zamknięcia usługi, migracje danych, komunikacja klientom|Strategii sprzedażowych|1–4|4–8|Przydatne (ops)|\n|Healthcheck / Readiness Endpoints Spec|Specyfikacja endpointów health/readiness, formaty odpowiedzi, polityki|Materiałów marketingowych|1–2|2–4|Przydatne (dev/sre)|\n|Cost Optimisation / Cloud Run‑rate Plan|Prognoza kosztów, optymalizacje, rekomendacje oszczędności|Planów produktowych|2–4|4–8|Przydatne (ops/fin)|\n|Secrets Inventory (powtórzone)|Rejestr sekretów i powiązane procesy|-|1–3|4–6|Przydatne (security)|\n\n---\n\n## F. Legal / Regulatory / Grants\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Grant Narrative / Project Description (długi)|Rozbudowany opis projektu wymagany w aplikacjach grantowych|Krótkich streszczeń|5–20|10–30|Wymagane (granty)|\n|Funding Application Budget Justification|Szczegółowe uzasadnienie kosztów dla grantów|Ogólnych kalkulacji|2–6|6–10|Wymagane (granty)|\n|Regulatory Submission Dossier (FDA/MDR)|Pełna dokumentacja do zgłoszeń regulatorowych, raporty z badań, dane kliniczne|Planów marketingowych|20–200+|50+|Wymagane (medycyna)|\n|Pharmacovigilance Plan / SAE Handling Guide|Procedury zgłaszania zdarzeń niepożądanych, eskalacje|Strategii sprzedaży|5–15|10–20|Wymagane (klinika/medycyna)|\n\n---\n\n## G. UX / Marketing / Localization\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Localization / Translation Glossary & Style Guide|Terminologia, ton, słownictwo, przykłady tłumaczeń|Kodów implementacji|1–3|3–6|Nice‑to‑Have (global)|\n|Case Study / Customer Reference Template|Struktura studium przypadku, metryki, wyniki|Danych wrażliwych|1–3|3–6|Nice‑to‑Have (marketing)|\n|VPAT / Accessibility Statement|Wyniki testów dostępności, zgodność z WCAG, rekomendacje|Kodów źródłowych|2–6|4–10|Przydatne (compliance)|\n\n---\n\n## H. Inne / organizacyjne / drobne\n\n|   |   |   |   |   |   |\n|---|---|---|---|---|---|\n|**Nazwa dokumentu**|**Zawiera**|**Czego nie zawiera**|**Strony (suger.)**|**Punkty (suger.)**|**Kategoria**|\n|Records Retention Schedule / Retention Policy|Zasady retencji dokumentów/danych, RTO/RPO, okresy przechowywania|Szczegółów technicznych|1–4|4–8|Przydatne (governance)|\n|Meeting Agendas + Action Item Tracker (template)|Szablony spotkań, lista zadań, przypisania odpowiedzialności|Treści techniczne|1–2|2–4|Nice‑to‑Have (org)|\n|Feature Decision Log / Change Impact Analysis|Decyzje funkcjonalne, wpływ zmian, analiza wpływu|Implementacji kodu|1–3|3–6|Przydatne (product)|\n|API Catalogue / Endpoint Inventory (machine‑readable)|Lista endpointów, właściciele, wersje, statusy|Treści marketingowe|1–5|5–12|Przydatne (integracje)|\n\n---\n\n**Uwaga:** wartości „Strony” i „Punkty” są orientacyjne i zależą od złożoności projektu. Tabela służy jako mapa referencyjna do generowania checklist, TODO i szablonów dokumentów.\n","x":-1280,"y":620,"width":1198,"height":1860},
		{"id":"d58d5b72f5d48bf8","type":"text","text":"---\nid: \"TODO-FEAS-001\"\ntitle: \"Studium wykonalności techniczno-ekonomiczne\"\ndocument: \"Feasibility_Study.md\"\nowner: \"Technical Lead\"\npriority: \"P1\"\neffort_days: 4\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2025-12-30\"\ndependencies:\n  - \"TODO-RESEARCH-001\"\nrelated_docs:\n  - \"Research_Plan.md\"\n  - \"Business_Case.md\"\ntags:\n  - \"feasibility\"\n---\n\n# TODO: Studium wykonalności techniczno-ekonomiczne\n\n## Opis\nOcenić wykonalność technologii, koszty wdrożenia, ryzyka techniczne i rekomendacje.\n\n## Kryteria akceptacji\n- [ ] Analiza kosztów TCO (pierwotne + operacyjne).\n- [ ] Ocena ryzyk technicznych i rekomendowane mitigacje.\n- [ ] Rekomendacja: proceed / pilot / reject.\n\n## Kroki / checklist\n1. Zbadać dostępne technologie i koszty licencji.\n2. Oszacować zasoby (ludzie, infra).\n3. Sporządzić raport i przesłać do CFO+CTO.\n\n## Notatki\nWynik wpływa bezpośrednio na decyzję Go/No-Go.\n","x":-862,"y":-296,"width":360,"height":354},
		{"id":"8e240b4c021934cd","type":"text","text":"---\nid: \"TODO-HIPAA-001\"\ntitle: \"Przygotowanie HIPAA Compliance Report (US healthcare client)\"\ndocument: \"HIPAA_Compliance_Report.md\"\nowner: \"Compliance Lead\"\npriority: \"P0\"\neffort_days: 6\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2026-01-12\"\ndependencies:\n  - \"TODO-DPIA-001\"\nrelated_docs:\n  - \"Security_Plan.md\"\ntags:\n  - \"hipaa\"\n  - \"healthcare\"\n---\n\n# TODO: Przygotowanie HIPAA Compliance Report\n\n## Opis\nSkompletować dokumentację i polityki zapewniające zgodność z HIPAA: PHI handling, breach reporting, audit trails.\n\n## Kryteria akceptacji\n- [ ] Polityki PHI zaimplementowane i opisane.\n- [ ] Wyniki audytu kontrolnego z remediation plan.\n- [ ] Zatwierdzenie przez Compliance Officer.\n\n## Kroki / checklist\n1. Zidentyfikować PHI i procesy.\n2. Opracować procedury kontroli dostępu i logowania.\n3. Przeprowadzić audyt wstępny.\n4. Opracować plan naprawczy (remediation).\n\n## Notatki\nDotyczy tylko klientów działających na rynku USA (HIPAA).\n","x":-467,"y":104,"width":360,"height":354},
		{"id":"04942188afb9b765","type":"text","text":"---\nid: \"TODO-DPIA-001\"\ntitle: \"Wykonanie DPIA\"\ndocument: \"DPIA.md\"\nowner: \"DPO\"\npriority: \"P0\"\neffort_days: 3\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2025-12-31\"\ndependencies:\n  - \"TODO-PRD-001\"\nrelated_docs:\n  - \"GDPR.md\"\ntags:\n  - \"privacy\"\n  - \"compliance\"\n---\n\n# TODO: Wykonanie DPIA\n\n## Opis\nOcena wpływu na prywatność, identyfikacja PHI/PII, oraz rekomendacja kroków aby zminimalizować ryzyko.\n\n## Kryteria akceptacji\n- [ ] Zidentyfikowane kategorie danych osobowych.\n- [ ] Ocena ryzyka (wysokie/śr/niskie) i zalecenia mitigacji.\n- [ ] Zatwierdzenie przez DPO.\n\n## Kroki / checklist\n1. Zmapować przepływy danych.\n2. Określić cele przetwarzania.\n3. Ocenić ryzyka i zaproponować środki.\n4. Dokument i podpis DPO.\n\n## Notatki\nWymagane przed CHECKPOINT: REQUIREMENTS FREEZE.\n","x":-862,"y":104,"width":360,"height":354},
		{"id":"8966651623160858","type":"text","text":"---\nid: \"TODO-PRD-001\"\ntitle: \"Sporządzenie PRD - MVP klienta X\"\ndocument: \"PRD.md\"\nowner: \"Product Owner\"\npriority: \"P0\"\neffort_days: 7\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2026-01-05\"\ndependencies:\n  - \"TODO-EXSUM-001\"\nrelated_docs:\n  - \"Business_Case.md\"\n  - \"TDD.md\"\n  - \"RTM.md\"\ntags:\n  - \"requirements\"\n  - \"mvp\"\n---\n\n# TODO: Sporządzenie PRD - MVP klienta X\n\n## Opis\nSporządzić pełne PRD dla MVP: user stories, wymagania niefunkcjonalne, integracje, acceptance criteria, roadmapa.\n\n## Cel / wartość biznesowa\nUmożliwia zespołowi deweloperskiemu wykonanie pracy zgodnie z oczekiwaniami klienta i spełnienie kryteriów inwestora.\n\n## Kryteria akceptacji\n- [ ] Minimum 10 user stories z AC.\n- [ ] RTM zmapowany dla wszystkich krytycznych wymagań.\n- [ ] PRD zatwierdzony przez Product Ownera i Stakeholderów.\n\n## Kroki / checklist\n1. Workshop z klientem -> zebrać wymagania.\n2. Napisać user stories + AC.\n3. Sprawdzić dependencies (integracje).\n4. Internal review (architekt + QA).\n5. Final sign-off.\n\n## Notatki\nUżyć PRD template z `templates/produkcyjne/PRD.md`.\n","x":-467,"y":-706,"width":360,"height":354},
		{"id":"ddf4229549e0c596","type":"text","text":"---\nid: \"TODO-BUSCASE-001\"\ntitle: \"Przygotowanie Business Case dla projektu X\"\ndocument: \"Business_Case.md\"\nowner: \"CFO (w kooperacji z BizDev)\"\npriority: \"P0\"\neffort_days: 4\nstatus: \"todo\"\ncreated: \"2025-12-22\"\ndue: \"2026-01-04\"\ndependencies:\n  - \"TODO-FEAS-001\"\nrelated_docs:\n  - \"Financial_Plan.md\"\ntags:\n  - \"bizcase\"\n---\n\n# TODO: Przygotowanie Business Case dla projektu X\n\n## Opis\nSkompilować analizy finansowe, projekcje przychodów i uzasadnienie inwestycyjne.\n\n## Kryteria akceptacji\n- [ ] Modele finansowe (3 scenariusze).\n- [ ] NPV / ROI policzone i udokumentowane.\n- [ ] Dokument zatwierdzony przez CFO.\n\n## Kroki / checklist\n1. Zbierać dane rynkowe.\n2. Wprowadzić założenia finansowe.\n3. Wykonać analizy scenariuszowe.\n4. Prezentacja dla zarządu.\n\n## Notatki\nPotrzebny dostęp do danych rynkowych (market research).\n","x":-467,"y":-296,"width":360,"height":354},
		{"id":"2cdf041ee521e568","type":"text","text":"**Sprint** to krótki, stały odcinek czasu (najczęściej 1–2 tygodnie), w którym zespół **dostarcza uzgodniony, domknięty zestaw rezultatów** (przyrost produktu/dokumentacji). To jednostka planowania i kontroli pracy w Scrumie.\n\n## Co sprint zawiera (w dojrzałym podejściu)\n\n1. **Sprint Goal** – jeden cel nadrzędny (dlaczego ten sprint istnieje).\n    \n2. **Sprint Backlog** – lista zadań/TODO, które realizują cel sprintu.\n    \n3. **Definition of Ready (DoR)** – kryteria, kiedy zadania mogą wejść do sprintu.\n    \n4. **Definition of Done (DoD)** – kryteria, kiedy zadania można uznać za ukończone.\n    \n5. **Review / Demo** – pokaz wyniku (co dowieźliśmy).\n    \n6. **Retrospective** – wnioski i poprawki procesu.\n    \n\n## Czy sprint ma „satelity” tak jak dokumenty?\n\nTak — sprint jako „pakiet pracy” ma własne artefakty satelitarne. Minimalny, profesjonalny zestaw:\n\n- **Sprint Plan** (krótki opis planu i zakresu)\n    \n- **Sprint Backlog** (TODO/issue + estymacje)\n    \n- **DoR (Sprint-level)** – co musi być gotowe, aby task/story weszło do sprintu\n    \n- **DoD (Sprint-level)** – co znaczy, że sprint deliverable jest „done”\n    \n- **Sprint Review Notes** (co pokazano, decyzje, akceptacje)\n    \n- **Retrospective Notes + Action Items** (TODO na usprawnienia)\n    \n- **Burndown/Burnup snapshot** (opcjonalnie)\n    \n- **Changelog/Release Notes entry** (jeśli sprint kończy się releasem)\n    \n\n## Jak sprint łączy się z dokumentacją (Twoje use-case: dokumenty dla klientów)\n\nSprint może dowozić **konkretne fragmenty dokumentacji** jako przyrost, np.:\n\n- Sprint 1: Executive Summary + Market Analysis draft + Evidence pack\n    \n- Sprint 2: Business Case + Financial Plan v1 + Letters of Support checklist\n    \n- Sprint 3: PRD + RTM szkic + DoR/DoD dla implementacji  \n    Każdy dokument ma swoje TODO per sekcja, a sprint wybiera z nich podzbiór.\n    \n\n## Typowa kolejność pracy w sprincie (flow)\n\n1. **Grooming**: wybór zadań spełniających DoR\n    \n2. **Planowanie**: Sprint Goal + zakres + ownerzy\n    \n3. **Wykonanie**: TODO → drafty → review → poprawki\n    \n4. **Domknięcie**: DoD spełnione + Approval/sign-off (jeśli wymagane)\n    \n5. **Review/Retro**: decyzje + action items na kolejny sprint\n    \n\nJeśli chcesz, dodam do Twoich szablonów jeszcze komplet:\n\n- `templates/sprints/sprint_plan.md`, `templates/sprints/sprint_backlog.md`, `templates/sprints/sprint_review.md`, `templates/sprints/sprint_retro.md`, plus `DoR/DoD sprint-level` w tym samym stylu co reszta.","x":2075,"y":-2720,"width":645,"height":1740},
		{"id":"452e758daa00af82","type":"text","text":"Dla sprintu (w dojrzałym podejściu) warto mieć własny zestaw plików satelitarnych — dokładnie tak jak dla dokumentów.\n\n**Najważniejsze pliki satelitarne sprintu:**\n\n## Minimum (zawsze)\n\n- `sprint-plan.md` — cel sprintu, zakres, capacity, checkpointy.\n    \n- `sprint-backlog.md` — lista elementów z ownerami, estymacją, linkami do TODO/dokumentów.\n    \n- `sprint-review.md` — co dowieziono, co nie, feedback i decyzje.\n    \n- `sprint-retro.md` — retrospektywa.\n    \n- `sprint-action-items.md` — akcje z retro (owner/due/status).\n    \n\n## Standard (zalecane)\n\n- `sprint-dor.md` — Sprint DoR (kryteria wejścia dla elementów sprintu).\n    \n- `sprint-dod.md` — Sprint DoD (kryteria domknięcia sprintu).\n    \n- `sprint-impediments.md` — rejestr blokerów (live).\n    \n\n## Rozszerzony (duże/regulowane/release-heavy)\n\n- `sprint-scope-change.md` — Change Request na zmianę zakresu w trakcie sprintu.\n    \n- `sprint-metrics.md` — velocity, jakość, lead time, dokumenty dowiezione.\n    \n- `sprint-approval.md` — formalny sign-off sprintu (PO/Sponsor), gdy trzeba.\n    \n- `daily/` — dzienniki dzienne (opcjonalnie).\n    \n- `metrics/` — np. `burndown.csv`, `burnup.csv` (opcjonalnie).\n    \n\n## Struktura per sprint (instancja w projekcie)\n\n```\ndocs/<project>/sprints/SXX/\n  sprint-plan.md\n  sprint-backlog.md\n  sprint-dor.md\n  sprint-dod.md\n  sprint-impediments.md\n  sprint-review.md\n  sprint-retro.md\n  sprint-action-items.md\n  sprint-metrics.md\n  sprint-scope-change.md\n  approvals/sprint-approval.md\n  daily/ (opcjonalnie)\n  metrics/ (opcjonalnie)\n```\n\n✅ Utworzyłem dla Ciebie pełną kanwę z gotowymi szablonami `.md` do katalogu `templates/sprints/` (plan, backlog, DoR/DoD, impediments, review, retro, action items, metrics, scope change, approval):  \n**„Sprinty — pliki satelitarne i szablony (templates/sprints)”**.\n\nJeśli chcesz, dopnę to jeszcze do Twojego manifestu CSV/JSON (żeby dało się importować sprinty jak resztę artefaktów).","x":2520,"y":-2720,"width":680,"height":1700},
		{"id":"e4677d3896bf7e83","type":"text","text":"# Sprinty — pliki satelitarne i szablony (Markdown)\n\nTen dokument zawiera:\n\n1. **listę rekomendowanych plików satelitarnych sprintu** (minimum / standard / rozszerzony),\n    \n2. **gotowe szablony `.md`** do skopiowania do `templates/sprints/`,\n    \n3. sugerowaną strukturę `docs/<project>/sprints/SXX/`.\n    \n\n---\n\n## 1) Pliki satelitarne sprintu — rekomendowany zestaw\n\n### Minimum (zawsze, dla podejścia dojrzałego)\n\n- `sprint-plan.md` — cel sprintu, zakres, capacity, checkpointy.\n    \n- `sprint-backlog.md` — lista itemów z ownerami, estymacją i linkami do TODO/dokumentów.\n    \n- `sprint-review.md` — co dowieziono, co nie, feedback, decyzje.\n    \n- `sprint-retro.md` — wnioski procesowe.\n    \n- `sprint-action-items.md` — akcje z retro (owner, due, status).\n    \n\n### Standard (zalecane w większości projektów)\n\n- `sprint-dor.md` — Sprint DoR (kryteria wejścia dla itemów).\n    \n- `sprint-dod.md` — Sprint DoD (kryteria domknięcia).\n    \n- `sprint-impediments.md` — rejestr blokerów (live).\n    \n\n### Rozszerzony (dla większych / regulowanych / release‑heavy)\n\n- `sprint-scope-change.md` — Change Request dla zmian scope w trakcie sprintu.\n    \n- `sprint-metrics.md` — velocity, jakość, lead time, dokumentacja dowieziona.\n    \n- `sprint-approval.md` — formalny sign‑off (np. PO/Sponsor) jeśli sprint domyka etap.\n    \n- `daily/` — dzienniki dzienne (opcjonalne, gdy potrzebujesz audytu).\n    \n- `metrics/` — burndown/burnup w CSV.\n    \n\n---\n\n## 2) Rekomendowana struktura w repo (instancje sprintów)\n\n```\ndocs/<project>/sprints/SXX/\n  sprint-plan.md\n  sprint-backlog.md\n  sprint-dor.md\n  sprint-dod.md\n  sprint-impediments.md\n  sprint-review.md\n  sprint-retro.md\n  sprint-action-items.md\n  sprint-metrics.md\n  sprint-scope-change.md\n  approvals/sprint-approval.md\n  daily/ (opcjonalnie)\n  metrics/ (burndown.csv, burnup.csv)\n```\n\n---\n\n# 3) Szablony do `templates/sprints/`\n\n## `templates/sprints/sprint-plan.md`\n\n```markdown\n---\nid: \"SPRINT-PLAN-SXX\"\ntitle: \"Sprint Plan — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Scrum Master / Delivery Lead\"\nstatus: \"draft\"          # draft|in-review|approved|closed\nversion: \"0.1\"\ndate_created: \"YYYY-MM-DD\"\nperiod: \"YYYY-MM-DD..YYYY-MM-DD\"\nsprint_goal: \"\"\nrelated: [\"ROADMAP-PROD-001\",\"REL-CHECK-001\"]\n---\n\n# Sprint Plan — SXX\n\n## 1. Sprint Goal\n- Jedno zdanie: co ma zostać osiągnięte i dlaczego.\n\n## 2. Zakres (Scope)\n- In scope:\n  - ...\n- Out of scope:\n  - ...\n\n## 3. Capacity / dostępność\n- Zespół i dostępność (FTE, urlopy, ograniczenia).\n\n## 4. Backlog wybrany do sprintu\n- Patrz: `sprint-backlog.md`\n\n## 5. Zależności i ryzyka (top 3)\n- D1: ...\n- R1: ...\n\n## 6. Definicje\n- DoR sprint: `sprint-dor.md`\n- DoD sprint: `sprint-dod.md`\n\n## 7. Checkpointy\n- Mid-sprint check (YYYY-MM-DD)\n- Review (YYYY-MM-DD)\n- Retro (YYYY-MM-DD)\n\n## 8. Komunikacja\n- Kto dostaje update i kiedy (np. weekly stakeholder update).\n```\n\n---\n\n## `templates/sprints/sprint-backlog.md`\n\n```markdown\n---\nid: \"SPRINT-BACKLOG-SXX\"\ntitle: \"Sprint Backlog — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Scrum Master / Delivery Lead\"\nstatus: \"draft\"          # draft|in-review|approved|closed\nversion: \"0.1\"\nperiod: \"YYYY-MM-DD..YYYY-MM-DD\"\nrelated: [\"SPRINT-PLAN-SXX\"]\n---\n\n# Sprint Backlog — SXX\n\n| ID | Item | Owner | Estimate | Status | Related doc / TODO | Acceptance |\n|---|---|---|---:|---|---|---|\n| SXX-001 | ... | ... | 3 | todo | TODO-PRD-001 | AC link |\n\n## Notes\n- Do sprintu trafiają tylko itemy spełniające Sprint DoR.\n```\n\n---\n\n## `templates/sprints/sprint-dor.md`\n\n```markdown\n---\nid: \"SPRINT-DOR-SXX\"\ntitle: \"Sprint Definition of Ready — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Product Owner\"\nstatus: \"draft\"\nversion: \"0.1\"\nrelated: [\"SPRINT-PLAN-SXX\"]\n---\n\n# Sprint DoR — SXX\n\n## Kryteria wejścia dla itemów sprintu\n- [ ] Cel i opis zadania jasno zapisane\n- [ ] Acceptance Criteria dostępne\n- [ ] Estymacja wykonana\n- [ ] Owner przypisany\n- [ ] Zależności znane i zarejestrowane\n- [ ] Dostęp do danych/test env (lub plan)\n```\n\n---\n\n## `templates/sprints/sprint-dod.md`\n\n```markdown\n---\nid: \"SPRINT-DOD-SXX\"\ntitle: \"Sprint Definition of Done — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Team Lead / QA\"\nstatus: \"draft\"\nversion: \"0.1\"\nrelated: [\"SPRINT-PLAN-SXX\"]\n---\n\n# Sprint DoD — SXX\n\n## Kryteria wyjścia (zamknięcia sprintu)\n- [ ] Wszystkie P0/P1 itemy domknięte lub świadomie odłożone (z CR)\n- [ ] Review przeprowadzone, wyniki zapisane\n- [ ] Retro przeprowadzone, action items zapisane\n- [ ] Dokumentacja (jeśli dotyczy) zaktualizowana i zmergowana\n- [ ] Approval / sign-off (jeśli wymagane)\n```\n\n---\n\n## `templates/sprints/sprint-impediments.md`\n\n```markdown\n---\nid: \"SPRINT-IMP-SXX\"\ntitle: \"Impediments Log — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Scrum Master\"\nstatus: \"live\"\nrelated: [\"SPRINT-PLAN-SXX\"]\n---\n\n# Impediments Log — SXX\n\n| ID | Impediment | Since | Owner | Impact | Status | Next step |\n|---|---|---|---|---|---|---|\n| IMP-001 | ... | YYYY-MM-DD | ... | High | Open | ... |\n```\n\n---\n\n## `templates/sprints/sprint-review.md`\n\n```markdown\n---\nid: \"SPRINT-REVIEW-SXX\"\ntitle: \"Sprint Review — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Scrum Master\"\nstatus: \"draft\"\nrelated: [\"SPRINT-PLAN-SXX\",\"SPRINT-BACKLOG-SXX\"]\n---\n\n# Sprint Review — SXX\n\n## 1. Sprint Goal — status\n- Czy cel został osiągnięty? (tak/nie + komentarz)\n\n## 2. Delivered\n- Lista dowiezionych elementów (linki do PR, dokumentów, release notes)\n\n## 3. Not delivered / carry-over\n- Co nie weszło i dlaczego\n\n## 4. Feedback / decyzje\n- Ustalenia i decyzje stakeholderów\n\n## 5. Następne kroki\n- Link do action items\n```\n\n---\n\n## `templates/sprints/sprint-retro.md`\n\n```markdown\n---\nid: \"SPRINT-RETRO-SXX\"\ntitle: \"Sprint Retrospective — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Scrum Master\"\nstatus: \"draft\"\nrelated: [\"SPRINT-PLAN-SXX\"]\n---\n\n# Sprint Retrospective — SXX\n\n## Went well\n- ...\n\n## To improve\n- ...\n\n## Action items\n- AI-001 — owner — due\n- AI-002 — owner — due\n```\n\n---\n\n## `templates/sprints/sprint-action-items.md`\n\n```markdown\n---\nid: \"SPRINT-AI-SXX\"\ntitle: \"Action Items — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Scrum Master\"\nstatus: \"live\"\nrelated: [\"SPRINT-RETRO-SXX\"]\n---\n\n# Action Items — SXX\n\n| ID | Action | Owner | Due | Status |\n|---|---|---|---|---|\n| AI-001 | ... | ... | YYYY-MM-DD | Open |\n```\n\n---\n\n## `templates/sprints/sprint-scope-change.md`\n\n```markdown\n---\nid: \"SPRINT-CR-SXX-001\"\ntitle: \"Sprint Scope Change Request — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Product Owner\"\nstatus: \"draft\"          # draft|approved|rejected\nrelated: [\"SPRINT-PLAN-SXX\",\"SPRINT-BACKLOG-SXX\"]\n---\n\n# Sprint Scope Change Request — SXX\n\n## Zmiana\n- Co dodajemy/usuwamy i dlaczego.\n\n## Wpływ\n- Na cel sprintu:\n- Na terminy:\n- Na ryzyko:\n\n## Decyzja\n- Approved/Rejected\n- Approver: ...\n- Date: ...\n```\n\n---\n\n## `templates/sprints/sprint-metrics.md`\n\n```markdown\n---\nid: \"SPRINT-METRICS-SXX\"\ntitle: \"Sprint Metrics — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Product Ops\"\nstatus: \"draft\"\nrelated: [\"SPRINT-PLAN-SXX\"]\n---\n\n# Sprint Metrics — SXX\n\n## Delivery\n- Velocity: ...\n- Burnup/Burndown: link do plików w `metrics/`\n\n## Quality\n- Defects found: ...\n- Rework ratio: ...\n\n## Docs / Governance\n- Dokumenty zaktualizowane (lista linków)\n```\n\n---\n\n## `templates/sprints/sprint-approval.md`\n\n```markdown\n---\nid: \"SPRINT-APPROVAL-SXX\"\ntitle: \"Sprint Sign-off — SXX\"\nproject: \"NAZWA_PROJEKTU\"\napprover: \"Product Owner / Sponsor\"\ndate: \"YYYY-MM-DD\"\nrelated: [\"SPRINT-REVIEW-SXX\",\"SPRINT-RETRO-SXX\"]\n---\n\n# Sprint Sign-off — SXX\n\n- **Approved by:** ...\n- **Date:** ...\n- **Notes:** ...\n```\n\n---\n\n> Jeśli chcesz, można dopisać do sprintów także `daily/` (dzienniki dzienne) i `metrics/` (CSV), ale to jest opcjonalne i zależy od potrzeb audytowych.","x":3000,"y":-2720,"width":800,"height":1700},
		{"id":"f20e9667bbbd8695","type":"text","text":"# Sprint Output Contract\n\nTen dokument jest **kontraktem rezultatów sprintu**. Jego celem jest wyeliminowanie sytuacji, w której sprint produkuje wyłącznie notatki lub „postęp deklaratywny”, zamiast realnych artefaktów, które **pchają produkcję dalej**.\n\n**Zasada nadrzędna:** każdy element sprintu musi wskazać **konkretny artefakt wyjściowy (output)** umieszczony w jednym z kanonicznych miejsc: kod/infra, dokumentacja, QA, release, ops, governance.\n\n> Uwaga: w sekcji „Szablon pliku” celowo występują pola typu `...` — to są **placeholdery**. Żeby nie było „pusto”, w dalszej części dodałem też **w pełni wypełniony przykład** (realistyczna instancja sprintu), gotowy do skopiowania i edycji.\n\n---\n\n## 1) Jak używać\n\n- Umieść **jedną instancję** tego pliku w: `docs/<project>/sprints/SXX/sprint-output-contract.md`.\n    \n- Każdy wpis w `sprint-backlog.md` musi mieć jednoznacznie zdefiniowane: `output_type`, `output_location`, `verification`.\n    \n- Sprint **DoR** (wejście) i Sprint **DoD** (wyjście) powinny wymagać zgodności z tym kontraktem.\n    \n\n---\n\n## 2) Kanoniczne typy output (dozwolone)\n\nUżywaj jednego (lub kilku) z poniższych typów. To są miejsca, które realnie „pchają produkcję dalej”:\n\n1. **CODE** — commit/PR/merge/tag w repo (implementacja).\n    \n2. **INFRA** — IaC (Terraform/Ansible), konfiguracje, manifesty (wdrożenia).\n    \n3. **DOC-REQ** — dokumentacja wymagań i produktu (PRD/BRD/RTM).\n    \n4. **DOC-DESIGN** — dokumentacja techniczna (TDD + ADR).\n    \n5. **DOC-BIZ** — dokumentacja biznesowa/inwestorska (Executive Summary, Business Case, Feasibility, Grant pack).\n    \n6. **QA** — test cases, test summary, performance report.\n    \n7. **RELEASE** — release checklist, changelog/release notes, release plan.\n    \n8. **OPS** — runbook, deployment guide, monitoring spec, SLO/SLI.\n    \n9. **GOV** — approval/sign-off, change request, risk register (aktualizacja).\n    \n10. **EVID** — dowód: arkusz, raport audytu, log z CI (załącznik w `evidence/`).\n    \n\n> Jeśli output nie pasuje do żadnego typu, istnieje ryzyko „informacji dla informacji”. W takim przypadku należy doprecyzować zakres albo przeredagować element backlogu tak, aby miał mierzalny rezultat.\n\n---\n\n## 3) Szablon pliku (do skopiowania)\n\nSkopiuj poniższy blok jako `docs/<project>/sprints/SXX/sprint-output-contract.md`:\n\n```markdown\n---\nid: \"SPRINT-OUT-SXX\"\ntitle: \"Sprint Output Contract — SXX\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Delivery Lead\"\nstatus: \"draft\"                 # draft|approved|closed\nversion: \"0.1\"\nperiod: \"YYYY-MM-DD..YYYY-MM-DD\"\nrelated:\n  - \"SPRINT-PLAN-SXX\"\n  - \"SPRINT-BACKLOG-SXX\"\n  - \"SPRINT-DOR-SXX\"\n  - \"SPRINT-DOD-SXX\"\n---\n\n# Sprint Output Contract — SXX\n\n## 1. Sprint Goal\n- (jedno zdanie)\n\n## 2. Reguła obowiązkowa\nKażdy element sprintu musi mieć zdefiniowane:\n- **output_type** (CODE/INFRA/DOC-REQ/DOC-DESIGN/DOC-BIZ/QA/RELEASE/OPS/GOV/EVID)\n- **output_location** (konkretny path lub link)\n- **verification** (jak udowodnimy, że output istnieje i jest poprawny)\n- **owner** (osoba odpowiedzialna)\n\n## 3. Backlog z deklaracją output\n\n| Item ID | Title | Owner | Estimate | Output type | Output location | Verification | Gate impact |\n|---|---|---|---:|---|---|---|---|\n| SXX-001 | ... | ... | 3 | CODE | PR: <link> | CI green + review approved | Release readiness |\n| SXX-002 | ... | ... | 2 | DOC-REQ | docs/<client>/PRD.md | DoD(PRD) met + approval | Requirements freeze |\n| SXX-003 | ... | ... | 1 | OPS | docs/runbook.md | ops checklist passed | Ops handover |\n\n## 4. Wymagania dowodowe (Evidence)\nJeśli output opiera się o dane zewnętrzne (finanse, audyt, rynek):\n- evidence file: `docs/<project>/sprints/SXX/evidence/<name>`\n- opis: co udowadnia i gdzie jest użyte\n\n## 5. Zależności i blokery\n- Dependency A → wpływa na item SXX-002\n- Blocker B → wymaga eskalacji (IMP-001)\n\n## 6. Akceptacja kontraktu (gates)\n- **Approved by:** ...\n- **Date:** ...\n- **Notes:** ...\n\n---\n\n## Appendix A — definicje Verification (przykłady)\n- CODE: PR merged + CI green + reviewer approved\n- DOC: plik `.md` w repo + review + approval record\n- QA: raport testów w `qa/` + link w sprint-review\n- OPS: runbook updated + monitoring spec + dry-run\n```\n\n---\n\n## 4) Przykład wypełniony (instancja sprintu)\n\nPoniższy przykład pokazuje sprint nastawiony na **dowożenie dokumentacji inwestorskiej + fundamentów produktu**. Skopiuj i zmień nazwy projektu/klienta.\n\n```markdown\n---\nid: \"SPRINT-OUT-S26\"\ntitle: \"Sprint Output Contract — S26\"\nproject: \"CLIENT_ALPHA\"\nowner: \"Delivery Lead\"\nstatus: \"approved\"\nversion: \"1.0\"\nperiod: \"2025-12-29..2026-01-11\"\nrelated:\n  - \"SPRINT-PLAN-S26\"\n  - \"SPRINT-BACKLOG-S26\"\n  - \"SPRINT-DOR-S26\"\n  - \"SPRINT-DOD-S26\"\n---\n\n# Sprint Output Contract — S26\n\n## 1. Sprint Goal\n- Dostarczyć pakiet inwestorski v1 (Executive Summary + Business Case + Financials) oraz PRD v0.3 gotowe do review i podpisu.\n\n## 2. Backlog z deklaracją output\n\n| Item ID | Title | Owner | Estimate | Output type | Output location | Verification | Gate impact |\n|---|---|---|---:|---|---|---|---|\n| S26-001 | Executive Summary v1 | BizDev Lead | 1 | DOC-BIZ | docs/client_alpha/investor/Executive_Summary.md | Review + APPROVAL-EXSUM-001 | Go/No-Go |\n| S26-002 | Business Case v1 | CFO/Fin Lead | 3 | DOC-BIZ | docs/client_alpha/investor/Business_Case.md | Review + APPROVAL-BUSCASE-001 | Go/No-Go |\n| S26-003 | Financial Model (xlsx) | Finance Analyst | 2 | EVID | docs/client_alpha/investor/evidence/financial_model_v1.xlsx | Hash + link in Business Case | Go/No-Go |\n| S26-004 | Market sources pack | Research Lead | 1 | EVID | docs/client_alpha/investor/evidence/market_sources.md | Sources list complete | Go/No-Go |\n| S26-005 | PRD v0.3 (MVP scope) | Product Owner | 3 | DOC-REQ | docs/client_alpha/product/PRD.md | DoD(PRD) + APPROVAL-PRD-001 | Requirements freeze |\n| S26-006 | RTM draft (MVP) | QA Lead | 2 | QA | docs/client_alpha/product/rtm.csv | RTM covers all PRD P0 | Requirements freeze |\n| S26-007 | Approval pack (sign-offs) | PM | 1 | GOV | docs/client_alpha/approvals/ | Approvals present for P0 docs | Go/No-Go |\n\n## 3. Wymagania dowodowe (Evidence)\n- docs/client_alpha/investor/evidence/financial_model_v1.xlsx — model finansowy wykorzystywany w Business Case.\n- docs/client_alpha/investor/evidence/market_sources.md — źródła dla TAM/SAM/SOM.\n\n## 4. Zależności i blokery\n- Dependency: dane finansowe od klienta → wpływa na S26-002.\n- Blocker: brak potwierdzenia cen (pricing) → eskalacja do stakeholdera.\n\n## 5. Akceptacja kontraktu (gates)\n- **Approved by:** Sponsor / CPO\n- **Date:** 2026-01-11\n- **Notes:** Zatwierdzono pakiet inwestorski v1 do złożenia wniosku grantowego.\n```\n\n---\n\n## 5) Integracja z DoR i DoD sprintu\n\n### Sprint DoR powinien wymagać\n\n- każdy item ma `output_type`, `output_location`, `verification`, `owner`,\n    \n- zależności są jawne i mają ownera,\n    \n- dla dokumentów P0 istnieje plan review i plan approval.\n    \n\n### Sprint DoD powinien wymagać\n\n- każdy output istnieje w zadeklarowanym miejscu,\n    \n- `verification` jest wykonane (dowód: link/artefakt/approval),\n    \n- `sprint-review.md` zawiera linki do wszystkich outputów.\n    \n\n---\n\n## 6) Minimalna checklista (planowanie sprintu)\n\n**Cel:** zanim element trafi do sprintu, ma mieć jednoznacznie określony rezultat (output) oraz sposób weryfikacji. To eliminuje pracę „dla informacji”.\n\n## Obowiązkowe\n\n- Każdy item ma `output_type`.\n    \n- Każdy item ma `output_location` (path/link).\n    \n- Każdy item ma `verification` (jakim dowodem potwierdzamy ukończenie: PR/CI, approval, raport QA, link do pliku).\n    \n- Każdy item ma ownera (osobę odpowiedzialną).\n    \n- Każdy item ma określony wpływ na gate (`Gate impact`: Go/No-Go, Requirements freeze, Release readiness, Ops handover).\n    \n- Zależności są jawne (ID/link) i mają ownera (jeśli blokują — wpis do impediments).\n    \n- Itemy bez output: usunąć albo doprecyzować tak, aby miały mierzalny rezultat.\n    \n\n### Dodatkowe (gdy sprint obejmuje release / compliance)\n\n- Dla outputów typu DOC (PRD/TDD/Biz) jest wskazany plan review + plan approval (kto zatwierdza).\n    \n- Dla outputów typu EVID jest wskazany plik w `evidence/` + opis „co udowadnia i gdzie jest użyty”.\n    \n- Jeżeli sprint zmienia zakres (scope), z góry przygotowany jest mechanizm CR (`sprint-scope-change.md`).\n    \n\n---\n\n## 7) Rekomendowana lokalizacja w repo\n\n- Szablon: `templates/sprints/sprint-output-contract.md`\n    \n- Instancja: `docs/<project>/sprints/SXX/sprint-output-contract.md`\n    \n- Dowody: `docs/<project>/sprints/SXX/evidence/`","x":4000,"y":-2720,"width":640,"height":1700},
		{"id":"a9d14ac100a7e9c7","type":"text","text":"Rozumiem. Sprintowe pliki satelitarne **nie są „dla informacji”** — ich sens jest taki, żeby **wymuszać i dokumentować przepływ pracy do artefaktów kanonicznych**, które faktycznie pchają produkcję dalej: **kod/infra, PRD/TDD/ADR, testy, release, runbooki, monitoring, approval**.\n\nPoniżej masz mapę: **(1) które pliki są źródłem sterowania**, **(2) gdzie lądują wyniki**, **(3) co to konsumuje dalej**.\n\n---\n\n## 1) Artefakty kanoniczne (to one „pchają produkcję dalej”)\n\nTo jest docelowe „lądowanie” informacji ze sprintu:\n\n1. **Kod / infra / konfiguracje**\n    \n    - output: PR/merge, tag/release, pipeline artefakty\n        \n2. **PRD / BRD** (wymagania)\n    \n3. **TDD + ADR** (projekt techniczny + decyzje)\n    \n4. **QA: Test Plan / RTM / Test Cases / Test Summary / Performance Report**\n    \n5. **Release: Release Management Plan + Release Checklist + Changelog/Release Notes**\n    \n6. **Ops: Runbook / Deployment Guide / Operational Manual + Monitoring & Observability**\n    \n7. **Governance: Approval / Sign-off + Change Requests + Risk Register**\n    \n\nSprintowe satelity są po to, żeby **wymusić przepływ** do tych 7 obszarów.\n\n---\n\n## 2) Sprintowe pliki satelitarne → co produkują i kto z tego korzysta\n\n### `sprint-plan.md`\n\n**Rola:** plan sterujący.  \n**Produkuje / aktualizuje:**\n\n- wybór zakresu + priorytetów (wejście do backlogu sprintu),\n    \n- checkpointy (mid/review/retro),\n    \n- decyzje o capacity.  \n    **Konsumują:** `sprint-backlog.md`, stakeholder update, roadmap (jeśli zmienia się plan).\n    \n\n---\n\n### `sprint-backlog.md`\n\n**Rola:** lista pracy, która ma zostać wykonana.  \n**Produkuje / aktualizuje:**\n\n- _konkretne instancje pracy_: linki do `TODO-*`, issue, PR, sekcji dokumentów.  \n    **Konsumują (i to jest „push”):**\n    \n- wykonanie (PR/merge w kodzie),\n    \n- aktualizacje dokumentów kanonicznych (PRD/TDD/Test Plan/Runbook),\n    \n- release checklist (jeśli sprint kończy releasem).\n    \n\n> To backlog jest najbliżej „pchnięcia produkcji”, bo każdy item ma mieć _konkretny output_ (merge / zatwierdzony dokument / dowód testów).\n\n---\n\n### `sprint-dor.md` (Sprint DoR)\n\n**Rola:** filtr wejścia do sprintu (brama).  \n**Produkuje / aktualizuje:** decyzję: _ten item może wejść / nie może wejść_.  \n**Konsumują:** `sprint-backlog.md` (tylko ready items), PO/Tech Lead/QA podczas planowania.\n\n---\n\n### `sprint-dod.md` (Sprint DoD)\n\n**Rola:** filtr wyjścia (brama jakości).  \n**Produkuje / aktualizuje:** decyzję: _item/sprint domknięty / niedomknięty_.  \n**Konsumują:** `sprint-review.md`, `release-checklist.md`, checkpoint **Release Readiness** z Twojego diagramu.\n\n> Sprint DoD jest tym, co łączy sprint z **Release readiness** i realnym wdrożeniem.\n\n---\n\n### `sprint-impediments.md`\n\n**Rola:** rejestr blokerów wpływających na delivery.  \n**Produkuje / aktualizuje:**\n\n- eskalacje,\n    \n- decyzje o zmianie scope lub przesunięciach.  \n    **Konsumują:** `sprint-scope-change.md`, `risk-register.md` (roadmap-level), plan kolejnego sprintu.\n    \n\n---\n\n### `sprint-scope-change.md` (Sprint CR)\n\n**Rola:** formalna zmiana zakresu sprintu (kontrola).  \n**Produkuje / aktualizuje:**\n\n- decyzję „zmieniamy scope” + uzasadnienie + wpływ.  \n    **Konsumują:** `sprint-backlog.md` (aktualizacja), `roadmap.product.md` (jeśli zmiana wpływa na release).\n    \n\n---\n\n### `daily/SPRINT-DAILY-*` (opcjonalne)\n\n**Rola:** krótkie logi wykonania i blokad.  \n**Produkuje / aktualizuje:** mikro-updaty do `sprint-backlog.md` i `sprint-impediments.md`.  \n**Konsumują:** Scrum Master/Delivery Lead.\n\n---\n\n### `sprint-review.md`\n\n**Rola:** zapis dowiezionych rezultatów (dowody delivery).  \n**Produkuje / aktualizuje:**\n\n- lista „Delivered” z linkami do PR/merge, dokumentów, release notes,\n    \n- decyzje stakeholderów.  \n    **Konsumują (push dalej):**\n    \n- `roadmap.product.md` (aktualizacja planu),\n    \n- `changelog.md` / release notes,\n    \n- decyzja o wejściu w release gate.\n    \n\n---\n\n### `sprint-retro.md` + `sprint-action-items.md`\n\n**Rola:** usprawnienia procesu.  \n**Produkują / aktualizują:** action items (które muszą wejść do backlogu jako praca).  \n**Konsumują:** następny sprint (backlog), standardy DoR/DoD (może je zmienić).\n\n---\n\n### `sprint-metrics.md` (opcjonalne)\n\n**Rola:** pomiar jakości/delivery (nie „informacja dla informacji”, tylko narzędzie sterowania).  \n**Produkuje / aktualizuje:** decyzje o zmianie capacity/procesu (np. za dużo reworku → zmiana DoR/DoD).  \n**Konsumują:** plan kolejnych sprintów + roadmap.\n\n---\n\n### `sprint-approval.md` (opcjonalne)\n\n**Rola:** formalny sign-off sprintu (np. gdy sprint domyka etap grantowy lub release).  \n**Produkuje:** dowód zatwierdzenia.  \n**Konsumują:** compliance/audit, checkpointy (np. “Operations Handover”, “Release Readiness”).\n\n---\n\n## 3) Gdzie „lądują” wyniki sprintu, żeby pchały produkcję\n\nW praktyce, **po sprincie powinny zostać zaktualizowane/utworzone** (zależnie od typu sprintu):\n\n### Jeśli sprint jest DEV/release\n\n- **repo (kod):** PR merged + tag/release\n    \n- **QA:** test summary + performance report\n    \n- **Ops:** runbook + deployment guide aktualne\n    \n- **Release:** release checklist + changelog/release notes\n    \n- **Governance:** approval (jeśli potrzebne)\n    \n\n### Jeśli sprint jest „dokumentacyjny” (Twoje usługi dla klientów)\n\n- **Główne dokumenty klienta:** Executive Summary / Business Case / PRD / Feasibility itd. (wersja i status)\n    \n- **Evidence pack:** arkusze finansowe, źródła rynku, załączniki (w `evidence/`)\n    \n- **Approvals:** podpisy/akceptacje (CFO/PO/Legal)\n    \n- **Changelog:** historia zmian (żeby było audytowalne)\n    \n\n---\n\n## 4) Minimalny „push-flow” (ASCII)\n\nTo jest najkrótszy łańcuch, który faktycznie pcha produkcję:\n\n```\nsprint-plan\n  -> sprint-backlog (only DoR-ready items)\n      -> execution outputs (PR/Docs/Evidence)\n          -> DoD check (item + sprint)\n              -> sprint-review (delivered links)\n                  -> release-checklist + changelog + approval (if needed)\n                      -> release gate / deploy\n```\n\n---\n\n## 5) Najważniejsza reguła: satelity muszą mieć output-kanoniczny\n\nŻeby nie robić „informacji dla informacji”, każdy sprintowy plik powinien wskazywać **konkretny output**, np.:\n\n- backlog item → **PR/merge** lub **konkretny plik doc** (`docs/clientX/Business_Case.md`)\n    \n- DoR/DoD → _bramka_, która dopuszcza/zamyka pracę\n    \n- review → _lista linków_ do dowiezionych artefaktów\n    \n- impediments → decyzja / CR / eskalacja\n    \n\n---\n\nJeśli chcesz, mogę Ci teraz przygotować **jedną stronę “Sprint Output Contract”** (szablon `.md`), która wymusza, żeby każdy backlog item miał pole `output_artifact:` wskazujące dokładnie, gdzie ma wylądować rezultat (kod/dokument/test/runbook). To praktycznie eliminuje „papierologię dla papierologii”.","x":3440,"y":-2720,"width":720,"height":1700},
		{"id":"c0a6578e2727cdf8","type":"text","text":"Roadmapa to _dokument aktywny_, więc logiczne, że powinna mieć własne „satelity” (lekkie artefakty wspierające zarządzanie, traceability, decyzyjność i wykonanie). Poniżej daję praktyczny, profesjonalny wzorzec: **typy roadmap**, **strukturę dokumentu**, **satelity które zawsze rozważyć**, **checkpointy / cadence**, przykładowy front-matter `.md` i krótki ASCII-diagram zależności.\n\n# 1 — Rodzaje roadmap (warstwy)\n\n1. **Strategiczna (Vision / 2–5 lat)** — cele biznesowe, OKR/KSF, kierunki R&D.\n    \n2. **Produktowa / Portfolio (12–24 mies.)** — główne epiki, value streams, priorytety.\n    \n3. **Program / Release (3–12 mies.)** — zgrupowane epiki/feature sets przypisane do wydań.\n    \n4. **Tactical / Iteration (Sprinty, Q)** — konkretne releasy, milestones, deliverables.\n    \n5. **Tech / Architecture roadmap** — migracje infra, wersje DB, deprecations.\n    \n6. **Go-to-Market / Commercial roadmap** — kanały, kampanie, onboarding klientów.\n    \n\n# 2 — Co powinna zawierać dobra roadmapa (sekcje)\n\n- **Meta / Front-matter**: id, owner, wersja, status, data.\n    \n- **Cel / Kontekst biznesowy**: dlaczego to robimy (KPIs, OKR powiązania).\n    \n- **Horyzonty czasowe**: swimlanes (Strategic / Product / Release / Tech).\n    \n- **Kamienie milowe (milestones)** + terminy.\n    \n- **Epiki / Feature sets** z priorytetami i hypothesami wartości.\n    \n- **Zależności i blokery** (internal/external).\n    \n- **Założenia / Ryzyka (top-3 per milestone)** i mitigacje.\n    \n- **Zasoby & capacity** (headcount, external vendors, budżet).\n    \n- **KPI / metryki sukcesu** i sposób walidacji (how we know it’s working).\n    \n- **Checkpointy / Gate criteria** (DoR/DoD for releases).\n    \n- **Komunikacja / RACI / Stakeholder map** (kto musi wiedzieć/co).\n    \n- **Links / Evidence** (business case, TDDs, compliance artefacts).\n    \n\n# 3 — Satelitarne dokumenty wokół roadmapy (konkret)\n\nKażda roadmapa (zwłaszcza product/program/release) powinna mieć _satelity_. Oto lista z krótką rolą:\n\n**A. Planowanie i przygotowanie**\n\n- `TODOs per epic/section` — zadania do zebrania danych/przygotowania opisów.\n    \n- **DoR (roadmap-level / epic-level)** — kryteria kiedy epik/release może wejść do planu.\n    \n- **Capacity Plan** — dostępne FTE, contractor hours, estymacje effort.\n    \n- **Budget / Cost Estimate** — budżet powiązany z kamieniem milowym.\n    \n\n**B. Kontrola jakości i akceptacja**\n\n- **DoD (release-level)** — kryteria gotowości releasu (QA, docs, compliance).\n    \n- **Release Checklist / Cutover Plan** — kroki pre/post release.\n    \n- **UAT / Acceptance Plan** — kto, jak testuje, kryteria sukcesu.\n    \n\n**C. Traceability i dowody**\n\n- **RTM fragment (mapowanie epic → PRD → TDD → test cases)**\n    \n- **Evidence items** — załączniki (arkusze finansów, audyty, DPO opinions).\n    \n- **ADR / Decision Log** — decyzje które wpłynęły na zmianę roadmapy.\n    \n\n**D. Governance, komunikacja**\n\n- **Approval records** — formalne akceptacje milestone’ów.\n    \n- **Stakeholder comms plan** — kto i kiedy dostaje update.\n    \n- **Change Request (CR)** — formalny proces zmiany dat/zakresu.\n    \n\n**E. Ryzyko i metryki**\n\n- **Risk Register (roadmap-level)** — ryzyko, właściciel, mitigacja.\n    \n- **KPIs / Dashboards spec** — jak raportować postęp (S-curve, %complete, value delivered).\n    \n\n**F. Operacyjne**\n\n- **Runbook links / Ops readiness** — powiązania z runbookami i SLO/SLA.\n    \n- **Monitoring Plan** — metryki produkcyjne które muszą być obserwowane po releasie.\n    \n\n# 4 — Checkpointy / cadence (zalecane)\n\n- **Quarterly strategic review** (aktualizacja strategicznej roadmapy).\n    \n- **Monthly program sync** (przegląd portfela epików, blocking issues).\n    \n- **Sprintly / biweekly tactical grooming** (przepływ epik→story, DoR weryfikacja).\n    \n- **Release gating**: Pre-freeze (DoR), Freeze, Pre-release DoD check, Post-release review + postmortem.\n    \n\n# 5 — Gdzie trzymać (konwencja plików)\n\n```\ndocs/<project>/roadmaps/\n  ├─ roadmap.product.md        # główny plik roadmapy (front-matter)\n  ├─ todos/                    # TODO per epic/section\n  ├─ approvals/                # approval records\n  ├─ evidence/                 # financials, analyses\n  ├─ risk-register.md\n  ├─ capacity-plan.md\n  ├─ release-checklists/\n  └─ dashboards/               # specyfikacje KPI/metric definitions\n```\n\n# 6 — Przykładowy front-matter dla roadmapy (`roadmap.product.md`)\n\n```yaml\n---\nid: \"ROADMAP-PROD-001\"\ntitle: \"Product Roadmap — Q1–Q4 2026\"\nowner: \"Head of Product\"\nstatus: \"draft\"     # draft|in-review|approved|archived\nversion: \"0.2\"\ndate_created: \"2025-12-24\"\nlast_modified: \"2025-12-24\"\nhorizon: \"12 months\"\nrelated_docs:\n  - \"DOC-BUSCASE-001\"\n  - \"DOC-PRD-001\"\ntags: [\"roadmap\",\"product\",\"release\"]\napprovers: [\"CEO\",\"CPO\"]\n---\n```\n\nPod roadmapą **zawsze** umieść linki do `todos/`, `approvals/`, `evidence/` i `risk-register.md`.\n\n# 7 — DoR i DoD dla roadmapy (szybko)\n\n**DoR (epic → roadmap):**\n\n- Epik ma klarowny cel biznesowy + AC (GIVEN/WHEN/THEN).\n    \n- Estymacja high-level i owner.\n    \n- Zidentyfikowane zależności i wpływ na inne epiki.\n    \n- Wstępne ryzyka ocenione.\n    \n\n**DoD (release → roadmap):**\n\n- Wszystkie krytyczne AC spełnione i zweryfikowane.\n    \n- QA/UAT zakończone (pass).\n    \n- Dokumentacja i runbooki uzupełnione.\n    \n- Monitoring/SLOs skonfigurowane.\n    \n- Approval record w `approvals/` z podpisem.\n    \n\n# 8 — Prosty ASCII-diagram (zależności)\n\n```\n[Vision / Strategy]\n       |\n   (breaks down)\n       v\n[Product Roadmap] -----------------------> [Stakeholder Comms]\n  |        |         \\\n  |        |          \\---> todos/ (per epic)\n  |        |---> capacity-plan.md\n  |        |---> risk-register.md\n  |        |---> approvals/\n  v\n[Release 1] -- DoR? --> (start) --> Dev/Test/Docs --> DoD? --> Release Checklist --> Prod\n   |                                                              \\\n   `--> evidence/ (financials, regs)                                --> Postmortem\n```\n\n# 9 — Metryki i raportowanie (co mierzyć)\n\n- % ukończenia epic (weighted by value)\n    \n- % delivered value vs forecast (business value)\n    \n- Lead time for features (epic start → release)\n    \n- Number of blocked epics / avg blocker time\n    \n- Burn-up chart by value delivered\n    \n\n","x":440,"y":-2140,"width":520,"height":1120},
		{"id":"93890efc5528f94b","type":"text","text":"---\nid: \"DEF-READY-001\"\ntype: \"definition\"\ntitle: \"Definition of Ready (DoR) — projekt / backlog\"\nowner: \"Product Owner\"\nstatus: \"draft\"\ncreated: \"2025-12-24\"\ntags: [\"dor\", \"agile\", \"backlog\", \"quality\"]\n---\n\n# Definition of Ready (DoR)\n\n## Cel\nOkreślić minimalny zestaw warunków, które musi spełniać **user story / zadanie / wymaganie**, aby mogło zostać przyjęte do sprintu/pracy. Zapobiega pracy nad niekompletnymi lub niezweryfikowanymi elementami.\n\n## Zakres stosowania\n- User stories w backlogu produktu\n- Zadania techniczne powiązane z PRD/TDD\n- Change requests wymagające implementacji kodu\n\n## Kryteria — przykład (konkretne, mierzalne)\nKażde zadanie/storia powinna spełniać poniższe kryteria zanim zostanie „rozpoczęta”:\n\n1. **Opis**: Krótki, jednozdaniowy opis celu.  \n2. **Akceptowalne kryteria (Acceptance Criteria)**: Minimum 1–3 mierzalne AC zapisane jako GIVEN/WHEN/THEN.  \n3. **Priorytet**: Określony priorytet i kontekst biznesowy (np. P0/P1/P2).  \n4. **Właściciel biznesowy**: Product Owner przypisany i dostępny do pytań.  \n5. **Wstępna estymacja**: Story oszacowana (np. story points / ideal days).  \n6. **Zależności**: Wymienione zależności z innymi zadaniami (jeśli są — ID powiązane).  \n7. **Dane testowe / dostęp do środowisk**: Dostęp do seeda/test data lub mocków; jeśli wymagane, środowisko testowe dostępne.  \n8. **Definicja ukończenia (DoD) referencja**: Link do odpowiedniej DoD lub listy obowiązkowych kryteriów końcowych.  \n9. **Aspekty niefunkcjonalne**: Wymagania niefunkcjonalne (security, perf, compliance) zidentyfikowane albo wyraźnie oznaczone jako „nie dotyczy”.  \n10. **Dokumentacja wejściowa**: Linki do PRD / TDD / UX / API spec lub krótkie załączniki.  \n11. **Akceptowalność techniczna**: Tech Lead zweryfikował wykonalność i ryzyka (jeśli dotyczy).  \n12. **Estymacja ryzyka**: Krótka ocena ryzyka i plan mitigacji (jeśli ryzyko > medium).\n\n## Kryteria wykluczające (czego DoR NIE obejmuje)\n- Nie zawiera pełnej implementacji ani kodu źródłowego.  \n- Nie zastępuje TDD ani pełnej dokumentacji testowej — to tylko warunki wejścia.\n\n## Proces weryfikacji\n- Product Owner (PO) zatwierdza kompletność opisu i AC.  \n- Tech Lead zatwierdza wykonalność / zależności techniczne.  \n- QA Lead potwierdza dostęp do test data i środowisk (jeśli konieczne).  \n- Zapis zatwierdzenia: update front-matter (`status: ready`) + data i podpis/ID approvera.\n\n## Przykład krótkiej checklisty (do użycia w Issue / TODO)\n- [ ] Opis klarowny.\n- [ ] AC (GIVEN/WHEN/THEN) przygotowane.\n- [ ] Estymacja ukończona.\n- [ ] Właściciel biznesowy przypisany.\n- [ ] Zależności wskazane i zarejestrowane.\n- [ ] Test data / mocki dostępne.\n- [ ] Tech Lead: akceptuję (komentarz).\n- [ ] QA: test env dostępny / zaakceptowane.\n\n## Przechowywanie i wersjonowanie\n- Rekomendowana ścieżka: `docs/atomic/definitions/Definition_of_Ready.md`  \n- Wersjonowanie: utrzymuj `status` i `changed` w front-matter; każda aktualizacja DoR powinna być zapisana jako commit/PR.\n\n## Powiązania\n- Powiązane artefakty: PRD, BRD, TDD, DoD, RTM, TODOs w backlogu.\n\n---\n","x":40,"y":-706,"width":540,"height":1250},
		{"id":"2e9d3cbeb39530c9","type":"text","text":"\n|Tak — **dobrze rozumiesz kierunek**, ale warto to ustrukturyzować: dokumenty powinny mieć „satelity” — lekkie, atomowe artefakty wokół nich — **proporcjonalnie** do skali, ryzyka i liczby interesariuszy. Nie każdy dokument potrzebuje pełnego zestawu; stosuj zasadę „proporcjonalności”: im większy wpływ/ilość współpracowników/ryzyko — tym więcej satelitów.\n\nPoniżej konkretna, praktyczna mapa: _co_ satelituje dokument, _dlaczego_, _kiedy_ stosować, _gdzie trzymać_ i gotowe, kopiowalne szablony front-matterów / checklist.\n\n---\n\n# 1. Minimalny zestaw (dla małych dokumentów / one-pagerów)\n\nKiedy: jeden autor, niskie ryzyko, szybkie zatwierdzenie.\n\n- `TODO` (1 wpis: napisać → review → sign-off)\n    \n- `Change Log` (wersjonowanie)\n    \n- `Approval / Sign-off` (kto i kiedy)\n    \n\nGdzie: `docs/<doc>/todos/`, `docs/<doc>/changelog.md`, `docs/<doc>/approvals.md`\n\n---\n\n# 2. Zalecany standard (dokumenty średniej ważności — PRD, Business Case, Feasibility)\n\nKiedy: wieloosobowe wejścia, wpływ na decyzję, powiązania z budżetem/architekturą.\n\n- `Meta (document front-matter)` — autor/owner, wersja, status, odbiorcy, powiązane artefakty, deadline.\n    \n- **TODOs per sekcja** — owner, acceptance criteria, dependencies.\n    \n- **DoR** (document-level lub section-level) — czy dokument/sekcja jest gotowa żeby przejść dalej (np. do review/sprintu).\n    \n- **DoD** (document-level) — co oznacza, że dokument jest ukończony (np. PR merged, attachments, sign-offs).\n    \n- `Review checklist` — lista osób do review (tech/legal/finance), terminy.\n    \n- `Approval record / Sign-off` — kto akceptuje (z rolą).\n    \n- `Decision Log / ADR links` — powiązania z decyzjami architektonicznymi.\n    \n- `RTM / Traceability links` — jeżeli dokument wiąże wymagania → testy.\n    \n- `Evidence items` — załączniki (arkusze finansowe, raporty audytów).\n    \n- `Change Request` template (na wypadek scope change po freeze).\n    \n- `Change Log / Version history`.\n    \n\nGdzie:\n\n```\ndocs/<doc>/\n  ├─ <doc>.md                 # główny dokument (z front-matter)\n  ├─ todos/                   # todo-per-section .md\n  ├─ approvals.md\n  ├─ changelog.md\n  ├─ evidence/                # załączniki (spreadsheets, audyt)\n  └─ adr-links.md\n```\n\n---\n\n# 3. Pełny zestaw (dokumenty krytyczne / compliance / regulatory / release)\n\nKiedy: regulatory, finansowe, publikacje do inwestorów, release readiness.\n\n- Wszystko z zestawu „zalecanego” +:\n    \n    - `DPIA fragments / compliance evidence` (pozycje dowodowe)\n        \n    - `Test cases / QA scripts` powiązane z wymaganiami dokumentu\n        \n    - `Runbook / deployment playbook` referencje\n        \n    - `Audit trail` (kto zmieniał, dlaczego — linki do PR)\n        \n    - `Post-release checklists` i `Monitoring plan` (satelita operacyjny)\n        \n    - `Legal sign-off` (DPO, counsel)\n        \n    - `Funding attachments / Cap table / Term sheet` (dla investor docs)\n        \n\nGdzie: analogicznie, z folderami `compliance/`, `qa/`, `ops/`, `legal/`.\n\n---\n\n# 4. Konkretny mapping: satelity → cel krótkie\n\n- **TODO (per sekcja)** — rozbijanie pracy, owner, AC.\n    \n- **DoR (document/section)** — gwarancja wejścia do następnego kroku (np. review).\n    \n- **DoD (document)** — kryteria ukończenia (Merge, attachments, tests, approvals).\n    \n- **Review checklist** — lista reviewerów + role + deadliny.\n    \n- **Approval record** — zapis zatwierdzeń (imię, rola, data).\n    \n- **Change Request** — formalny wniosek zmian po freeze.\n    \n- **ADR / Decision Log** — powiązane decyzje architektoniczne.\n    \n- **Evidence items** — pliki potwierdzające twierdzenia (arkusze, audyt, certyfikaty).\n    \n- **RTM / Coverage** — mapowanie wymagań na testy.\n    \n- **Test cases / QA** — scenariusze powiązane z treścią dokumentu.\n    \n- **Runbook / Ops notes** — jeśli dokument ma wpływ na operacje.\n    \n- **Changelog / Version history** — śledzenie zmian i powodów.\n    \n- **Meeting minutes / action items** — jeśli dokument powstaje w wyniku spotkań.\n    \n- **Sign-off checklist** — ostateczna lista do „podpisania”.\n    \n\n---\n\n# 5. Praktyczne zasady stosowania (reguły decyzyjne)\n\n1. **Per-sekcja TODO** kiedy: sekcja wymaga wejść od innych właścicieli (>1 osoba) lub ma >3 akapitów.\n    \n2. **DoR per section** gdy: sekcja agreguje zewnętrzne dane (finanse, UX research, security).\n    \n3. **DoD document-level** zawsze — by zautomatyzować merge/release/archiwizację.\n    \n4. **Evidence** — dołączaj minimalny dowód do każdej krytycznej tezy (np. źródło TAM, model finansowy).\n    \n5. **Traceability** — każde TODO/ADR/CR powinno mieć `related: <doc>.md` w front-matter.\n    \n6. **Automatyzacja** — generuj TODO jako Issue/PR skeletons (skrypt), a gdy PR zamknięty — automatycznie oznacz TODO jako done.\n    \n7. **Identyfikatory** — używaj stałych prefiksów: `TODO-`, `ADR-`, `CR-`, `EVID-`, `APPROVAL-` — ułatwia filtrowanie.\n    \n\n---\n\n# 6. Gotowe szablony (kopiuj/wklej)\n\n## A) Document front-matter (umieść na górze każdego dokumentu)\n\n```yaml\n---\nid: \"DOC-PRD-001\"\ntitle: \"Product Requirements Document\"\nowner: \"Imię Nazwisko / Zespół\"\nstatus: \"draft|in-review|ready|approved\"\nversion: \"0.1\"\ncreated: \"2025-12-24\"\nupdated: \"2025-12-24\"\napprover: \"\"            # kto zatwierdza doc\nrelated: [\"BUSCASE-001\", \"TDD-001\"]\ntags: [\"prr\",\"prjX\",\"prd\"]\ndoR: \"DO R link or id\"\ndoD: \"DO D link or id\"\n---\n```\n\n## B) TODO per section (szablon)\n\n```yaml\n---\nid: \"TODO-PRD-FUNC-001\"\ntype: \"todo\"\ntitle: \"Sekcja: Wymagania funkcjonalne - PRD\"\nowner: \"Product Owner\"\nstatus: \"todo\"\npriority: \"P0\"\ncreated: \"2025-12-24\"\ndue: \"2026-01-07\"\nrelated: [\"DOC-PRD-001\"]\nacceptance_criteria:\n  - \"Min. 10 user stories z AC\"\n  - \"Źródła wymagań załączone (linki)\"\n---\n# TODO: Wymagania funkcjonalne\n- [ ] Zebrać wymagania od stakeholderów (link)\n- [ ] Sformułować user stories + AC\n- [ ] Przekazać do tech review (Tech Lead)\n- [ ] Dodać do RTM\n```\n\n## C) DoR (krótka wersja; per document lub per section)\n\n```markdown\n---\nid: \"DEF-READY-PRD-001\"\ntype: \"definition\"\ntitle: \"Definition of Ready — PRD\"\nowner: \"Product Owner\"\nstatus: \"draft\"\ncreated: \"2025-12-24\"\nrelated: [\"DOC-PRD-001\"]\n---\n## DoR - PRD (przykładowe kryteria)\n- [ ] Opis i cel biznesowy (1-2 zdania)\n- [ ] Min. 5 AC (GIVEN/WHEN/THEN)\n- [ ] Estymacja (story points)\n- [ ] Właściciel biznesowy przypisany\n- [ ] Źródła danych (linki)\n- [ ] Tech Lead: wykonalność potwierdzona\n```\n\n## D) DoD (krótka wersja; document-level)\n\n```markdown\n---\nid: \"DEF-DONE-PRD-001\"\ntype: \"definition\"\ntitle: \"Definition of Done — PRD\"\nowner: \"Team Lead / QA\"\nstatus: \"draft\"\ncreated: \"2025-12-24\"\nrelated: [\"DOC-PRD-001\"]\n---\n## DoD - PRD (przykładowe kryteria)\n- [ ] PR zmergowany / dokument opublikowany\n- [ ] Wszystkie TODO sekcji: done\n- [ ] Reviewy: Tech + QA + PO completed\n- [ ] Evidence attachments dołączone (arkusze/raporty)\n- [ ] Approval: approver name, date\n```\n\n## E) Approval / Sign-off record (krótki)\n\n```markdown\n---\nid: \"APPROVAL-DOC-PRD-001\"\ntype: \"approval\"\ntitle: \"Approval PRD v0.1\"\napprover: \"CFO / Sponsor / Head of Product\"\ndate: \"2026-01-15\"\nrelated: [\"DOC-PRD-001\"]\nnotes: \"Approved for development start under budget X\"\n---\n```\n\n---\n\n# 7. Gdzie trzymać te pliki (konwencja)\n\n- `docs/<project>/<document>.md` — główny plik z front-matter.\n    \n- `docs/<project>/todos/` — TODO per section.\n    \n- `docs/<project>/evidence/` — załączniki (xlsx, csv, pdf).\n    \n- `docs/<project>/approvals/` — sign-offs.\n    \n- `docs/atomic/` — ADR, RFC, CR, spike notes.\n    \n- `changelog/` lub `docs/<project>/changelog.md` — wersje.\n    \n\n---\n\n# 8. Kiedy NIE robić per-section TODO / DoR / DoD\n\n- Prosty one-pager marketingowy lub wewnętrzny notatnik, gdzie koszt procesowy > wartość.\n    \n- Gdy dokument ma 1 autora i łatwość zatwierdzenia, a jego wpływ jest zerowy na integracje / budżet / bezpieczeństwo.\n    \n\n---\n\n","x":60,"y":720,"width":520,"height":1720},
		{"id":"5313b63ec08484e4","type":"text","text":"# Definition of Ready (DoR)\n\n# Krótkie porównanie\n\n- **DoR (Definition of Ready)** — warunki, które muszą być spełnione _przed_ rozpoczęciem pracy nad zadaniem/storią (wejściowe kryteria). Zapobiega rozpoczęciu pracy na nieprzygotowanych wymaganiach.\n    \n- **DoD (Definition of Done)** — warunki, które muszą być spełnione _po_ zakończeniu pracy (wyjściowe kryteria). Gwarantuje jakość i powtarzalność dostawy.\n    \n\n# Kiedy używać DoR\n\n- W zespołach Agile/Scrum przy przyjmowaniu User Story do sprintu.\n    \n- Gdy wiele zespołów korzysta z jednego backlogu (wymusza spójność).\n    \n- Przy dokumentach wielo-właścicielskich (PRD/TDD), żeby uniknąć „niekompletnych” prac.\n    \n\n# Kto powinien utrzymywać DoR\n\n- Product Owner (główna odpowiedzialność za treść),\n    \n- Tech Lead/Architect (dla kryteriów technicznych),\n    \n- QA Lead (kryteria testowalności),\n    \n- Stakeholderzy, jeśli wymagane (np. Security Lead).\n    \n\n# Ile to zajmuje / objętość\n\n- Zazwyczaj 1 strona (lista kryteriów).\n    \n- Punkty: 6–12 kluczowych kryteriów (może być więcej w projektach regulowanych).\n    \n\n---\n\n# Szablon: Definition of Ready (MD)\n\n```markdown\n---\nid: \"DEF-READY-001\"\ntype: \"definition\"\ntitle: \"Definition of Ready (DoR) — projekt / backlog\"\nowner: \"Product Owner\"\nstatus: \"draft\"\ncreated: \"2025-12-24\"\ntags: [\"dor\", \"agile\", \"backlog\", \"quality\"]\n---\n\n# Definition of Ready (DoR)\n\n## Cel\nOkreślić minimalny zestaw warunków, które musi spełniać **user story / zadanie / wymaganie**, aby mogło zostać przyjęte do sprintu/pracy. Zapobiega pracy nad niekompletnymi lub niezweryfikowanymi elementami.\n\n## Zakres stosowania\n- User stories w backlogu produktu\n- Zadania techniczne powiązane z PRD/TDD\n- Change requests wymagające implementacji kodu\n\n## Kryteria — przykład (konkretne, mierzalne)\nKażde zadanie/storia powinna spełniać poniższe kryteria zanim zostanie „rozpoczęta”:\n\n1. **Opis**: Krótki, jednozdaniowy opis celu.  \n2. **Akceptowalne kryteria (Acceptance Criteria)**: Minimum 1–3 mierzalne AC zapisane jako GIVEN/WHEN/THEN.  \n3. **Priorytet**: Określony priorytet i kontekst biznesowy (np. P0/P1/P2).  \n4. **Właściciel biznesowy**: Product Owner przypisany i dostępny do pytań.  \n5. **Wstępna estymacja**: Story oszacowana (np. story points / ideal days).  \n6. **Zależności**: Wymienione zależności z innymi zadaniami (jeśli są — ID powiązane).  \n7. **Dane testowe / dostęp do środowisk**: Dostęp do seeda/test data lub mocków; jeśli wymagane, środowisko testowe dostępne.  \n8. **Definicja ukończenia (DoD) referencja**: Link do odpowiedniej DoD lub listy obowiązkowych kryteriów końcowych.  \n9. **Aspekty niefunkcjonalne**: Wymagania niefunkcjonalne (security, perf, compliance) zidentyfikowane albo wyraźnie oznaczone jako „nie dotyczy”.  \n10. **Dokumentacja wejściowa**: Linki do PRD / TDD / UX / API spec lub krótkie załączniki.  \n11. **Akceptowalność techniczna**: Tech Lead zweryfikował wykonalność i ryzyka (jeśli dotyczy).  \n12. **Estymacja ryzyka**: Krótka ocena ryzyka i plan mitigacji (jeśli ryzyko > medium).\n\n## Kryteria wykluczające (czego DoR NIE obejmuje)\n- Nie zawiera pełnej implementacji ani kodu źródłowego.  \n- Nie zastępuje TDD ani pełnej dokumentacji testowej — to tylko warunki wejścia.\n\n## Proces weryfikacji\n- Product Owner (PO) zatwierdza kompletność opisu i AC.  \n- Tech Lead zatwierdza wykonalność / zależności techniczne.  \n- QA Lead potwierdza dostęp do test data i środowisk (jeśli konieczne).  \n- Zapis zatwierdzenia: update front-matter (`status: ready`) + data i podpis/ID approvera.\n\n## Przykład krótkiej checklisty (do użycia w Issue / TODO)\n- [ ] Opis klarowny.\n- [ ] AC (GIVEN/WHEN/THEN) przygotowane.\n- [ ] Estymacja ukończona.\n- [ ] Właściciel biznesowy przypisany.\n- [ ] Zależności wskazane i zarejestrowane.\n- [ ] Test data / mocki dostępne.\n- [ ] Tech Lead: akceptuję (komentarz).\n- [ ] QA: test env dostępny / zaakceptowane.\n\n## Przechowywanie i wersjonowanie\n- Rekomendowana ścieżka: `docs/atomic/definitions/Definition_of_Ready.md`  \n- Wersjonowanie: utrzymuj `status` i `changed` w front-matter; każda aktualizacja DoR powinna być zapisana jako commit/PR.\n\n## Powiązania\n- Powiązane artefakty: PRD, BRD, TDD, DoD, RTM, TODOs w backlogu.\n\n---\n```\n\n---\n\nJeżeli chcesz, **dodam ten plik do kanwy / templates** (i wygeneruję kilka przykładowych DoR dla: user story, epic, change request). Ma być od razu:\n\n- 1. w `templates/atomic/definitions/Definition_of_Ready.md`, oraz\n        \n- 2. opcjonalnie skopiuję go do `docs/<client>/definitions/` z przykładem wypełnienia.\n        \n\nDaj znać — zrobię to teraz.","x":620,"y":-706,"width":760,"height":1250},
		{"id":"2a0b647a9e65fe08","type":"text","text":"# Krótko: najważniejsza różnica\n\n**DoR (Definition of Ready)** — kryteria wejścia: co musi być spełnione _przed_ rozpoczęciem pracy nad zadaniem/story.  \n**DoD (Definition of Done)** — kryteria wyjścia: co musi być spełnione _po_ wykonaniu zadania, żeby można je uznać za naprawdę ukończone.\n\n# Cel i kiedy się stosuje\n\n- **DoR**: zapobiega zaczynaniu pracy na niekompletnych wymaganiach; używasz przy przyjmowaniu itemu do sprintu/backlogu/pracy.\n    \n- **DoD**: zapewnia jakość i powtarzalność dostawy; stosujesz przy zatwierdzaniu ukończonej pracy (PR merge, release, wydanie).\n    \n\n# Kto odpowiada\n\n- **DoR** — odpowiedzialny: Product Owner (treść), Tech Lead (techniczna wykonalność), QA (testowalność).\n    \n- **DoD** — odpowiedzialny: zespół wykonawczy + QA + DevOps/Release Manager (spełnienie kryteriów operacyjnych).\n    \n\n# Typowe przykłady kryteriów (konkret)\n\n**DoR — przykładowe kryteria**\n\n- Opis jasno sformułowany (1 zdanie + cel biznesowy).\n    \n- Acceptance Criteria (GIVEN/WHEN/THEN) min. 1–3.\n    \n- Estymacja (story points / ideal days).\n    \n- Właściciel biznesowy przypisany i dostępny.\n    \n- Zidentyfikowane zależności (ID powiązanych zadań).\n    \n- Dostęp do test data / mocków lub plan ich przygotowania.\n    \n- Wstępna analiza ryzyka (jeśli > medium).\n    \n- Linki do PRD/TDD/API/UX.\n    \n\n**DoD — przykładowe kryteria**\n\n- Kod zmergowany do main (PR zatwierdzony).\n    \n- Wszystkie unit/integration tests zielone.\n    \n- E2E/UAT (jeśli wymagane) — przeprowadzone i zaakceptowane.\n    \n- Dokumentacja uaktualniona (API, runbook, changelog).\n    \n- Wersja zbudowana i wdrożona na staging z passing smoke tests.\n    \n- Security check / linter / SAST/DAST (jeśli wymagane) — wykonane.\n    \n- Migration scripts (jeśli dotyczy) + rollback tested.\n    \n- Owner zatwierdził i podpisał (approver, data).\n    \n\n# Porównanie (jedna tabela — do szybkiego zapamiętania)\n\n- DoR = _Wejście_ → „Czy mamy wszystko, żeby zacząć?”\n    \n- DoD = _Wyjście_ → „Czy to naprawdę gotowe do użycia/wyjścia z zespołu?”\n    \n\n# Jak współpracują w procesie (praktyka)\n\n1. Before sprint planning: sprawdzasz DoR — tylko itemy spełniające DoR trafiają do sprintu.\n    \n2. Podczas developmentu: developerzy realizują pracę według PRD/TDD i stopniowo spełniają kryteria DoD.\n    \n3. Przy końcu pracy: przed zamknięciem zadania checklist DoD musi być zaznaczona/udokumentowana.\n    \n4. Gate / release: Release Manager sprawdza DoD globalnie przed release’em.\n    \n\n# Gotowe szablony (do .md) — front-matter + checklist (skopiuj/wklej)\n\n**DoR (Definition of Ready)**\n\n```markdown\n---\nid: \"DEF-READY-001\"\ntype: \"definition\"\ntitle: \"Definition of Ready (DoR)\"\nowner: \"Product Owner\"\nstatus: \"draft\"\ncreated: \"2025-12-24\"\ntags: [\"dor\",\"agile\",\"backlog\"]\n---\n\n## Definition of Ready (DoR)\n\n- Cel: minimalne warunki przed rozpoczęciem pracy nad story/task.\n- Kryteria (przykład):\n  - [ ] Opis i cel biznesowy\n  - [ ] Acceptance Criteria (GIVEN/WHEN/THEN)\n  - [ ] Estymacja (story points)\n  - [ ] Właściciel biznesowy przypisany\n  - [ ] Zależności zarejestrowane\n  - [ ] Test data / mocki dostępne lub plan\n  - [ ] Tech Lead potwierdził wykonalność\n```\n\n**DoD (Definition of Done)**\n\n```markdown\n---\nid: \"DEF-DONE-001\"\ntype: \"definition\"\ntitle: \"Definition of Done (DoD)\"\nowner: \"Team Lead / QA\"\nstatus: \"draft\"\ncreated: \"2025-12-24\"\ntags: [\"dod\",\"quality\",\"release\"]\n---\n\n## Definition of Done (DoD)\n\n- Cel: minimalne warunki uznania pracy za ukończoną.\n- Kryteria (przykład):\n  - [ ] Kod zmergowany do branch/main (PR approved)\n  - [ ] Unit + Integration tests green\n  - [ ] E2E / UAT (jeśli wymagane) — passed\n  - [ ] Dokumentacja (API, changelog, runbook) zaktualizowana\n  - [ ] Build artefakt opublikowany/staging deployed + smoke tests\n  - [ ] Security checks / linters completed\n  - [ ] Owner: approval/sign-off (imię, data)\n```\n\n# Praktyczna wskazówka\n\n- Trzymaj **DoR** i **DoD** jako pliki w repo (np. `docs/definitions/Definition_of_Ready.md` i `Definition_of_Done.md`) — wersjonuj i aktualizuj je razem z procesem.\n    \n- W dużych projektach zróżnicuj DoD: _component-level DoD_, _release-level DoD_, _compliance-level DoD_.\n    \n\n---\n","x":1428,"y":-706,"width":852,"height":1250},
		{"id":"9a5e831046d0c857","type":"text","text":"Tak — dokładnie tak, tylko warto to sformalizować krótko i praktycznie.\n\n## Krótkie podsumowanie\n\n- **DoR (Definition of Ready)** — warunki _wejścia_: co musi być spełnione **przed** rozpoczęciem pracy nad itemem (user story, task, change request, epic).\n    \n- **DoD (Definition of Done)** — warunki _wyjścia_: co musi być spełnione **po** wykonaniu pracy, żeby uznać ją za ukończoną i nadającą się do releasu / przekazania dalej.\n    \n- Relacja: **DoR → praca → DoD**. DoR uprawnia do startu; DoD potwierdza, że rezultat spełnia jakość/wymagania i może przejść dalej (np. do release-gate / produkcji).\n    \n\n## Mini-diagram (ASCII)\n\n```\n[Item w backlogu]\n     |\n  (spełnia DoR?)\n     ├─> NIE -> uzupełnić wejścia / TODO → powrót\n     └─> TAK -> start prac\n               |\n            development, testy, dokumentacja\n               |\n         (spełnia DoD?)\n               ├─> NIE -> poprawki / rework\n               └─> TAK -> PR/merge / release readiness -> checkpoint\n```\n\n## Typowe przykłady kryteriów (szybko)\n\n**DoR (co najczęściej musi być):**\n\n- Jasny opis i cel biznesowy (1–2 zdania)\n    \n- Acceptance Criteria (GIVEN/WHEN/THEN)\n    \n- Właściciel biznesowy dostępny do pytań\n    \n- Wstępna estymacja (story points/ideal days)\n    \n- Wykonalność techniczna sprawdzona przez Tech Lead\n    \n- Zidentyfikowane zależności i dostęp do danych/mocków\n    \n\n**DoD (co najczęściej musi być):**\n\n- Kod zmergowany i PR zatwierdzony\n    \n- Wszystkie unit/integration tests green\n    \n- E2E/UAT (jeśli wymagane) — passed\n    \n- Dokumentacja uaktualniona (API, changelog, runbook)\n    \n- Build artefakt dostępny/staging deployed + smoke tests passed\n    \n- Security checks / linters / SAST wykonane\n    \n- Owner podpisał (approval/sign-off)\n    \n\n## Dodatkowe uwagi praktyczne\n\n- **Poziomy**: miej osobne DoR/DoD dla story, epica i releasu (np. „release-DoD” zawiera dodatkowe kryteria operacyjne i compliance).\n    \n- **Checkpointy**: używaj DoR przy planowaniu sprintu / przyjmowaniu worku; używaj DoD przy zamykaniu itemu i przy gate’ach release readiness.\n    \n- **Traceability**: wymagaj, by każde `DoD` było widoczne w PR/issue (checklist w PR) — automatyzuje review.\n    \n- **Proces**: DoR = weryfikacja przed startem; DoD = dowód jakości przed merge/release.\n    \n- **Wersjonowanie**: trzymaj DoR i DoD w repo (`docs/definitions/`), aktualizuj i wersjonuj (PR + approver).\n    \n\n","x":2360,"y":-706,"width":920,"height":1186},
		{"id":"93187c7ba39a51b6","type":"text","text":"\n|# Satelitarne artefakty dokumentacyjne — kanwa opisowa\n\nDokument podsumowuje koncepcję **satelitów dokumentu** — lekkich, atomowych artefaktów towarzyszących głównym dokumentom projektowym (PRD, TDD, Business Case, Feasibility itp.). Zawiera definicje, zasady użycia, rekomendowaną strukturę przechowywania oraz gotowe szablony front‑matter dla najczęściej stosowanych artefaktów.\n\n---\n\n## 1. Cel kanwy\n\n- Ujednolicić sposób tworzenia i przechowywania artefaktów satelitarnych.\n    \n- Zapewnić ślad audytowy i śledzenie zależności między dokumentami.\n    \n- Umożliwić automatyczne generowanie issue/PR skeletonów na podstawie front‑matter.\n    \n\n---\n\n## 2. Co to są „satelity dokumentu”?\n\nSatelity to krótkie, jednozadaniowe lub kilkusekcyjne pliki o niskim koszcie utrzymania, które towarzyszą dużym dokumentom i umożliwiają:\n\n- rozbijanie pracy (TODO per sekcja),\n    \n- formalizację wejścia (DoR) i wyjścia (DoD),\n    \n- zachowanie dowodów (evidence items),\n    \n- rejestr decyzji (ADR/Decision Log),\n    \n- kontrolę zmian (Change Requests, Changelog),\n    \n- formalne zatwierdzenia (Approval records).\n    \n\n---\n\n## 3. Zestawy satelitów — zasada proporcjonalności\n\n- **Minimalny (one‑pager):** TODO, Changelog, Approval.\n    \n- **Standard (dokumenty średniej ważności — PRD, Business Case):** front‑matter dokumentu, TODO per sekcja, DoR (sekcja lub dokument), DoD (document‑level), Review checklist, Approval record, Evidence folder, ADR links, Changelog.\n    \n- **Pełny (dokumenty krytyczne/regulatory/release):** wszystkie powyższe + DPIA fragments, QA test cases, runbook references, audit trail, monitoring plan, legal sign‑off.\n    \n\n---\n\n## 4. Najważniejsze typy satelitów (lista szybkiego dostępu)\n\n- TODO / Action Item\n    \n- DoR (Definition of Ready)\n    \n- DoD (Definition of Done)\n    \n- ADR / Decision Record\n    \n- RFC / Proposal\n    \n- Change Request (CR)\n    \n- Evidence Item (dowód/załącznik)\n    \n- Approval / Sign‑off record\n    \n- Review Checklist\n    \n- RTM fragment (traceability)\n    \n- Test Case / QA Script\n    \n- Runbook entry / Deployment Playbook\n    \n- Postmortem / Incident report\n    \n\n---\n\n## 5. Gdzie przechowywać (konwencja katalogów)\n\nRekomendowana struktura w repozytorium projektu:\n\n```\ndocs/<project>/\n  ├─ <document>.md                # główny dokument z front‑matter\n  ├─ todos/                        # TODO per section (*.md)\n  ├─ approvals/                    # approval records\n  ├─ evidence/                     # załączniki (xlsx/pdf/csv)\n  ├─ adr/                          # ADR entries\n  ├─ qa/                           # test cases, scripts\n  └─ changelog.md\n\ntemplates/atomic/\n  ├─ TODO_template.md\n  ├─ DoR_template.md\n  ├─ DoD_template.md\n  └─ Approval_template.md\n```\n\n---\n\n## 6. Uniwersalny front‑matter (zalecany dla wszystkich atomów)\n\nUżywaj YAML front‑matter, aby umożliwić automatyzację i parsowanie.\n\n```yaml\n---\nid: \"ATOM-<TYPE>-000\"\ntype: \"todo|adr|rfc|cr|decision|meeting|issue|spike|test|checklist|release|incident|risk|approval\"\ntitle: \"Krótki tytuł\"\nowner: \"Imię Nazwisko / Zespół\"\nstatus: \"todo|in-progress|review|blocked|done|approved\"\npriority: \"P0|P1|P2|P3\"\ncreated: \"YYYY-MM-DD\"\ndue: \"YYYY-MM-DD\"         # opcjonalne\nrelated: []                 # lista powiązanych plików / id\napprover: \"\"              # jeśli dotyczy\ntags: []\n---\n```\n\n---\n\n## 7. Typowe szablony (skrót)\n\n**TODO (per section)** — front‑matter + checklista kroków do zamknięcia.  \n**DoR (Definition of Ready)** — lista kryteriów wejścia; weryfikacja przed startem (owner: PO).  \n**DoD (Definition of Done)** — lista kryteriów wyjścia; musi być spełniona przed zamknięciem i przed release (owner: Team/QA).  \n**Approval record** — krótki zapis: kto zatwierdził, data, notatka.\n\n> W kanwie `templates/atomic/` znajdują się pełne wersje tych szablonów gotowe do kopiowania i wypełniania.\n\n---\n\n## 8. Zasady operacyjne / dobre praktyki\n\n1. **Proporcjonalność**: rozbijaj artefakty tylko tam, gdzie wartość przewyższa koszt zarządzania.\n    \n2. **1 problem = 1 atom**: każdy atom powinien rozwiązywać jedną sprawę/kwestię.\n    \n3. **Powiązania**: każde satelitarne id powinno mieć `related` wskazujący dokument główny.\n    \n4. **Automatyzacja**: generuj TODO → issue/PR skeletony automatycznie (skrypt/Jinja2).\n    \n5. **Wersjonowanie i audit**: każda akceptacja (Approval) i decyzja (ADR) musi być commitowana z odwołaniem do PR.\n    \n6. **Checkpoints**: łącz DoR i DoD z checkpointami (go/no‑go, requirements freeze, release readiness, ops handover, closure).\n    \n\n---\n\n## 9. Workflow — przykład szybkiego cyklu dla PRD (praktycznie)\n\n1. Utwórz `DOC-PRD-001.md` (front‑matter + outline).\n    \n2. Wygeneruj `TODO` per sekcja w `docs/<project>/todos/`.\n    \n3. Wypełnij sekcje → PO/AUTHORS uzupełniają treść.\n    \n4. Tech Lead / QA sprawdzają DoR (sekcja/dokument).\n    \n5. Gdy DoR OK → development / review → DoD checklist w PR.\n    \n6. Po spełnieniu DoD → Approval record → publish + changelog update + archiwum evidence.\n    \n\n---\n\n## 10. Automatyzacja (opcje do wdrożenia)\n\n- Generator szablonów Jinja2 (`scripts/render_templates.py`).\n    \n- Action: tworzenie Issue z front‑matter TODO (GitHub Action / CLI).\n    \n- Linter front‑matter (CI check) — walidacja pól `id`, `type`, `owner`, `status`.\n    \n- Raport traceability: CSV/JSON generowany z `related` powiązań.\n    \n\n---\n\n## 11. Kolejne kroki (co mogę wygenerować teraz)\n\n- pełny zestaw plików `templates/atomic/` (DoR, DoD, TODO, Approval, ADR, Spike, Evidence),\n    \n- manifest CSV/JSON z metadanymi (id, nazwa, kategoria, effort_days),\n    \n- przykładowe wypełnienia (demo) dla 3 dokumentów: Executive Summary, PRD, TDD,\n    \n- skrypt Jinja2 do renderowania i GitHub Action do tworzenia issue skeleton.\n    \n\n---\n\n","x":800,"y":720,"width":540,"height":1720},
		{"id":"8ca872a9af93ed3f","type":"text","text":"Zestaw **małych, atomowych artefaktów** podobnych do `TODO`, `DoD`, `ADR` — używanych do śledzenia decyzji, zadań, eksperymentów i dowodów. Poniższa listazawiera zwięzłą, praktyczną listę takich typów (opis + kiedy używać) oraz **uniwersalny front-matter** i rekomendowaną ścieżkę przechowywania. \n\n---\n\n# Najważniejsze „atomowe” artefakty (krótko)\n\n1. **TODO / Task**  \n    Krótkie zadanie z ownerem, kryteriami akceptacji. Używaj do rozbijania dokumentów i prac. _(jednorazowe / backlog)_\n    \n2. **DoD — Definition of Done**  \n    Zestaw kryteriów, które muszą być spełnione by uznać pracę za zakończoną (feature / dokument / release). _(ciągłe, przypisane do scope)_\n    \n3. **ADR — Architecture Decision Record**  \n    Krótka karta decyzji architektonicznej: kontekst → opcje → decyzja → konsekwencje. _(ciągłe)_\n    \n4. **RFC — Request for Comments / Proposal**  \n    Propozycja zmiany (funkcja, architektura) z zaproszeniem do dyskusji i terminem feedbacku. _(jednorazowe, przed decyzją)_\n    \n5. **Change Request (CR)**  \n    Formalne żądanie zmiany zakresu/scopeu z oceną wpływu i decyzją aprobaty. _(przed/po decyzji)_\n    \n6. **Decision Log (Decision Record)**  \n    Centralny log wszystkich istotnych decyzji (krótkie wpisy, cross-reference do ADR/RFC). _(ciągłe)_\n    \n7. **Action Item**  \n    Krótkie działanie wynikające ze spotkania/retrospektywy z ownerem i deadlinem. _(jednorazowe)_\n    \n8. **Meeting Minutes / Notes**  \n    Zapis spotkania: decyzje, action items, follow-ups. _(jednorazowe / archiwum)_\n    \n9. **Issue / Bug Report**  \n    Strukturalny opis problemu: kroki reprodukcji, oczekiwany vs rzeczywisty rezultat, severity. _(operacyjne)_\n    \n10. **Spike / Research Note**  \n    Krótki raport z eksperymentu/prototypu: cel, co testowano, wnioski, rekomendacja. _(krótkie R&D)_\n    \n11. **Design Note / LDD (Lightweight Design Doc)**  \n    Szybka notatka projektowa (component sketch, trade-offs) — mniej formalna niż TDD. _(przed implementacją)_\n    \n12. **Acceptance Criteria Card**  \n    Samodzielny zapis kryteriów akceptacji dla pojedynczego user story/sekcji PRD. _(łatwe mapowanie do RTM)_\n    \n13. **Test Case / Test Script**  \n    Konkretne kroki testowe + dane wejściowe + oczekiwany rezultat. _(QA)_\n    \n14. **Checklist (np. Release / Pre-deploy)**  \n    Punktowana lista kroków do wykonania przed wydarzeniem (wydanie, audyt, wdrożenie). _(operacyjne)_\n    \n15. **Release Note / Changelog Entry**  \n    Krótkie podsumowanie zmian w danym release (co, wpływ, migration notes). _(komunikacja)_\n    \n16. **Deployment Playbook / Runbook Entry**  \n    Konkretna procedura wdrożeniowa/operacyjna dla jednego komponentu. _(operacyjne)_\n    \n17. **Incident Report / Postmortem (light)**  \n    Krótkie RCA: co się stało, root cause, akcje naprawcze, owner. _(po incydencie)_\n    \n18. **Risk Register Item / RAID entry**  \n    Pojedynczy rekord ryzyka (opis, likelihood, impact, mitigations, owner). _(governance)_\n    \n19. **RACI / Responsibility Note**  \n    Krótkie przypisanie ról dla konkretnego deliverable (Responsible / Accountable / Consulted / Informed). _(governance)_\n    \n20. **Approval / Sign-off Record**  \n    Krótki dowód zatwierdzenia (kto, kiedy, na jakich warunkach) — używany przy checkpointach. _(formalność)_\n    \n21. **Feature Flag Doc / Toggle Note**  \n    Deklaracja flagi: owner, rollout policy, metrics, kill-switch. _(operacyjne)_\n    \n22. **API Contract Stub / Schema Note**  \n    Minimalny opis kontraktu API (endpoint, request/response, status codes) — do szybkich integracji. _(integration)_\n    \n23. **Onboarding Checklist (dla nowego modułu / deva)**  \n    Kroki startowe: repo, env, access, sample data. _(operacyjne / people ops)_\n    \n24. **Compliance Evidence Item**  \n    Krótki artefakt-dowód wymagany przy audycie (np. wynik testu, log audytowy, certyfikat). _(compliance)_\n    \n\n---\n\n# Uniwersalny, zalecany front-matter (używaj we wszystkich atomowych plikach)\n\n```yaml\n---\nid: \"ATOM-XXXX-001\"\ntype: \"todo|adr|rfc|cr|decision|meeting|min|issue|spike|test|checklist|release|incident|risk|raci|approval|flag|api|onboarding|evidence\"\ntitle: \"Krótki tytuł\"\nowner: \"Imię Nazwisko / zespół\"\nstatus: \"todo|in-progress|review|blocked|done|approved\"\npriority: \"P0|P1|P2|P3\"\ncreated: \"YYYY-MM-DD\"\ndue: \"YYYY-MM-DD\"         # opcjonalne\nrelated: []               # lista plików / id powiązanych artefaktów\napprover: \"\"              # kto zatwierdza (jeśli dotyczy)\ntags: []\n---\n```\n\n---\n\n# Rekomendowana struktura przechowywania (porządek)\n\n- `docs/atomic/todos/` — TODO, Action Items\n    \n- `docs/atomic/decisions/` — ADRs, Decision Log, Approvals\n    \n- `docs/atomic/proposals/` — RFC, Change Requests\n    \n- `docs/atomic/meetings/` — Meeting Minutes, Action Items\n    \n- `docs/atomic/incidents/` — Incident Report, Postmortem\n    \n- `docs/atomic/qa/` — Test Cases, Test Scripts, Checklists\n    \n- `docs/atomic/compliance/` — Evidence items, DPIA snippets\n    \n- `docs/atomic/integration/` — API stubs, Feature Flag notes\n    \n\n---\n\n# Krótkie zasady użycia / dobre praktyki\n\n- **Lekkość**: każdy atom to 1 problem/1 decyzja/1 zadanie — nie mieszaj kilku rzeczy w jednym pliku.\n    \n- **Identyfikacja**: stały prefiks ID (np. `TODO-`, `ADR-`, `RFC-`, `INC-`) ułatwia śledzenie.\n    \n- **Powiązania**: pole `related` linkuje do PRD/TDD/RTM/etc. — automatycznie tworzy ślad audytowy.\n    \n- **Wersjonowanie**: używaj `status` + `approver` do formalnych checkpointów.\n    \n- **Automatyzacja**: generator TODO → tworzy issue/PR skeletony w systemie pracy (GitHub/Jira).\n    \n\n---\n","x":1600,"y":674,"width":600,"height":1252},
		{"id":"695fc6d1ebdf5b03","x":1000,"y":-2140,"width":640,"height":1120,"type":"text","text":"# Szablony — Roadmapy i satelitarne artefakty\n\nTo jest komplet szablonów i artefaktów pomocniczych (\"satelitów\"), gotowych do skopiowania do struktury Twojego repozytorium. Pliki są przygotowane tak, aby ułatwić zarządzanie roadmapami, planowaniem wydań oraz powiązaną dokumentacją operacyjną i compliance.\n\n**Zestaw zawiera:**\n\n- `templates/roadmaps/` — główny szablon roadmapy oraz powiązane artefakty: capacity plan, risk register, release checklist, postmortem, KPI spec.\n- `templates/atomic/` — lekkie, atomowe pliki (TODO, DoR, DoD, Approval, Evidence, Risk Item, Release checklist — atom, Postmortem — atom itd.).\n- `manifests/` — przykładowe manifesty CSV i JSON z metadanymi plików (importowalne do narzędzi PM).\n\nSkopiuj wybrane pliki do odpowiednich katalogów (np. `docs/<project>/roadmaps/` lub `templates/roadmaps/`) i edytuj front‑matter zgodnie z projektem.\n\n---\n\n## Główne zasady użycia\n\n1. **Proporcjonalność**: stosuj satelity tylko tam, gdzie ich wartość uzasadnia koszt utrzymania.  \n2. **Jedno zadanie = jeden atom**: każdy plik atomowy powinien dotyczyć jednej sprawy (TODO, ADR, CR, Evidence itp.).  \n3. **Traceability**: używaj front‑matter `related` do wiązania artefaktów z dokumentem głównym.  \n4. **Automatyzacja**: front‑matter pozwala na generowanie issue/PR skeletonów i walidację CI.  \n5. **Wersjonowanie**: trzymaj dokumenty w repo, każda akceptacja i decyzja powinna mieć commit/PR.\n\n---\n\n# Szablony: Roadmaps (katalog `templates/roadmaps/`)\n\nPoniżej znajdują się kompletne, gotowe do użycia pliki markdown. Zachowaj front‑matter i dostosuj pola `project`, `owner`, `date_created` itp.\n\n### `roadmap.product.md`\n```markdown\n---\nid: \"ROADMAP-PROD-001\"\ntitle: \"Product Roadmap — H1 2026\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Head of Product\"\nstatus: \"draft\"          # draft|in-review|approved|archived\nversion: \"0.1\"\ndate_created: \"YYYY-MM-DD\"\nlast_modified: \"YYYY-MM-DD\"\nhorizon: \"12 months\"\nrelated_docs: [\"DOC-BUSCASE-001\",\"DOC-PRD-001\"]\ntags: [\"roadmap\",\"product\",\"release\"]\napprovers: [\"CEO\",\"CPO\"]\n---\n\n# Product Roadmap — H1 2026\n\n## 0. Meta\n- **Project:** NAZWA_PROJEKTU\n- **Owner:** Head of Product\n- **Status:** draft\n- **Version:** 0.1\n\n## 1. Context & Strategic goal\n- Krótkie podsumowanie kontekstu i celów strategicznych (powiązanie z OKR/KPIs):\n  - OKR-1: ...\n  - KPI: ...\n\n## 2. Roadmap swimlanes (high‑level)\n| Horizon | Focus | Key outcomes |\n|---|---|---|\n| Strategic (2–5y) | Platform growth | ... |\n| Product (12m) | Core features | ... |\n| Release (3–6m) | Release X | ... |\n| Tactical (sprint) | Iteration delivery | ... |\n\n## 3. Milestones & Releases\n- **Release 1 (M1)** — YYYY‑MM‑DD — scope: Epics A, B\n- **Release 2 (M2)** — YYYY‑MM‑DD — scope: Epics C\n\n## 4. Epics / Feature sets (skrót)\n- **EPIC‑001:** Tytuł — Owner — Priorytet — Hipoteza wartości\n  - DoR: link/todo\n  - Dependencies: EPIC‑003\n\n## 5. Dependencies & Blockers\n- External vendor X: opis zależności\n- Regulatory approval Y: spodziewana data\n\n## 6. Risks (top items) — link do `risk-register.md`\n- R1: opis ryzyka — owner — mitigacje\n\n## 7. Capacity & Budget summary — link do `capacity-plan.md`\n- FTE needed: 5 devs for 3 months\n- Budget: EUR 100k\n\n## 8. KPIs & success metrics\n- Metric A: target\n- Metric B: target\n\n## 9. Checkpoints & Gates\n- Quarterly strategic review (data)\n- Pre‑freeze DoR check (data)\n- Pre‑release DoD verification (data)\n\n## 10. Communication / Stakeholders\n- Weekly: Product Sync (owners)\n- Monthly: Exec update (CPO/CEO)\n\n## 11. Links & evidence\n- Business Case: DOC‑BUSCASE‑001\n- RTM: docs/rtm.csv\n\n---\n*Suggested length: 2–6 pages. Keep the roadmap high‑level and link do szczegółowych artefaktów.*\n```\n\n---\n\n### `capacity-plan.md`\n```markdown\n---\nid: \"CAP-PLAN-001\"\ntitle: \"Capacity Plan — H1 2026\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Delivery Manager\"\nversion: \"0.1\"\nstatus: \"draft\"\nrelated: [\"ROADMAP-PROD-001\"]\n---\n\n# Capacity Plan — H1 2026\n\n## Summary\n- Dostępne zasoby: 12 FTE (engineering)\n- Dostępne godziny kontraktorskie: 800h\n\n## Assumptions\n- Okna urlopowe: ...\n- Rezerwa (bench): 10%\n\n## Demand by milestone\n| Milestone | Effort (FTE months) | Owner |\n|---|---:|---|\n| Release 1 | 5.0 | Delivery Lead |\n| Release 2 | 3.0 | Delivery Lead |\n\n## Gaps & mitigation\n- Luka: potrzebne +2 backend devs → plan: zatrudnienie / contractor\n\n## Notes\n- Aktualizować co miesiąc i synchronizować z finansami.\n```\n\n---\n\n### `risk-register.md`\n```markdown\n---\nid: \"RISK-REGISTER-001\"\ntitle: \"Roadmap Risk Register\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Head of Product\"\nversion: \"0.1\"\nstatus: \"live\"\nrelated: [\"ROADMAP-PROD-001\"]\n---\n\n# Risk Register (roadmap‑level)\n\n| ID | Risk description | Likelihood | Impact | Severity | Owner | Mitigation | Status |\n|---|---|---:|---:|---:|---|---|---|\n| R‑001 | Regulatory approval delay | Medium | High | High | Legal Lead | Early engagement; contingency plan | Open |\n| R‑002 | Vendor integration fails | Low | Medium | Medium | Integration Lead | PoC first; fallback option | Open |\n\n---\n\nAktualizuj ten plik na bieżąco — każdy wiersz to pojedynczy RAID item.\n```\n\n---\n\n### `release-checklist.md`\n```markdown\n---\nid: \"REL-CHECK-001\"\ntitle: \"Release Checklist — Release 1\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Release Manager\"\nversion: \"0.1\"\nstatus: \"draft\"\nrelated: [\"ROADMAP-PROD-001\"]\n---\n\n# Release Checklist — Release 1\n\n## Pre‑freeze\n- [ ] All critical PRs merged into release branch\n- [ ] DoR check for all epics: passed\n- [ ] Release notes: draft\n\n## Pre‑release\n- [ ] QA smoke tests green on staging\n- [ ] Security scans (SAST/DAST) passed\n- [ ] DB migration scripts reviewed and rollback tested\n- [ ] Ops runbook updated\n\n## Release window\n- [ ] Cutover: run idempotent deploy script\n- [ ] Smoke tests on production passed\n- [ ] Monitoring thresholds verified\n\n## Post‑release\n- [ ] Postmortem scheduled\n- [ ] Stakeholder communication sent\n- [ ] Changelog published\n```\n\n---\n\n### `postmortem_template.md`\n```markdown\n---\nid: \"POST-001\"\ntitle: \"Postmortem — Release 1\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Incident Lead\"\nversion: \"0.1\"\nstatus: \"draft\"\nrelated: [\"REL-CHECK-001\",\"ROADMAP-PROD-001\"]\n---\n\n# Postmortem — Release 1\n\n## Summary\n- What happened (brief):\n\n## Impact\n- Users affected, metrics, outage duration\n\n## Timeline\n- YYYY‑MM‑DD HH:MM — Event\n- YYYY‑MM‑DD HH:MM — Event\n\n## Root cause\n- Summary of root cause\n\n## Remediation & Actions\n- Action 1 — owner — due date\n- Action 2 — owner — due date\n\n## Lessons learned\n- Bullet points\n\n## Follow‑ups\n- Tracking in TODOs / issue tracker\n```\n\n---\n\n### `kpi-dashboard-spec.md`\n```markdown\n---\nid: \"KPI-001\"\ntitle: \"KPI & Dashboard Spec\"\nproject: \"NAZWA_PROJEKTU\"\nowner: \"Product Ops\"\nversion: \"0.1\"\nstatus: \"draft\"\nrelated: [\"ROADMAP-PROD-001\"]\n---\n\n# KPI & Dashboard Spec\n\n## Metrics\n- % complete (by epic) — metoda pomiaru\n- Delivered value vs forecast — metoda pomiaru\n- Lead time for features — definicja\n\n## Dashboards\n- Exec dashboard: metrics & SLA\n- Delivery dashboard: progress per release\n\n## Data sources\n- Data warehouse tables, ETL jobs\n```\n\n---\n\n# Szablony atomowe: `templates/atomic/`\n\nAtomowe, lekkie pliki są przeznaczone do szybkiego tworzenia i powiązania z głównymi dokumentami. Wykorzystaj je jako pojedyncze, wersjonowane artefakty.\n\n### `TODO_template.md`\n```markdown\n---\nid: \"TODO-<DOC>-001\"\ntype: \"todo\"\ntitle: \"<Short title>\"\nowner: \"<Name / Team>\"\nstatus: \"todo\"\npriority: \"P1\"\ncreated: \"YYYY-MM-DD\"\ndue: \"YYYY-MM-DD\"\nrelated: [\"DOC-<id>\"]\nacceptance_criteria: []\n---\n\n# TODO: <Short title>\n\n## Description\n- Krótki opis zadania\n\n## Checklist\n- [ ] Krok 1\n- [ ] Krok 2\n\n## Notes / Links\n- Link do źródeł\n```\n\n---\n\n### `DoR_template.md` (Definition of Ready)\n```markdown\n---\nid: \"DEF-READY-<DOC>-001\"\ntype: \"definition\"\ntitle: \"Definition of Ready — <DOC>\"\nowner: \"Product Owner\"\nstatus: \"draft\"\ncreated: \"YYYY-MM-DD\"\nrelated: [\"DOC-<id>\"]\n---\n\n# Definition of Ready (DoR)\n\n## Purpose\n- Kryteria wejścia przed rozpoczęciem prac\n\n## Criteria (example)\n- [ ] Description and business goal\n- [ ] Acceptance Criteria (GIVEN/WHEN/THEN)\n- [ ] Estimation (story points)\n- [ ] Owner available\n- [ ] Dependencies listed\n- [ ] Test data / mocks available\n- [ ] Tech Lead checked feasibility\n```\n\n---\n\n### `DoD_template.md` (Definition of Done)\n```markdown\n---\nid: \"DEF-DONE-<DOC>-001\"\ntype: \"definition\"\ntitle: \"Definition of Done — <DOC>\"\nowner: \"Team Lead / QA\"\nstatus: \"draft\"\ncreated: \"YYYY-MM-DD\"\nrelated: [\"DOC-<id>\"]\n---\n\n# Definition of Done (DoD)\n\n## Purpose\n- Kryteria uznania pracy za zakończoną\n\n## Criteria (example)\n- [ ] Code merged to main/release branch\n- [ ] Unit and integration tests green\n- [ ] E2E / UAT (if required) passed\n- [ ] Documentation updated (API, runbook)\n- [ ] Build artifact published / staging smoke tests passed\n- [ ] Security checks / linters passed\n- [ ] Owner approval / sign-off\n```\n\n---\n\n### `Approval_template.md`\n```markdown\n---\nid: \"APPROVAL-<DOC>-001\"\ntype: \"approval\"\ntitle: \"Approval — <DOC> v0.1\"\napprover: \"Name\"\ndate: \"YYYY-MM-DD\"\nrelated: [\"DOC-<id>\"]\nnotes: \"\"\n---\n\n# Approval\n\n- **Approver:** Name\n- **Date:** YYYY-MM-DD\n- **Notes:** Short notes\n```\n\n---\n\n### `evidence_template.md`\n```markdown\n---\nid: \"EVID-<DOC>-001\"\ntype: \"evidence\"\ntitle: \"Evidence — <DOC>\"\nowner: \"Owner\"\nrelated: [\"DOC-<id>\"]\n---\n\n# Evidence\n\n- **File:** path/to/file.xlsx\n- **Description:** what it proves and where used\n- **Hash / checksum:** optional\n```\n\n---\n\n### `risk_item_template.md`\n```markdown\n---\nid: \"RISK-<DOC>-001\"\ntype: \"risk\"\ntitle: \"Risk item\"\nowners: [\"Name\"]\nlikelihood: \"Low|Medium|High\"\nimpact: \"Low|Medium|High\"\nstatus: \"open|mitigating|closed\"\nrelated: [\"DOC-<id>\"]\n---\n\n# Risk item\n\n- Description: ...\n- Mitigation: ...\n- Owner: ...\n```\n\n---\n\n### `release_checklist_atom.md`\n```markdown\n---\nid: \"REL-ATOM-001\"\ntype: \"checklist\"\ntitle: \"Release Checklist — atom\"\nrelated: [\"REL-CHECK-001\"]\n---\n\n# Release checklist (atom)\n- [ ] Smoke tests passed\n- [ ] Monitoring configured\n- [ ] Rollback verified\n```\n\n---\n\n### `postmortem_atom.md`\n```markdown\n---\nid: \"PM-ATOM-001\"\ntype: \"postmortem\"\ntitle: \"Postmortem — atom\"\nrelated: [\"POST-001\"]\n---\n\n# Postmortem (atom)\n- Summary:\n- Timeline:\n- Root cause:\n- Actions:\n```\n\n---\n\n# Manifests\n\n### `manifests/manifest.csv` (przykład)\n```csv\nid,filename,category,owner,estimated_days,related\nROADMAP-PROD-001,templates/roadmaps/roadmap.product.md,roadmap,Head of Product,3,DOC-BUSCASE-001\nREL-CHECK-001,templates/roadmaps/release-checklist.md,release,Release Manager,1,ROADMAP-PROD-001\nTODO-<DOC>-001,templates/atomic/TODO_template.md,todo,Team,0.1,DOC-<id>\n```\n\n\n### `manifests/manifest.json` (przykład)\n```json\n[\n  {\"id\":\"ROADMAP-PROD-001\",\"filename\":\"templates/roadmaps/roadmap.product.md\",\"category\":\"roadmap\",\"owner\":\"Head of Product\",\"estimated_days\":3},\n  {\"id\":\"REL-CHECK-001\",\"filename\":\"templates/roadmaps/release-checklist.md\",\"category\":\"release\",\"owner\":\"Release Manager\",\"estimated_days\":1}\n]\n```\n\n---\n\n## Opcjonalny skrypt — `scripts/render_templates.py` (stub)\n\n```python\n# render_templates.py — minimalny stub do renderowania Jinja2 templates\nfrom jinja2 import Environment, FileSystemLoader\nimport yaml\n\nenv = Environment(loader=FileSystemLoader('templates'))\n\ndef render(template_path, context_path, out_path):\n    template = env.get_template(template_path)\n    with open(context_path) as f:\n        ctx = yaml.safe_load(f)\n    rendered = template.render(**ctx)\n    with open(out_path, 'w') as o:\n        o.write(rendered)\n\nif __name__ == '__main__':\n    # example usage: render('roadmaps/roadmap.product.md', 'data/meta.yaml', 'docs/project/roadmap.md')\n    pass\n```\n\n---\n\n## Co zrobiłem\n- Przygotowałem komplet szablonów do skopiowania — roadmapy + satelity atomowe + manifesty + prosty stub skryptu do renderowania.\n\n## Co chcesz teraz?\n- Mogę:\n  1) Wykonać i umieścić te pliki bezpośrednio w kanwie `templates/` (utworzyć osobne pliki),\n  2) Wygenerować przykładowe wypełnienia (demo) dla Executive Summary, PRD, Roadmap (czy chcesz konkretny projekt jako przykład?),\n  3) Przygotować GitHub Action / CI snippet do walidacji front‑matter i tworzenia issue skeletons z TODOs.\n\nWskaż 1 / 2 / 3 lub kombinację (np. 1+2).\n"},
		{"id":"e6978dc9112d50d5","type":"text","text":"Poniżej masz spójny, sposób przygotowania **biblioteki szablonów + walidatorów**, tak żeby dokumentacja była:\n\n- jednolita jakościowo,\n    \n- „failure-driven” (pokazuje _co blokuje_ i _co trzeba zrobić_),\n    \n- automatycznie sprawdzalna (braki, sprzeczności, brak danych, brak zależności, brak dowodów).\n    \n\n---\n\n## 1) Jak wyciągnąć dokumenty do jednolitej jakości\n\n### A. Jeden kontrakt formatu dla wszystkich dokumentów\n\nKażdy `.md` ma:\n\n- **YAML front-matter** z metadanymi (id, type, status, owner, version, related, gates).\n    \n- Stałe **nagłówki sekcji** (łatwe do parsowania).\n    \n- Sekcję **Evidence/Źródła** (nawet jeśli pusta — ma istnieć).\n    \n- Sekcję **Open questions / Assumptions** (żeby brak danych był jawny, nie ukryty).\n    \n\n**Minimalny front-matter (przykład):**\n\n```yaml\n---\nid: \"DOC-PRD-001\"\ntype: \"PRD\"          # typ dokumentu\nstatus: \"draft\"      # draft|review|approved\nowner: \"PO\"\nversion: \"0.3\"\nproject: \"CLIENT_X\"\nrelated:\n  - \"DOC-BUSCASE-001\"\ngates:\n  - \"GATE-REQ-FREEZE\"\nsources_of_truth:\n  - \"docs/_meta/project.yaml\"\n---\n```\n\n### B. Jedna „house style guide” (Twoja jakość)\n\n- nazwy sekcji i kolejność,\n    \n- styl: krótko, jednoznacznie, bez lania wody,\n    \n- obowiązkowe: definicje pojęć, ID, wersjonowanie, evidence.\n    \n\n### C. Jedna definicja jakości (DoD dla dokumentów)\n\nDla dokumentów (nie dla kodu):\n\n- brak placeholderów („…”, „TBD”),\n    \n- wszystkie sekcje wymagane obecne,\n    \n- wszystkie twierdzenia krytyczne mają evidence,\n    \n- dokument ma review + approval (jeśli to gate),\n    \n- cross-links do zależnych dokumentów istnieją.\n    \n\n---\n\n## 2) Jak napisać pliki kodowe, które sygnalizują braki i blokady\n\nBudujesz 4 elementy (to jest minimalny dojrzały zestaw):\n\n### A. **Parser**\n\n- czyta front-matter YAML,\n    \n- mapuje nagłówki `#`, `##`, `###`,\n    \n- wykrywa placeholdery (`TBD`, `...`, `<fill>`) i puste sekcje.\n    \n\n### B. **Registry / Spec dokumentów**\n\nJedno źródło prawdy: _jakie sekcje musi mieć typ PRD/TDD/Business Case itd._ oraz jakie ma zależności.\n\nPrzykład specyfikacji typu (YAML):\n\n```yaml\nPRD:\n  required_sections:\n    - \"Cel produktu\"\n    - \"Zakres\"\n    - \"Wymagania funkcjonalne\"\n    - \"Wymagania niefunkcjonalne\"\n    - \"Kryteria akceptacji\"\n    - \"Ryzyka\"\n    - \"Źródła / Evidence\"\n  required_meta:\n    - \"id\"\n    - \"type\"\n    - \"status\"\n    - \"owner\"\n    - \"version\"\n  dependencies:\n    - type: \"Business_Case\"\n      gate: \"GATE-REQ-FREEZE\"\n```\n\n### C. **Validator / Rules engine**\n\nWaliduje na poziomach:\n\n- **L0**: format (front-matter, ID, wersja).\n    \n- **L1**: struktura (sekcje).\n    \n- **L2**: kompletność (placeholdery, puste sekcje, brak evidence).\n    \n- **L3**: zależności (brak dokumentu, brak approval, gate zablokowany).\n    \n- **L4**: spójność cross-doc (sprzeczności).\n    \n\n### D. **Reporter (najważniejsze)**\n\nGeneruje raport „failure-driven”:\n\n- _co blokuje gate i dlaczego_,\n    \n- _który dokument/sekcja_,\n    \n- _co zrobić dalej_ (remediation).\n    \n\n---\n\n## 3) Jakie błędy powinien „wywalać” system, żeby było czytelnie\n\nZamiast „brak sekcji w pliku X” użyj standardu:\n\n### A. Klasy błędów + kody\n\n- **E100** Missing file (brak wymaganego dokumentu)\n    \n- **E110** Missing section (brak sekcji)\n    \n- **E120** Placeholder present (sekcja istnieje, ale pusta / TBD)\n    \n- **E130** Missing evidence (twierdzenie bez dowodu)\n    \n- **E140** Missing dependency link (related nie wskazuje na wymagany doc)\n    \n- **E150** Gate blocked (nie można iść dalej)\n    \n- **E160** Approval missing (status/approver nie spełnia wymagań)\n    \n- **E200** Contradiction (sprzeczność danych)\n    \n- **E210** ID collision (duplikat ID)\n    \n- **Wxxx** warnings (np. styl, brak recommended section)\n    \n\n### B. Format komunikatu (ważne)\n\nKomunikat ma zawsze:\n\n- kod, severity,\n    \n- dokument + typ + ścieżka,\n    \n- sekcja (jeśli dotyczy),\n    \n- gate (jeśli blokuje),\n    \n- wymagane działanie.\n    \n\nPrzykład:\n\n> **E150 (BLOCKER)**: `docs/clientX/PRD.md` (PRD) — brak `Kryteria akceptacji`.  \n> **Blokuje:** `GATE-REQ-FREEZE`.  \n> **Naprawa:** dodaj sekcję `## Kryteria akceptacji` + min. 5 AC + link do RTM.\n\nTo jest dokładnie ten „szablon błędu”, o który Ci chodzi.\n\n---\n\n## 4) Sygnalizowanie „braku wszystkich informacji” (nie tylko brak sekcji)\n\nTu robi się „walidację semantyczną”:\n\n### A. Placeholdery\n\nSekcja jest, ale zawartość to:\n\n- `TBD`, `...`, `<fill>`, „do uzupełnienia” → **E120**.\n    \n\n### B. Minimalne pola w sekcji\n\nNp. `Business Case` musi mieć:\n\n- 3 scenariusze,\n    \n- założenia,\n    \n- wnioski,\n    \n- evidence (arkusz).\n    \n\nJeśli brakuje jednego elementu → **E121** „Section incomplete”.\n\n### C. „Evidence requirement”\n\nJeżeli w tekście jest liczba / obietnica:\n\n- „rynek 2B USD”, „ROI 18%”, „czas 3 miesiące”  \n    to musi być link do źródła w `evidence/` → inaczej **E130**.\n    \n\n---\n\n## 5) Sygnalizowanie sprzeczności z innymi dokumentami\n\nNajprościej i najczytelniej:\n\n### A. Zdefiniuj „Single Source of Truth” dla faktów\n\nNp. `docs/_meta/project.yaml` jest źródłem:\n\n- nazwy projektu,\n    \n- wersji,\n    \n- KPI,\n    \n- budżetu bazowego.\n    \n\n### B. Każdy dokument deklaruje, jakie fakty „claimuje”\n\nW front-matter:\n\n```yaml\nfacts:\n  budget_total_eur: 100000\n  target_release_date: \"2026-03-31\"\n```\n\nValidator zbiera wszystkie `facts` i wykrywa konflikty:\n\n- PRD mówi „release Q2”, Roadmap mówi „Q1” → **E200** z oboma źródłami.\n    \n\n### C. Reguły spójności\n\n- `project` w front-matter musi być identyczny,\n    \n- `version` nie może cofać się,\n    \n- daty milestone nie mogą być wcześniejsze niż gate,\n    \n- budżet w Business Case musi odpowiadać Financial Plan.\n    \n\n---\n\n## 6) Czy każdy plik ma mieć własny słownik reguł/semantyki?\n\n**Nie każdy plik.** Dojrzałe podejście to:\n\n- **core rules** wspólne dla wszystkich (format, ID, placeholdery, evidence),\n    \n- **rules per typ dokumentu** (PRD/TDD/Business Case…),\n    \n- **opcjonalne ruleset branżowe** jako plugin (HIPAA/PCI/MDR), uruchamiane tylko gdy `compliance:` to zawiera.\n    \n\nTo jest klucz do obsługi wielu domen klientów bez chaosu.\n\n---\n\n## 8) Czego jeszcze nie wymieniłeś, żeby system „pokazywał porażki” i wymuszał poprawne wykonanie\n\nŻeby to działało jako narzędzie prowadzenia projektu „co się nie udało i co trzeba zrobić”, potrzebujesz jeszcze:\n\n1. **Gate registry** (lista gate’ów + co je odblokowuje)\n    \n    - np. `GATE-REQ-FREEZE` wymaga: PRD approved + RTM draft + DoR met.\n        \n2. **Blocker register** (automatycznie generowany)\n    \n    - „Top 10 blockerów” z linkami do dokumentów i remediacji.\n        \n3. **Doc graph (zależności)**\n    \n    - graf: dokument → zależności → gate.\n        \n4. **Approval model**\n    \n    - kto ma prawo zatwierdzać co (role: PO/CFO/DPO/Security Lead).\n        \n5. **Evidence index**\n    \n    - spis plików dowodowych + gdzie są użyte.\n        \n6. **Traceability** jako standard (RTM / mapping)\n    \n    - PRD → Test Cases → Release.\n        \n7. **Kontrakt outputów (to co zrobiłeś dla sprintu)** również dla dokumentów\n    \n    - dokument musi produkować output: „można złożyć grant / można wejść w implementację / można iść na release”.\n        \n\n---\n\n## Minimalna struktura repo (która to spina)\n\n```\ndocs/\n  _meta/\n    project.yaml\n    gates.yaml\n    glossary.md\n  specs/\n    doc_types.yaml\n    rulesets/\n      base.yaml\n      healthcare.yaml\n      fintech.yaml\nscripts/\n  doc_parse.py\n  doc_validate.py\n  doc_report.py\nreports/\n  blockers.md\n  quality.md\n  graph.json\n```\n\n---\n\nJeżeli chcesz, kolejnym krokiem (najbardziej sensownym) jest:  \n**napisać `doc_types.yaml` + `gates.yaml` jako źródło prawdy**, bo wtedy validator może:\n\n- wykrywać braki,\n    \n- wyliczać blokady gate’ów,\n    \n- dawać remediacje w szablonie błędu.\n    \n\nJeśli powiesz „tak”, przygotuję Ci **gotowe szkielety `doc_types.yaml` i `gates.yaml`** (w Markdown/YAML, do wrzucenia do `docs/specs/` i `docs/_meta/`) wraz z przykładowymi regułami dla 5 najważniejszych dokumentów (Executive Summary, Business Case, Roadmap, PRD, TDD).","x":3440,"y":-673,"width":600,"height":2740},
		{"id":"7eec4a2b57fa5b9e","type":"text","text":"Tak — jest kilka elementów, o których jeszcze nie powiedzieliśmy, a które **domykają** podejście „dojrzałe i failure-driven” (czyli nie raport _co wyszło_, tylko _co blokuje i co trzeba zrobić_). Poniżej najważniejsze brakujące klocki.\n\n---\n\n## 1) Lifecycle dokumentów i stanów formalnych\n\nŻeby walidator wiedział, co jest „gotowe”, musisz mieć spójny **model stanów** dla każdego dokumentu i artefaktu:\n\n- `draft → in-review → approved → archived` (+ opcjonalnie `blocked`)\n    \n- reguły przejść (kto może zmienić status, jakie warunki muszą być spełnione)\n    \n- minimalny zestaw pól: `owner`, `reviewers`, `approver`, `approved_at`, `version`\n    \n\nTo daje walidatorowi realną logikę „blokuje gate, bo nie ma approver/sign-off”, a nie tylko „brak sekcji”.\n\n---\n\n## 2) System wyjątków (waiver / risk acceptance)\n\nW dojrzałych systemach zawsze są wyjątki. Bez tego walidacja stanie się „religią”, a nie narzędziem.\n\n- plik typu: `waivers.yaml` / `exceptions.md`\n    \n- każdy wyjątek ma: **ID reguły**, **powód**, **kto zatwierdził**, **termin ważności**\n    \n- walidator rozróżnia: _błąd do naprawy_ vs _zaakceptowane odstępstwo_\n    \n\nTo pozwala pracować bez paraliżu, ale nadal audytowalnie.\n\n---\n\n## 3) Claim → Evidence (mapowanie tez do dowodów)\n\nTo jest fundament „profesjonalnej dokumentacji dla grantów/inwestorów”.\n\n- każda krytyczna teza/liczba ma swój **dowód** w `evidence/`\n    \n- dodatkowo: `evidence-index.md` (spis dowodów + gdzie są użyte)\n    \n- opcjonalnie: hash pliku dowodowego (provenance)\n    \n\nWalidator wtedy nie raportuje „brak informacji”, tylko:\n\n> **E130**: teza o ROI bez dowodu → dodaj evidence lub oznacz jako założenie.\n\n---\n\n## 4) Facts store (jedno źródło prawdy dla wartości globalnych)\n\nŻeby wykrywać sprzeczności i nie powielać danych:\n\n- `docs/_meta/facts.yaml` jako single source of truth (budżet, daty, KPI, nazwy, definicje)\n    \n- dokumenty w front-matter mogą deklarować `facts_used:` lub `facts_claimed:`\n    \n- walidator porównuje claimy i wykrywa konflikty (**E200** z wskazaniem źródeł)\n    \n\nBez tego sprzeczności będą „niewidzialne”.\n\n---\n\n## 5) Profile branżowe jako pluginy reguł\n\nPonieważ obsługujesz wielu klientów z różnych dziedzin:\n\n- core rules (wspólne) + ruleset per typ dokumentu + ruleset per branża (HIPAA/PCI/MDR)\n    \n- aktywacja przez `compliance: [...]` w front-matter\n    \n\nBez profili kończysz z „pojedynczym potworem reguł”, którego nie da się utrzymać.\n\n---\n\n## 6) Gate registry (bramki) + gate impact jako mechanika sterująca\n\nTo, co realnie pcha projekt do przodu, to bramki:\n\n- `docs/_meta/gates.yaml`: definicje gate’ów + warunki odblokowania\n    \n- warunki są wyrażone regułami: dokumenty wymagane, statusy, approvals, evidence, RTM coverage\n    \n- raporty walidatora są „gate-centric”: **co blokuje gate i jak to odblokować**\n    \n\nTo robi z dokumentacji narzędzie zarządzania, a nie archiwum.\n\n---\n\n## 7) Auto-remediation: generator TODO z błędów walidatora\n\nDojrzały system nie tylko krzyczy „brak”, ale generuje pracę:\n\n- dla każdego błędu: wygeneruj `TODO` z remediation steps + owner default + priorytet\n    \n- wynik: `reports/remediation_plan.md` + pliki `docs/<project>/todos/…`\n    \n\nTo jest dokładnie tryb „co się nie udało i jak to musi być wykonane”.\n\n---\n\n## 8) Raporty operacyjne (nie tylko lista błędów)\n\nMinimum raportów, które powinny powstawać automatycznie:\n\n- `reports/blockers.md` (Top blokery per gate)\n    \n- `reports/completeness.md` (coverage sekcji/evidence)\n    \n- `reports/contradictions.md` (sprzeczności factów)\n    \n- `reports/missing-dependencies.md` (brakujące pliki / linki)\n    \n- `reports/waivers.md` (aktywne wyjątki, terminy)\n    \n\nTo zamienia walidację w „dashboard decyzyjny”.\n\n---\n\n## 9) Testy walidatora (golden fixtures)\n\nJeśli walidator ma być narzędziem, musi być testowany:\n\n- `tests/fixtures/` — przykładowe dokumenty poprawne i błędne\n    \n- `tests/golden/` — oczekiwane raporty\n    \n- CI odpala testy walidatora, żeby zmiana reguł nie psuła logiki\n    \n\nTo jest często pomijane, a krytyczne.\n\n---\n\n## 10) Pre-commit / CI policy\n\nŻeby system działał w praktyce:\n\n- pre-commit hook: waliduje zmienione pliki `.md`\n    \n- CI: fail build na **BLOCKER** (np. E150/E200), warn na Wxxx\n    \n- tryb: `--strict` (release) vs `--lenient` (draft)\n    \n\nBez tego reguły pozostaną „na papierze”.\n\n---\n\n## 11) Słownik / glosariusz jako część semantyki\n\nNie chodzi o słownik per plik, tylko:\n\n- jeden **glossary.md** + kontrolowana terminologia\n    \n- opcjonalnie: „zakazane słowa/nieprecyzyjne” (np. „może”, „prawdopodobnie” w dokumentach inwestorskich)\n    \n- walidator może wykrywać brak definicji pojęć krytycznych\n    \n\nTo zwiększa spójność między klientami i dziedzinami.\n\n---\n\n## 12) Redakcja i sanitizacja (dla klientów)\n\nJeśli piszesz dla wielu klientów:\n\n- mechanizm „redaction” (sekcje poufne / anonimizacja)\n    \n- osobny packaging: `deliverables/` (PDF/ZIP/manifest)\n    \n- kontrola, czy nie wyciekają dane wrażliwe (regex + allowlist)\n    \n\nTo nie jest „nice-to-have” przy pracy komercyjnej.\n\n---\n\n### Co to daje w praktyce\n\nPo dodaniu tych elementów walidator nie mówi: „brak sekcji X”.  \nTylko mówi:\n\n- **który gate jest zablokowany**\n    \n- **co dokładnie trzeba zrobić**\n    \n- **jakim dowodem to potwierdzić**\n    \n- **i generuje TODO/remediation plan**\n    \n\nJeśli chcesz, następnym logicznym krokiem jest ustalenie 3 plików źródłowych prawdy:\n\n1. `doc_types.yaml` (sekcje i zależności per typ)\n    \n2. `gates.yaml` (bramki i warunki)\n    \n3. `rules_base.yaml` (core rules + severity + kody błędów)\n    \n\nNa ich bazie da się napisać prosty parser/walidator, który generuje raporty i TODO automatycznie.","x":4160,"y":-653,"width":720,"height":2720},
		{"id":"516326d1102c2b58","type":"text","text":"Nie ma „absolutnie wszystkiego” w sensie _uniwersalnym_ (bo branże i grantodawcy potrafią wymagać własnych, niszowych załączników), ale możesz mieć **kompletny core + mechanizm profili branżowych**. To jest dojrzałe podejście: katalog szablonów jest stabilny, a zmienność obsługujesz pluginami/regułami, nie ręczną rzeźbą.\n\nPoniżej struktura katalogów, która **pokazuje dojrzałość narzędzia** i jest zaprojektowana pod: jednolitą jakość, walidację, gate’y, satelity, dowody (evidence), sprzeczności i workflow „co blokuje”.\n\n---\n\n## 1) Warstwy dojrzałego systemu szablonów\n\n### A. Core (wspólne dla wszystkich)\n\n- standard front-matter (meta, id, status, owner, related)\n    \n- standard atomów: TODO/DoR/DoD/Approval/Evidence/CR/ADR\n    \n- wspólne reguły jakości + kody błędów\n    \n\n### B. Typ dokumentu (PRD/TDD/Business Case…)\n\nKażdy typ ma **własny katalog**, w którym trzymasz:\n\n- template `.md`\n    \n- definicję sekcji (required/optional)\n    \n- reguły walidacji specyficzne dla typu\n    \n- satelity wymagane dla tego typu (DoR/DoD/Approval/Evidence)\n    \n- przykłady (wypełnione)\n    \n\n### C. Profile branżowe (pluginy)\n\n- healthcare/fintech/public/defense…\n    \n- _dokładają_ sekcje, reguły i wymagane evidence, nie psują core\n    \n\n---\n\n## 2) Proponowana struktura repo (dojrzały layout)\n\n```text\ntemplates/\n  _core/\n    atoms/                  # wzorce satelitów (uniwersalne)\n      todo.md\n      dor.md\n      dod.md\n      approval.md\n      evidence.md\n      change_request.md\n      adr.md\n    style/\n      writing_rules.md      # styl redakcji, słownictwo, zakazy \"TBD\"\n      section_naming.md     # nazwy sekcji (kanon)\n    schemas/\n      frontmatter.schema.json\n      doc_types.schema.json\n\n  document_types/           # KAŻDY TYP MA SWÓJ KATALOG (dojrzałość)\n    PRD/\n      template.md\n      sections.yaml         # required/optional + kolejność\n      rules.yaml            # reguły specyficzne PRD\n      satellites/           # satelity dedykowane PRD\n        dor.md\n        dod.md\n        approval.md\n        evidence.md\n        todo_section.md\n      examples/\n        filled_example.md\n      README.md             # jak używać + minimalne wymagania\n\n    BUSINESS_CASE/\n      template.md\n      sections.yaml\n      rules.yaml\n      satellites/\n      examples/\n      README.md\n\n    TDD/\n    FEASIBILITY/\n    ROADMAP/\n    SPRINT/                 # sprint ma swój typ i satelity\n    ...\n\n  profiles/                 # pluginy branżowe\n    base.yaml               # core profile\n    healthcare.yaml         # np. HIPAA/MDR\n    fintech.yaml            # PCI/SOX\n    public.yaml             # eIDAS itp.\n    defense.yaml            # STANAG itd.\n\nspecs/                      # ŹRÓDŁO PRAWDY dla walidatora i gate’ów\n  doc_types.yaml            # rejestr typów dokumentów + zależności\n  gates.yaml                # definicje gate’ów + warunki odblokowania\n  error_codes.yaml          # kody E/W + remediation templates\n  facts_schema.yaml         # definicje factów (single source of truth)\n\ndocs/\n  _meta/\n    facts.yaml              # single source of truth (budżet, daty, KPI, nazwy)\n    glossary.md             # terminologia (globalna)\n    waivers.yaml            # wyjątki/odstępstwa (expiry + approver)\n\n  clients/\n    <client_id>/\n      documents/\n        PRD.md\n        BUSINESS_CASE.md\n        ...\n      satellites/\n        todos/\n        approvals/\n        evidence/\n        adr/\n        change_requests/\n      sprints/\n        S26/\n          sprint-plan.md\n          sprint-backlog.md\n          sprint-output-contract.md\n          evidence/\n      roadmaps/\n        roadmap.product.md\n        risk-register.md\n        capacity-plan.md\n\nscripts/\n  parse_docs.py\n  validate_docs.py\n  detect_conflicts.py\n  generate_todos.py\n  build_reports.py\n\nreports/\n  blockers.md               # TOP blokery per gate\n  completeness.md           # coverage sekcji/evidence\n  contradictions.md         # sprzeczności factów\n  remediation_plan.md       # automatycznie wygenerowane TODO\n  manifest.json             # graf zależności / indeks\ntests/\n  fixtures/\n    good/\n    bad/\n  golden_reports/\n```\n\n**Dlaczego to wygląda “dojrzale”:**\n\n- jest separacja: _templates/specs/docs/scripts/reports/tests_\n    \n- każdy typ dokumentu ma **własny folder** (template + sections + rules + satelity + przykład)\n    \n- branże są pluginami (profiles), nie „kopiuj-wklej tysiąc wariantów”\n    \n- jest mechanizm wyjątków (`waivers.yaml`) i single source of truth (`facts.yaml`)\n    \n- walidacja jest gate-centric (blokery), a nie „ładna lista błędów”\n    \n\n---\n\n## 3) Jak działa “dziedziczenie” (żebyś miał „pliki dziedziczne”)\n\nTo rozwiązuje Twój wątek „brak pliku dziedzicznego”:\n\n- `_core/atoms/*` = baza satelitów\n    \n- `document_types/PRD/*` = nadpisuje/rozszerza bazę (np. PRD wymaga RTM)\n    \n- `profiles/healthcare.yaml` = dokłada wymagane sekcje i reguły do PRD/TDD/DPIA\n    \n\nWalidator składa finalną specyfikację: `base + doc_type + profile`.\n\n---\n\n## 4) Minimalny zestaw „własnego katalogu” dla każdego typu dokumentu\n\nŻeby było spójnie, każdy folder typu dokumentu powinien mieć **zawsze**:\n\n1. `template.md`\n    \n2. `sections.yaml` (required/optional + order)\n    \n3. `rules.yaml` (walidacja typu + severities)\n    \n4. `satellites/` (DoR/DoD/Approval/Evidence/TODO_section)\n    \n5. `examples/filled_example.md`\n    \n6. `README.md` (kiedy używać, jakie wejścia są potrzebne)\n    \n\nTo jest bardzo czytelny sygnał dojrzałości dla narzędzia.\n\n---\n\n## 5) Czy mamy wszystko?\n\nMasz wszystko, co jest potrzebne do _frameworku_, który skaluje na klientów z różnych domen.  \nBrakujące rzeczy będą już tylko **specyfiką programu grantowego / regulatora** — i to właśnie obsługujesz przez `profiles/` + ewentualne dodatkowe typy dokumentów.\n\nJeśli chcesz, mogę następnie przygotować Ci **gotowe szkielety**:\n\n- `specs/doc_types.yaml`\n    \n- `specs/gates.yaml`\n    \n- `specs/error_codes.yaml`\n    \n- bazowe foldery `templates/document_types/<...>/` dla 10 kluczowych typów (PRD/TDD/BUSINESS_CASE/FEASIBILITY/ROADMAP/SPRINT/DPIA/SECURITY_PLAN/TEST_PLAN/RELEASE)\n    \n\n…tak, żebyś mógł od razu wrzucić to do repo i zacząć budować walidator.","x":4960,"y":-653,"width":800,"height":2720},
		{"id":"b29e22449610b288","type":"text","text":"SQLAlchemy nie jest „lepsze” samo w sobie. To jest **warstwa dostępu do bazy** (toolkit/ORM), która ma sens wtedy, gdy chcesz ustandaryzować sposób pracy z DB w większym ekosystemie modułów.\n\n## Po co w ogóle proponowałem SQLAlchemy\n\nBo w Twoim układzie (wiele modułów: parsery, reguły, graf, publikatory, GUI) prędzej czy później pojawia się potrzeba:\n\n- jednego, spójnego zarządzania **połączeniami i transakcjami**,\n    \n- bezpiecznego parametryzowania zapytań (mniej „sklejania SQL stringów”),\n    \n- łatwego testowania (np. SQLite in-memory),\n    \n- ewentualnie migracji (często razem z **Alembic**).\n    \n\n## Kiedy SQLAlchemy ma sens\n\nWybierz SQLAlchemy, jeśli:\n\n- chcesz mieć **warstwę repozytoriów** i spójne API dla wielu modułów,\n    \n- przewidujesz, że część danych może kiedyś trafić do innej bazy niż SQLite,\n    \n- chcesz automatycznie wspierać więcej niż proste CRUD (filtry, joiny, dynamiczne zapytania).\n    \n\n## Kiedy SQLAlchemy jest zbędne (i lepsze będzie „czyste SQL”)\n\nW Twoim przypadku (SQLite-first, duża kontrola, chęć deterministyczności) bardzo często lepsze jest:\n\n- `sqlite3` + **jawne SQL** + własny „migration runner” na plikach `.sql`,\n    \n- albo `apsw` (jeśli chcesz pełniejszy dostęp do możliwości SQLite i więcej kontroli).\n    \n\nTo daje:\n\n- maksymalną przewidywalność,\n    \n- łatwiejsze debugowanie (masz SQL 1:1),\n    \n- brak „magii ORM” i brak narzutu mapowania obiektów.\n    \n\n## Najlepszy kompromis, jeśli chcesz „maksymalnie” bez utraty kontroli\n\nJeżeli chcesz korzyści (transakcje, spójny dostęp, testy), ale bez ORM-owej magii:\n\n- użyj **SQLAlchemy Core** (bez ORM)  \n    albo\n    \n- zostań przy `sqlite3` i zrób cienką warstwę: `db.py` (połączenia, transakcje) + `queries/*.sql`.\n    \n\n## Rekomendacja dla Twojego ekosystemu\n\n- **Start**: jawne SQL + `sqlite3`/`apsw` + migracje w `.sql` (najmniej ryzyka i najwięcej kontroli).\n    \n- **Dodaj SQLAlchemy Core** dopiero, gdy zaczniesz czuć ból w: dynamicznych zapytaniach, wspólnych transakcjach między modułami, testach integracyjnych.\n    \n\nJeśli podasz, jakie tabele przewidujesz (facts/issues/graph/provenance/revisions), to powiem wprost: czy w Twoim modelu SQLAlchemy coś realnie upraszcza, czy będzie tylko dodatkową warstwą do utrzymania.","x":8260,"y":-653,"width":520,"height":960},
		{"id":"e186744d402e4462","type":"text","text":"- [ ] Tak — da się to złożyć z gotowych klocków. Poniżej masz **konkretną listę bibliotek / narzędzi / małych modeli**, które możesz pobrać i spiąć w jeden ekosystem: **parser → semantyka/reguły → graf → publikacje → GUI (bez terminala)**.\n\n- [ ] ---\n\n- [ ] ## 1) GUI „program” (bez komend)\n\n- [ ] **Python + Qt (PySide6) + wbudowany podgląd HTML**\n\n- [ ] **PySide6 (Qt for Python)** – framework GUI. ([PyPI](https://pypi.org/project/PySide6/?utm_source=chatgpt.com \"PySide6\"))\n    \n- [ ] **QtWebEngine (QWebEngineView)** – żeby w aplikacji mieć dwa panele webowe: _graf_ i _public preview_. ([Qt Documentation](https://doc.qt.io/qtforpython-6/PySide6/QtWebEngineWidgets/index.html?utm_source=chatgpt.com \"PySide6.QtWebEngineWidgets - Qt for Python\"))\n    \n\n- [ ] To pozwala mieć jeden EXE/AppImage: startujesz ikoną, a nie terminalem.\n\n- [ ] ---\n\n- [ ] ## 2) Interaktywny graf (frontend)\n\n- [ ] **Najpraktyczniej: Cytoscape.js w panelu QtWebEngine**\n\n- [ ] **Cytoscape.js** – biblioteka do wizualizacji i analizy grafów. ([js.cytoscape.org](https://js.cytoscape.org/?utm_source=chatgpt.com \"Cytoscape.js\"))\n    \n- [ ] Format danych: **JSON (Cytoscape.js JSON)** – prosty export/import grafu z backendu. ([manual.cytoscape.org](https://manual.cytoscape.org/en/stable/Cytoscape.js_and_Cytoscape.html?utm_source=chatgpt.com \"25. Cytoscape.js and Cytoscape\"))\n    \n\n- [ ] Backend generuje `graph.json`, a UI tylko rysuje i koloruje braki/konflikty.\n\n- [ ] ---\n\n- [ ] ## 3) Warstwa „semantyki” i reguł\n\n- [ ] Tu masz dwie ścieżki — obie są sensowne, ale jedna jest „bardziej maksymalna”:\n\n- [ ] ### A) Policy engine (maksymalnie przyszłościowe)\n\n- [ ] **Open Policy Agent (OPA) + Rego** – silnik reguł nad danymi strukturalnymi (JSON). Bardzo dobry do Twojego „walidator/bramki/konflikty”. ([Open Policy Agent](https://openpolicyagent.org/docs?utm_source=chatgpt.com \"Open Policy Agent (OPA)\"))\n    \n\n- [ ] OPA trzyma reguły w plikach `.rego`, a Twój backend odpala OPA lokalnie i odbiera wynik jako JSON.\n\n- [ ] ### B) Reguły w Pythonie (szybciej, mniej „enterprise”)\n\n- [ ] **Pydantic** (model danych, walidacja typów)\n    \n- [ ] **jsonschema** (kontrakty/schematy)\n    \n- [ ] plus własne reguły domenowe (kod)\n    \n\n- [ ] Jeśli chcesz „maksymalnie”, to i tak finalnie wygodniej mieć **OPA jako warstwę polityk** + Python jako „glue”.\n\n- [ ] ---\n\n- [ ] ## 4) Parsowanie dokumentów (Twoje .md + szablony)\n\n- [ ] Żeby system nie zgadywał „z tekstu”, tylko deterministycznie wyciągał fakty:\n\n- [ ] **python-frontmatter** – YAML front-matter w plikach `.md` (ID/type/domain/provides/…)\n    \n- [ ] **ruamel.yaml** lub **PyYAML** – YAML (manifesty, słowniki, routing)\n    \n- [ ] **markdown-it-py** lub **mistune** – parser Markdown (sekcje, nagłówki, checklisty)\n    \n- [ ] **watchdog** – obserwacja zmian plików (auto-rebuild bez ręcznego odpalania)\n    \n\n- [ ] ---\n\n- [ ] ## 5) Analiza grafu i konfliktów zależności\n\n- [ ] **networkx** – cykle, topological sort, ścieżki krytyczne, wykrywanie konfliktów strukturalnych (graf).\n    \n- [ ] (opcjonalnie) **graphviz/pygraphviz** – jeśli chcesz też generować statyczne diagramy do dokumentacji.\n    \n\n- [ ] ---\n\n- [ ] ## 6) Generowanie „publicznych” wyników (Release Notes / DevLog / strona)\n\n- [ ] **Jinja2** – składanie dokumentów z danych (facts + routing) do `out/*.md` / `out/*.html`\n    \n- [ ] (opcjonalnie) **MkDocs** – szybki lokalny podgląd jako „strona projektu” (może działać offline)\n    \n\n- [ ] ---\n\n- [ ] ## 7) Lokalny LLM do ekstrakcji (opcjonalnie, ale bardzo użyteczne)\n\n- [ ] Jeżeli chcesz wkleić „luźny opis projektu” i dostać ustrukturyzowany plan/IR:\n\n- [ ] **Ollama** – lokalny runtime modeli + **Structured Outputs** (wymuszenie JSON Schema na odpowiedzi), co jest kluczowe dla niezawodnej ekstrakcji. ([Ollama Documentation](https://docs.ollama.com/capabilities/structured-outputs?utm_source=chatgpt.com \"Structured Outputs\"))\n    \n\n- [ ] Modele: wybierasz mały model instrukcyjny (3–7B) do ekstrakcji + mały embedding do wyszukiwania; ważniejsze od nazwy jest, żeby dobrze trzymał się schematu (Ollama to ułatwia przez JSON Schema).\n\n- [ ] ---\n\n- [ ] ## 8) Składowanie i indeks (żeby „pamiętało” i dało się debugować)\n\n- [ ] **SQLite (FTS5)** – indeks treści i faktów (źródła, proweniencja, wersje)\n    \n- [ ] **SQLAlchemy** (opcjonalnie) – jeśli chcesz ORM\n    \n- [ ] (opcjonalnie) **Ripgrep** jako szybkie wsparcie diagnostyczne (szukanie w repo)\n    \n\n- [ ] ---\n\n- [ ] ## 9) Pluginy i „maksymalność od startu”\n\n- [ ] Żebyś nie musiał potem przebudowywać systemu:\n\n- [ ] **pluggy** albo entrypoints (`importlib.metadata`) – system pluginów:\n    \n    - [ ] `ParserPlugin` (typ dokumentu/pack),\n        \n    - [ ] `RulePack` (reguły + słowniki + kody błędów),\n        \n    - [ ] `Publisher` (release/devlog/www),\n        \n    - [ ] `GraphDecorator` (kolorowanie, etapy, pipeline).\n        \n\n- [ ] To jest sposób na „maksymalny zakres”, bez robienia monolitu.\n\n- [ ] ---\n\n- [ ] ## 10) Pakowanie jako aplikacja (ikona, klik, działa)\n\n- [ ] **PyInstaller** (spakowanie do binarki)\n    \n- [ ] **AppImage** (dystrybucja na Ubuntu jako „normalny program”)\n    \n- [ ] `.desktop` + ikona (integracja z menu)\n    \n\n- [ ] ---\n\n- [ ] # Proponowany „zestaw obowiązkowy” (rdzeń)\n\n- [ ] Jeśli chcesz to składać bez ryzyka, że zabraknie fundamentów:\n\n- [ ] PySide6 + QtWebEngine ([Qt Documentation](https://doc.qt.io/qtforpython-6/PySide6/QtWebEngineWidgets/index.html?utm_source=chatgpt.com \"PySide6.QtWebEngineWidgets - Qt for Python\"))\n    \n- [ ] Cytoscape.js ([js.cytoscape.org](https://js.cytoscape.org/?utm_source=chatgpt.com \"Cytoscape.js\"))\n    \n- [ ] OPA/Rego ([Open Policy Agent](https://openpolicyagent.org/docs?utm_source=chatgpt.com \"Open Policy Agent (OPA)\"))\n    \n- [ ] watchdog + frontmatter + yaml + markdown parser\n    \n- [ ] networkx + jinja2\n    \n- [ ] SQLite jako „ledger/provenance”\n    \n\n- [ ] A jako „dopalenie”: Ollama Structured Outputs do niezawodnej ekstrakcji z luźnego opisu. ([Ollama Documentation](https://docs.ollama.com/capabilities/structured-outputs?utm_source=chatgpt.com \"Structured Outputs\"))\n\n- [ ] ---\n\n- [ ] Jeśli chcesz, w kolejnym kroku mogę Ci to spiąć w **konkretne moduły ekosystemu** (foldery + interfejsy pluginów + format `facts.json/issues.json/graph.json`), tak żebyś od pierwszego dnia miał „maksymalny” kontrakt i nie wracał do pytania „czemu nie przewidziałem tej funkcji”.","x":7520,"y":1260,"width":645,"height":837},
		{"id":"1b9dfae26e962f38","type":"text","text":"Tak — w dużej mierze mieli rację. To, co omówiliśmy, jest solidnym szkieletem (szablony, satelity, bramki, walidacja, raporty „co blokuje”), ale **żeby podejście było w pełni dopowiedziane i dało się je wdrożyć jako narzędzie**, brakuje kilku „klocków operacyjnych” i kilku formalnych definicji.\n\nPoniżej najczęstsze brakujące elementy, które zwykle trzeba doprecyzować w dojrzałym systemie tego typu:\n\n## 1) Model usługi i intake klienta\n\nBez tego narzędzie nie skaluje na „wiele dziedzin”.\n\n- standardowy **brief wejściowy** (formularz) + minimalny zestaw danych wymaganych do startu,\n    \n- klasy projektów (startup/grant/regulated) i domyślne profile,\n    \n- zasady: NDA, poufność, retencja, redakcja danych, zakres odpowiedzialności.\n    \n\n## 2) „Kto zatwierdza co” (matryca ról)\n\nSame Approval/DoR/DoD są, ale trzeba dopisać **matrycę sign-off**:\n\n- per typ dokumentu: PO/CFO/DPO/Security/Legal/Sponsor,\n    \n- kiedy approval jest wymagany (który gate),\n    \n- co jest „wystarczające” vs „pełne” (np. dla draftów).\n    \n\n## 3) Jednoznaczna maszyna stanów dla dokumentów i satelitów\n\nŻeby walidator nie był „subiektywny”:\n\n- statusy: `draft → in-review → approved → archived` (+ `blocked`),\n    \n- reguły przejść (kto może zmienić status i na jakich warunkach),\n    \n- minimalne pola w front-matter (owner/reviewers/approver/approved_at/version).\n    \n\n## 4) System wyjątków (waiver) i akceptacji ryzyka\n\nW dojrzałych procesach wyjątki są nieuniknione:\n\n- `waivers.yaml` z: reguła, powód, approver, expiry,\n    \n- walidator rozróżnia: **BLOCKER** vs **WAIVED** (audytowalne).\n    \n\n## 5) Formalne mapowanie „teza → dowód”\n\nSzczególnie krytyczne dla grantów/inwestorów:\n\n- `evidence-index.md` (co udowadnia dany plik i gdzie jest użyty),\n    \n- reguły: które sekcje wymagają evidence (np. liczby/rynek/ROI),\n    \n- minimalny standard cytowania źródeł (wiarygodność, data, link, snapshot).\n    \n\n## 6) Single Source of Truth dla faktów + spójność\n\nŻeby realnie wykrywać sprzeczności:\n\n- `facts.yaml` jako źródło prawdy (budżet, daty, KPI, nazwy),\n    \n- dokumenty deklarują `facts_claimed`/`facts_used`,\n    \n- walidator raportuje sprzeczności jako **E200** z oboma źródłami.\n    \n\n## 7) Dokładna specyfikacja reguł walidacji i remediacji\n\nCzyli nie tylko „brak sekcji”, ale:\n\n- kody błędów + severity + **remediation template** (co zrobić krok po kroku),\n    \n- gate-centric reporting: „blokuje GATE-X, bo …; napraw: …”.\n    \n\n## 8) Automatyczna produkcja pracy z błędów (remediation → TODO)\n\nŻeby system był „co się nie udało i jak to naprawić”:\n\n- walidator generuje TODO per błąd (owner default, AC, due),\n    \n- raport `reports/remediation_plan.md` + pliki `docs/<project>/todos/…`.\n    \n\n## 9) Testy walidatora i CI policy\n\nBez tego narzędzie będzie chwiejne:\n\n- fixtures „good/bad” + golden reports,\n    \n- pre-commit / CI: fail na BLOCKER, warn na Wxxx,\n    \n- tryb `strict` (release) vs `lenient` (draft).\n    \n\n## 10) Packaging deliverables (na zewnątrz)\n\nDla klientów liczy się „pakiet do złożenia”:\n\n- struktura „binder”: spis dokumentów, załączniki, evidence index,\n    \n- export PDF/ZIP, numeracja wersji, redakcja danych wrażliwych,\n    \n- checklista submission (grant/investor/regulator).\n    \n\n---\n\n### Wniosek\n\n**Tak — nie wszystko było dopowiedziane**, bo te elementy są zwykle „ostatnią warstwą”, która zamienia same szablony w **narzędzie produkcyjne** (operating model + governance + evidence + waivers + CI).\n\nJeśli chcesz, mogę Ci to domknąć w formie trzech dokumentów-specyfikacji (w `.md`), które staną się „kontraktem systemu”:\n\n1. `OPERATING_MODEL.md` (workflow, role, approvals, stany)\n    \n2. `VALIDATION_SPEC.md` (kody błędów, gate’y, remediacje, waivers)\n    \n3. `DELIVERABLES_PACKAGING.md` (binder, evidence, eksport, redakcja)\n    \n\nTo jest zwykle ten brakujący fragment, który z zewnątrz „czuć”, że nie był dopowiedziany.","x":5840,"y":-653,"width":960,"height":2720},
		{"id":"c04e1f3d9b3b68cc","type":"text","text":"Tak — to jest bardzo dobre podejście. Żeby „namierzyć” problem bez domysłów, każdy błąd powinien mieć **(a) stabilny identyfikator**, **(b) kod błędu**, oraz **(c) ścieżkę przyczynowo-zależnościową** (łańcuch plików + ich kody), która prowadzi do „root cause”.\n\nPoniżej gotowy wzorzec, jak to opracować.\n\n---\n\n## 1) Ustal stałe identyfikatory (ID) dla wszystkiego\n\nMinimalny zestaw ID, który daje pełną śledzalność:\n\n- **Document ID** (z front-matter): `DOC-PRD-001`, `DOC-BUSCASE-003`\n    \n- **Section ID** (stabilna nazwa sekcji): `SEC-PRD-ACCEPTANCE`, `SEC-BUSCASE-ROI`\n    \n- **Rule ID** (reguła walidacji): `RULE-PRD-SEC-ACCEPTANCE-MINCOUNT`\n    \n- **Gate ID** (bramka): `GATE-REQ-FREEZE`, `GATE-RELEASE-READY`\n    \n- **Run ID** (uruchomienie walidacji): `RUN-20251224-2310`\n    \n- **Error Instance ID** (konkretny błąd w danym runie): `ERR-RUN-20251224-2310-0042`\n    \n\n> ID dokumentu musi być niezależne od ścieżki pliku, bo ścieżki się zmieniają.\n\n---\n\n## 2) Zdefiniuj taksonomię kodów błędów (czytelne kategorie)\n\nPrzykład rozsądnego podziału:\n\n- **E1xx – Struktura**\n    \n    - `E100` Missing file\n        \n    - `E110` Missing section\n        \n    - `E120` Placeholder/TBD w sekcji\n        \n- **E14x – Zależności**\n    \n    - `E140` Missing dependency link\n        \n    - `E141` Dependency exists but wrong type/status\n        \n- **E15x – Gate/Approval**\n    \n    - `E150` Gate blocked\n        \n    - `E160` Missing approval/sign-off\n        \n- **E2xx – Spójność**\n    \n    - `E200` Contradiction (sprzeczne fakty)\n        \n    - `E210` ID collision\n        \n- **E13x – Evidence**\n    \n    - `E130` Missing evidence for claim\n        \n\nKażdy błąd ma też **severity**: `BLOCKER | ERROR | WARN`.\n\n---\n\n## 3) Klucz: „Trace Chain” = łańcuch plików + kodów (root cause)\n\nTo jest dokładnie to, czego chcesz: błąd ma nie tylko lokalizację, ale też **łańcuch przyczyn**.\n\n### Struktura „trace chain” (zalecana)\n\nKażdy element łańcucha to:\n\n- `artifact_id` (np. DOC-PRD-001)\n    \n- `path` (dla wygody)\n    \n- `code` (E140/E100/…)\n    \n- `rule_id` (jeśli dotyczy)\n    \n- `location` (sekcja/linia)\n    \n- `message` (krótko)\n    \n- `causes` (link do następnego elementu w łańcuchu)\n    \n\n### Przykład: PRD blokuje gate, bo brakuje Business Case\n\n**ERR-RUN-20251224-2310-0042 (BLOCKER)**\n\n- Gate: `GATE-REQ-FREEZE`\n    \n- Trace chain:\n    \n\n1. `DOC-PRD-001` → `E140 Missing dependency: DOC-BUSCASE-001`\n    \n2. `DOC-BUSCASE-001` → `E100 Missing file: docs/clientX/investor/Business_Case.md`\n    \n\n**Root cause:** `E100` (brak pliku), a nie „PRD ma problem”.\n\nTo dramatycznie poprawia czytelność naprawy.\n\n---\n\n## 4) Format komunikatu błędu (żeby był „narzędziowy”, nie opisowy)\n\nKażdy błąd powinien mieć stałe pola:\n\n- `error_id`\n    \n- `severity`\n    \n- `code`\n    \n- `gate_blocked[]` (jeśli dotyczy)\n    \n- `primary_artifact` (doc_id + path)\n    \n- `location` (sekcja/anchor)\n    \n- `rule_id`\n    \n- `trace_chain[]` (łańcuch przyczyn)\n    \n- `remediation` (instrukcja „co zrobić”)\n    \n\n**Przykład komunikatu (tekst):**\n\n> **ERR-… E150 (BLOCKER)** Gate `GATE-REQ-FREEZE` zablokowany.  \n> **Primary:** `DOC-PRD-001` (SEC-PRD-ACCEPTANCE) → `E110 Missing section: Kryteria akceptacji`  \n> **Trace:** `DOC-PRD-001:E110`  \n> **Naprawa:** dodaj `## Kryteria akceptacji` + min. 5 AC + link do RTM.\n\n---\n\n## 5) Skąd validator ma wiedzieć „jakie sekcje są wymagane”\n\nNie robisz „słownika per plik”, tylko:\n\n- **core rules** (wspólne)\n    \n- **rules per typ dokumentu** (PRD/TDD/Business Case)\n    \n- **profiles branżowe** (pluginy, uruchamiane przez `compliance:`)\n    \n\nCzyli specyfikacje:\n\n- `specs/doc_types.yaml` (sekcje wymagane/opcjonalne, zależności)\n    \n- `specs/error_codes.yaml` (kody, severity, message template, remediation template)\n    \n- `specs/gates.yaml` (bramki i warunki odblokowania)\n    \n\n---\n\n## 6) Jak zrobić, żeby błędy były „dziedziczne” i agregowalne\n\nDwa mechanizmy:\n\n### A) Fingerprint (stały identyfikator problemu)\n\nŻeby ten sam błąd dało się rozpoznać w kolejnych runach:\n\n- `fingerprint = hash(code + rule_id + doc_id + section_id)`\n    \n\n### B) Error graph (graf błędów)\n\nBłędy łączysz relacją `caused_by`:\n\n- `ERR-0042 caused_by ERR-0007`\n    \n\nI możesz generować raporty:\n\n- „Top 10 root causes”\n    \n- „Blokery gate’ów”\n    \n- „Najczęściej powtarzane braki”\n    \n\n---\n\n## 7) Output dla człowieka i dla maszyn\n\nŻeby narzędzie było dojrzałe, walidator produkuje zawsze 2 formaty:\n\n1. **JSONL/JSON** (dla automatyzacji): `reports/errors.jsonl`\n    \n2. **Markdown** (dla Ciebie/klienta): `reports/blockers.md` + `reports/remediation_plan.md`\n    \n\nW `remediation_plan.md` każdy błąd może automatycznie generować TODO.\n\n---\n\n## 8) Minimalna „implementacja logiczna” (bez kodu, tylko architektura)\n\n1. Parser wczytuje `.md` → meta + sekcje + placeholdery\n    \n2. Validator robi błędy lokalne (E110/E120/E130…)\n    \n3. Resolver buduje `trace_chain` (przechodzi po zależnościach i znajduje root cause)\n    \n4. Gate evaluator mapuje błędy na bramki (E150)\n    \n5. Reporter tworzy raporty + TODO z remediacją\n    \n\n---\n\nJeżeli chcesz, następnym krokiem jest ustalenie **konkretnego formatu rekordów błędów** (JSON) i **konkretnej składni trace_chain**, np.:\n\n- `GATE-REQ-FREEZE > DOC-PRD-001:E140 > DOC-BUSCASE-001:E100`\n    \n\ni zapisanie tego jako `specs/error_record_format.md` + `specs/error_codes.yaml`.","x":6840,"y":-653,"width":640,"height":960},
		{"id":"ccad09e037bb0e5a","type":"text","text":"# System Audytu Kompletności Projektu (Error‑Driven)\n\n## 1. Cel dokumentu\n\nCelem tego dokumentu jest opisanie koncepcji systemu, który **ujawnia braki, niespójności i luki w projekcie**, zanim staną się kosztownym problemem. System nie zarządza zadaniami, nie organizuje pracy zespołu i nie tworzy dokumentacji. Jego jedyną rolą jest **pokazywanie, czego brakuje oraz gdzie model projektu przestaje opisywać rzeczywistość**.\n\nDokument definiuje:\n\n- czym jest system,\n    \n- do czego służy,\n    \n- jak działa na poziomie logicznym,\n    \n- w czym realnie pomaga,\n    \n- kto z niego korzysta i co zyskuje.\n    \n\n---\n\n## 2. Problem, który system rozwiązuje\n\nW większości projektów:\n\n- braki są wykrywane zbyt późno,\n    \n- dokumentacja jest niespójna lub niepełna,\n    \n- nie istnieje jedno miejsce, które mówi wprost „tego nie ma”,\n    \n- narzędzia pokazują **dane**, a nie **luki**.\n    \n\nSystemy typu GitLab, Jira, Notion czy klasyczne checklisty:\n\n- nie znają definicji „kompletności”,\n    \n- nie potrafią wykryć braków, których nie przewidziano,\n    \n- zalewają użytkownika informacjami zamiast sygnałem.\n    \n\nEfekt:\n\n- czas jest tracony na ręczne przeglądanie plików,\n    \n- błędy wychodzą po fakcie,\n    \n- projekt sprawia wrażenie „niby gotowego”, ale niestabilnego.\n    \n\n---\n\n## 3. Czym jest ten system\n\nSystem Audytu Kompletności Projektu to **mechanizm kontroli zgodności projektu z jego własnym modelem kompletności**, który:\n\n- działa na dokumentach, strukturze i regułach projektu,\n    \n- pokazuje wyłącznie **problemy i braki**,\n    \n- nie zarządza treścią projektu,\n    \n- nie narzuca procesu pracy,\n    \n- uczy się wyłącznie na podstawie **realnych błędów**, które już wystąpiły.\n    \n\nSystem odpowiada na jedno pytanie:\n\n> **„Czego w tym projekcie brakuje, albo co jest niespójne, względem tego, co już wiemy, że musi istnieć?”**\n\n---\n\n## 4. Filozofia działania\n\n### 4.1. Braki są ważniejsze niż kompletność\n\nSystem:\n\n- **nie pokazuje elementów poprawnych**,\n    \n- **nie raportuje „OK”**,\n    \n- **nie generuje zielonych statusów**.\n    \n\nBrak informacji oznacza brak problemu.\n\n### 4.2. Reguły nie są projektowane z góry\n\nReguły systemu:\n\n- **nie powstają teoretycznie**,\n    \n- **nie są przewidywane na zapas**,\n    \n- **nie są generowane przez AI „na wszelki wypadek”**.\n    \n\nKażda reguła istnieje, ponieważ:\n\n- pojawił się realny błąd,\n    \n- coś zostało wykryte za późno,\n    \n- projekt poniósł koszt.\n    \n\nBłąd → reguła → blok → kafel.\n\n### 4.3. Model musi wiedzieć, kiedy jest niekompletny\n\nSystem nie tylko wykrywa braki w ramach znanych obszarów, ale również sygnalizuje, że:\n\n- pojawił się nowy byt, który nie ma kontraktu,\n    \n- istnieje pojęcie bez własnego kafla,\n    \n- model projektu przestał nadążać za rzeczywistością.\n    \n\nTo jest warstwa **meta‑kompletności**.\n\n---\n\n## 5. Podstawowe pojęcia\n\n### 5.1. Błąd\n\nBłąd to zdarzenie, które:\n\n- zostało wykryte po etapie, na którym powinno być wykryte,\n    \n- spowodowało koszt (czas, cofanie, poprawki, ryzyko),\n    \n- nie było wychwycone przez istniejące reguły.\n    \n\nNie każdy brak jest błędem. Nie każda decyzja jest brakiem.\n\n---\n\n### 5.2. Blok reguł\n\nBlok to zbiór **utrwalonych braków**, które już wystąpiły w danym kontekście.\n\nBlok:\n\n- nie opisuje idealnego stanu,\n    \n- nie jest dokumentacją funkcjonalną,\n    \n- jest listą tego, co realnie zawiodło wcześniej.\n    \n\n---\n\n### 5.3. Kafel\n\nKafel reprezentuje **jedną funkcję lub obszar projektu** (np. testy, ADR, moduł, integrację).\n\nKafel:\n\n- posiada własne wymagania kompletności,\n    \n- korzysta z jednego lub wielu bloków reguł,\n    \n- działa jak brama (gate), przez którą musi przejść dokumentacja lub zmiana.\n    \n\n---\n\n### 5.4. Widok zbiorczy (macierz kontrolna)\n\nJest to jedno, centralne okno (tabela), które:\n\n- pokazuje tylko kafle z problemami,\n    \n- grupuje braki według funkcji,\n    \n- nie wymaga przeglądania struktury projektu.\n    \n\nTo jest główny interfejs użytkownika.\n\n---\n\n## 6. Jak system działa (logicznie)\n\n1. Projekt ewoluuje.\n    \n2. W pewnym momencie wykrywany jest brak lub błąd.\n    \n3. Błąd zostaje zarejestrowany.\n    \n4. Z błędu powstaje reguła.\n    \n5. Reguła trafia do bloku.\n    \n6. Blok zostaje przypisany do kafla.\n    \n7. Od tej pory ten typ braku jest automatycznie sygnalizowany.\n    \n8. System dodatkowo sprawdza, czy nie pojawił się obszar bez kafla.\n    \n\nSystem nie cofa błędów. System **zapobiega ich powtórzeniu**.\n\n---\n\n## 7. Czego system NIE robi\n\nSystem:\n\n- nie tworzy dokumentów,\n    \n- nie zarządza zadaniami,\n    \n- nie planuje sprintów,\n    \n- nie decyduje za człowieka,\n    \n- nie zastępuje architekta ani autora dokumentacji.\n    \n\nJego rola kończy się na **ujawnieniu braków**.\n\n---\n\n## 8. W czym system pomaga\n\nSystem:\n\n- skraca czas wykrywania braków,\n    \n- redukuje ręczne przeglądy projektu,\n    \n- zapobiega powtarzalnym błędom,\n    \n- daje obiektywny sygnał postępu,\n    \n- umożliwia świadome podejmowanie decyzji (brak vs decyzja),\n    \n- pozwala zatrzymać projekt na etapie „wystarczająco kompletne”.\n    \n\n---\n\n## 9. Kto zyskuje\n\n### 9.1. Architekci i projektanci\n\n- widzą, gdzie model projektu jest dziurawy,\n    \n- nie muszą pamiętać historii wszystkich błędów,\n    \n- mogą świadomie rozwijać standardy.\n    \n\n### 9.2. Autorzy dokumentacji\n\n- wiedzą, czego brakuje,\n    \n- nie są zalewani teorią,\n    \n- pracują na konkretnych brakach.\n    \n\n### 9.3. Zespoły techniczne\n\n- dostają jasny sygnał ryzyka,\n    \n- nie muszą domyślać się „czy to wystarczy”,\n    \n- unikają cofania pracy.\n    \n\n### 9.4. Projekty długoterminowe\n\n- zachowują pamięć błędów,\n    \n- nie tracą wiedzy wraz z ludźmi,\n    \n- nie degenerują się w chaos reguł.\n    \n\n---\n\n## 10. Podsumowanie\n\nSystem Audytu Kompletności Projektu:\n\n- nie jest kolejnym narzędziem do zarządzania,\n    \n- nie próbuje być „inteligentny”,\n    \n- nie ukrywa problemów pod UI.\n    \n\nJest **mechanizmem kontroli rozbieżności między projektem a jego własnym standardem**, który:\n\n> pokazuje tylko to, co nie działa,  \n> uczy się wyłącznie na realnych błędach,  \n> i daje jasną odpowiedź, gdzie projekt jest niekompletny.\n\nTo jest narzędzie dla ludzi, którzy **chcą wiedzieć prawdę o stanie projektu**, a nie oglądać jego pozory.","x":7520,"y":-653,"width":720,"height":960},
		{"id":"27a940f6d10323ce","type":"text","text":"Możesz to zrobić spójnie i „dojrzale”, ale **nie** w ten sposób, że _każdy_ szablon będzie miał własne SQL-tabele, kody błędów itd. Dojrzałość polega na tym, że:\n\n- **każdy dokument ma minimalny, jednolity kontrakt metadanych**,\n    \n- a **reguły / semantyka / kody błędów są zcentralizowane** (per _typ dokumentu_ i per _profil branżowy_), a nie kopiowane do każdego pliku.\n    \n\nPoniżej masz konkret: co uzupełniać, co jest „must”, co „optional”, jakie są punkty odniesienia nie do ignorowania oraz jak je zabezpieczyć „tylko sudo”.\n\n---\n\n## 1) Czy każdy dokument musi mieć: dziedzinę, domenę, typ, grupę…?\n\n**Tak — ale w formie minimalnej klasyfikacji**, a nie encyklopedii.\n\n### Minimalny zestaw metadanych (MUST w front-matter)\n\nKażdy dokument `.md` powinien mieć co najmniej:\n\n- `id` (stałe, niezmienne)\n    \n- `doctype` (typ: PRD/TDD/BUSINESS_CASE/ROADMAP/…)\n    \n- `group` (np. investor, requirements, design, qa, ops, compliance)\n    \n- `domain` (obszar merytoryczny: product, engineering, data, security, legal, ops)\n    \n- `profile` / `industry` (np. base/healthcare/fintech/public/defense)\n    \n- `status` + `version`\n    \n- `owner` + opcjonalnie `reviewers`, `approver`\n    \n- `requires` (zależności wejściowe) + `outputs` (co odblokowuje / co produkuje)\n    \n- `gates` (jakie bramki odblokowuje albo blokuje)\n    \n\nPrzykład:\n\n```yaml\n---\nid: \"DOC-PRD-001\"\ndoctype: \"PRD\"\ngroup: \"requirements\"\ndomain: \"product\"\nprofile: \"base\"           # lub healthcare/fintech/...\nstatus: \"draft\"\nversion: \"0.3.0\"\nowner: \"PO\"\nreviewers: [\"TechLead\",\"QA\"]\napprover: \"CPO\"\nrequires: [\"DOC-BUSCASE-001\",\"DOC-ROADMAP-001\"]\noutputs:\n  unlock_gates: [\"GATE-REQ-FREEZE\"]\nrelated: [\"DOC-TDD-001\",\"DOC-RTM-001\"]\n---\n```\n\n### Co NIE musi być per dokument\n\n- **SQL tabele** – nie per dokument. To jest element narzędzia (katalog/specyfikacja), nie treści.\n    \n- **kody błędów** – nie per dokument. Kody błędów są globalne, a reguły są per typ.\n    \n- **własny słownik semantyki per plik** – nie. Semantyka jest per `doctype` + per `profile`.\n    \n\n---\n\n## 2) Gdzie mają żyć reguły „co musi być w dokumencie”\n\nTo jest serce spójności: **specyfikacje typu dokumentu** (source of truth).\n\n### `specs/doc_types.yaml` (MUST)\n\nTu definiujesz:\n\n- wymagane sekcje (i ich ID),\n    \n- wymagane pola meta,\n    \n- wymagane satelity (TODO/DoR/DoD/Approval/Evidence),\n    \n- zależności (requires),\n    \n- warunki wystarczalności (semantic “sufficient”).\n    \n\nPrzykład (skrót):\n\n```yaml\nPRD:\n  required_meta: [id, doctype, status, version, owner]\n  required_sections:\n    - {id: SEC-PRD-GOAL, title: \"Cel produktu\"}\n    - {id: SEC-PRD-SCOPE, title: \"Zakres\"}\n    - {id: SEC-PRD-FUNC, title: \"Wymagania funkcjonalne\"}\n    - {id: SEC-PRD-AC, title: \"Kryteria akceptacji\"}\n    - {id: SEC-PRD-EVID, title: \"Źródła / Evidence\"}\n  satellites_required: [TODO, DOR, DOD, APPROVAL, EVIDENCE]\n  sufficiency_rules:\n    - rule: \"min_acceptance_criteria\"\n      section: SEC-PRD-AC\n      min: 5\n      severity: BLOCKER\n```\n\n---\n\n## 3) „Rodzic i potomstwo” – jak to ugryźć, żeby nie robić ręcznej pajęczyny\n\nNajlepiej nie utrzymywać „parent/child” ręcznie. Zamiast tego:\n\n- **`requires`** = rodzice (wejścia)\n    \n- **`produces` / `outputs`** = potomstwo (wyniki)\n    \n\nZależności i graf da się wtedy wyliczyć automatycznie.\n\nPrzykład:\n\n- PRD `requires` Business Case\n    \n- TDD `requires` PRD\n    \n- RTM `requires` PRD + Test Plan  \n    → graf buduje się sam.\n    \n\n---\n\n## 4) Kryteria „wystarczalności” (żeby wiedzieć: więcej nie trzeba)\n\nTo nie jest „opinia”, tylko **reguły semantyczne** przypięte do:\n\n- `doctype` (np. PRD),\n    \n- i do gate (np. `GATE-REQ-FREEZE`).\n    \n\nW praktyce robisz:\n\n- `sufficiency_rules` w `doc_types.yaml` (dla dokumentu),\n    \n- oraz `gates.yaml` (dla etapu procesu).\n    \n\nPrzykład gate:\n\n```yaml\nGATE-REQ-FREEZE:\n  requires_docs:\n    - {doctype: PRD, status: approved}\n    - {doctype: RTM, status: draft}\n  requires_rules:\n    - \"PRD.min_acceptance_criteria\"\n```\n\nEfekt: walidator mówi _nie “brak sekcji”_, tylko:\n\n> Gate REQ-FREEZE zablokowany, bo PRD ma <5 AC.\n\n---\n\n## 5) Punkty odniesienia „nie do ignorowania” (system-of-record)\n\nTo są pliki, które muszą być **nieusuwalne / chronione**, bo bez nich system się rozjedzie:\n\n### MUST (absolutne fundamenty)\n\n1. `specs/doc_types.yaml`\n    \n2. `specs/gates.yaml`\n    \n3. `specs/error_codes.yaml` (+ remediation templates)\n    \n4. `docs/_meta/facts.yaml` (Single Source of Truth dla faktów)\n    \n5. `docs/_meta/glossary.md` (terminologia)\n    \n6. `docs/_meta/waivers.yaml` (wyjątki + expiracja + approver)\n    \n7. `specs/todo_generation_policy.yaml` (kiedy TODO/RFC/CR)\n    \n\nBez tego AI może „produkować dokumenty”, ale nie da się utrzymać spójności i sterowania blokadami.\n\n---\n\n## 6) Jak zrobić „nieusuwalne” tylko przez sudo\n\nMasz 3 warstwy (najlepiej łącznie):\n\n### A) OS-level (najbardziej „sudo”)\n\nNa Linux:\n\n- `sudo chattr +i specs/doc_types.yaml specs/gates.yaml ...`  \n    To ustawia **immutable flag** – pliku nie da się usunąć ani zmienić bez:\n    \n- `sudo chattr -i <plik>`\n    \n\n### B) Git-level (hook)\n\nPre-commit lub pre-receive (jeśli masz serwer):\n\n- blokuj usunięcie/zmianę plików z listy `PROTECTED_FILES`.\n    \n- pozwól tylko, jeśli commit zawiera np. `OVERRIDE-PROTECTED` i jest podpisany.\n    \n\n### C) Tool-level (Twoje narzędzie)\n\nWalidator może odmówić działania, jeśli wykryje naruszenie protected set.\n\n---\n\n## 7) Czy to co opisałem jest spójne i można używać „w 100%”?\n\n**Jest spójne jako framework**, ale „100%” osiągasz dopiero po _zamrożeniu_ trzech rzeczy:\n\n- **ID scheme** (jak nadajesz i czy nigdy się nie zmienia),\n    \n- **listy sekcji + ich nazw/ID** per typ (`doc_types.yaml`),\n    \n- **gate’ów** (`gates.yaml`) i polityki wyjątków (`waivers.yaml`).\n    \n\nBez tych trzech, każdy system zaczyna dryfować.\n\n---\n\n## 8) Jak uzupełniać resztę szablonów – procedura (konkret)\n\nDla każdego nowego `doctype` robisz w tej kolejności:\n\n1. **Zdefiniuj typ** w `specs/doc_types.yaml`\n    \n    - required sections + sufficiency rules + required satellites.\n        \n2. **Wygeneruj template.md** (sekcje w tej kolejności, z anchorami/ID).\n    \n3. **Dodaj satelity** (min.: TODO, DoR, DoD, Approval, Evidence).\n    \n4. **Dodaj gate impact** (które gate’y odblokowuje).\n    \n5. **Dodaj rules** (placeholdery, evidence, sprzeczności, zależności).\n    \n6. **Dodaj example** (1 filled example).\n    \n7. **Dodaj test fixture** (good/bad) dla walidatora.\n    \n\nTo daje powtarzalność i brak „niespójnych wyjątków”.\n\n---\n\nJeżeli chcesz, mogę teraz przygotować dla Ciebie **gotowe szkielety trzech plików źródłowych prawdy** (w `.yaml/.md`, gotowe do wrzucenia do repo):\n\n- `specs/doc_types.yaml` (z 8–10 kluczowymi typami na start),\n    \n- `specs/gates.yaml` (Twoje checkpointy),\n    \n- `specs/error_codes.yaml` (kody + remediation templates),\n    \n\noraz listę `PROTECTED_FILES` + instrukcję `chattr +i`.","x":7520,"y":340,"width":720,"height":900},
		{"id":"711472b91d4525bd","type":"text","text":"Poniżej masz jasne zasady „kiedy błąd **musi** generować TODO, kiedy **warto**, kiedy **fajnie**, a kiedy **nie wolno** generować TODO”. To jest dokładnie to, co odróżnia dojrzały system od spamowania backlogu.\n\n---\n\n## 1) MUSI generować TODO\n\nGeneruj TODO zawsze, gdy spełnione są łącznie warunki:\n\n### A. Błąd jest **naprawialny przez działanie**\n\nCzyli istnieje konkretna czynność, która usuwa przyczynę.\n\n- brak sekcji / brak pliku / brak approval / brak evidence\n    \n- gate zablokowany przez brak artefaktu\n    \n\n### B. Błąd ma **jednoznaczne miejsce naprawy**\n\nMożna wskazać: `doc_id + section_id` albo `path` oraz wymaganie.\n\n### C. Błąd ma **severity = BLOCKER** lub blokuje gate\n\nPrzykłady:\n\n- `E100 Missing file` (wymagany dokument)\n    \n- `E110 Missing required section`\n    \n- `E130 Missing evidence` dla tezy krytycznej (finanse/rynek)\n    \n- `E160 Missing approval` (a gate wymaga approval)\n    \n- `E200 Contradiction` jeżeli blokuje decyzję (go/no-go, req-freeze, release)\n    \n\n**Reguła praktyczna:** jeśli błąd blokuje `GATE-*` → TODO obowiązkowe.\n\n---\n\n## 2) DOBRZE żeby generował TODO (zalecane)\n\nGeneruj TODO, gdy błąd nie blokuje natychmiast gate, ale ma wysoki koszt, jeśli go zignorujesz.\n\n- `ERROR` o wysokim wpływie (np. brak RTM w projekcie regulowanym, brak test data plan)\n    \n- braki, które _nie blokują teraz_, ale blokują następny etap\n    \n- błędy, które powtarzają się i zwykle kończą „pożarem” (np. brak ownera, brak dependencies)\n    \n\nTu TODO mogą być oznaczane jako:\n\n- `P1` z datą, albo\n    \n- „collect & batch” (np. 10 warningów → 1 TODO zbiorczy)\n    \n\n---\n\n## 3) FAJNIE żeby generował TODO (opcjonalnie)\n\nTo są rzeczy usprawniające jakość, ale nie powinny zjadać czasu:\n\n- `WARN` stylu redakcji / formatowania\n    \n- brak sekcji „nice-to-have”\n    \n- brak diagramu opcjonalnego\n    \n- drobne niespójności formatów, które nie wpływają na spójność faktów\n    \n\n**Zasada:** generuj TODO tylko, jeśli masz ustawiony tryb „quality improvement sprint” albo klient kupił „premium polishing”.\n\n---\n\n## 4) ABSOLUTNIE nie powinien generować TODO\n\nTo jest kluczowe — inaczej backlog robi się toksyczny.\n\n### A. Błąd jest **nie-actionable** (brak jasnej naprawy)\n\n- walidator nie potrafi wskazać miejsca i kroku naprawy\n    \n- to tylko symptom, a nie przyczyna (np. `E150 Gate blocked` jako agregat)\n    \n    - TODO powinny powstawać dla **root cause** (`E100/E110/E130/E160/E200`), nie dla „gate blocked”.\n        \n\n### B. Błąd jest **duplikatem** istniejącego TODO\n\nJeżeli fingerprint się zgadza → tylko aktualizuj status / dopisz kontekst do istniejącego TODO.\n\n### C. Błąd jest **konfliktem wymagającym decyzji**, a nie pracy\n\nNp. `E200 Contradiction` między Business Case i Roadmapą:\n\n- to nie jest TODO „napraw sekcję”, tylko **DECISION/RFC** (albo Change Request)\n    \n    - generuj `RFC` lub `Decision Request`, nie TODO.\n        \n\n### D. Błąd wynika z **zaakceptowanego wyjątku (waiver)**\n\nJeżeli jest wpis w `waivers.yaml` → nie generuj TODO (chyba że waiver wygasa i trzeba go odnowić).\n\n### E. Błąd dotyczy **danych wrażliwych / bezpieczeństwa w logice generacji**\n\nNp. wykryto sekret w repo:\n\n- tutaj nie tworzysz publicznego TODO z treścią sekretu.\n    \n- zamiast tego generujesz **SECURITY INCIDENT** (osobny kanał), albo minimalny placeholder TODO bez wrażliwych treści.\n    \n\n### F. Błąd jest czysto „informacyjny”\n\nNp. raportuje statystyki, coverage, metryki — nie generuj TODO automatycznie.\n\n---\n\n## 5) Najlepszy model: polityka generowania TODO (policy)\n\nW praktyce ustawiasz proste reguły:\n\n- **AUTO-TODO = ON** dla: `E100, E110, E120, E130, E160` oraz root-cause `E200`\n    \n- **AUTO-TODO = BATCH** dla: `WARN/Wxxx` (zbiorczo)\n    \n- **AUTO-TODO = OFF** dla: `E150` (agregat), `E141` (jeśli wynika z `E100`), duplikaty, waiver, security-sensitive\n    \n\nI dodatkowo:\n\n- TODO tworzymy tylko, jeśli `owner` jest znany lub da się ustawić owner default (np. `doc_owner`).\n    \n- inaczej generujemy `NEEDS_TRIAGE` (do ręcznego przypisania), nie TODO.\n    \n\n---\n\n## 6) Krótki przykład (czytelna praktyka)\n\n### Gate blocked (agregat) — **nie generuje TODO**\n\n> `E150 Gate blocked: GATE-REQ-FREEZE`\n\n### Root cause — **musi generować TODO**\n\n> `E110 Missing section: \"Kryteria akceptacji\" in DOC-PRD-001`  \n> → TODO: „Dodaj sekcję Kryteria akceptacji (min 5 AC) + link do RTM”.\n\n### Sprzeczność — **generuje DECISION/RFC, nie TODO**\n\n> `E200 Contradiction: budget_total_eur differs (BUSCASE vs Financial Plan)`  \n> → RFC/Decision: „Ustalić źródło prawdy i zatwierdzić wartość budżetu”.\n\n---\n\nJeżeli chcesz, przygotuję Ci gotowy plik polityki:\n\n- `specs/todo_generation_policy.yaml`  \n    z mapą: `error_code → action {todo|batch_todo|rfc|no_action}` + reguły deduplikacji i waiverów.","x":6840,"y":360,"width":640,"height":880},
		{"id":"8f0a582ee2c7ca7f","type":"text","text":"Tak — jest kilka elementów, o których jeszcze nie powiedzieliśmy wprost, a **wynikają z całości** i w praktyce domykają ten system jako narzędzie „blokery → naprawa → gate odblokowany”.\n\n## 1) Model operacyjny narzędzia\n\n- **Role i odpowiedzialności (RACI)**: kto jest właścicielem dokumentu, kto reviewuje, kto zatwierdza, kto może dawać waiver.\n    \n- **Maszyna stanów** dla dokumentów i satelitów: `draft → review → approved → archived` + reguły przejść (kto i kiedy).\n    \n\n## 2) „Single Source of Truth” i zarządzanie faktami\n\n- Jeden plik/warstwa „facts” (budżet, daty, KPI, nazwy, definicje) + reguły co jest źródłem prawdy.\n    \n- Bez tego sprzeczności będą wiecznie „niewidzialne” lub nierozstrzygalne.\n    \n\n## 3) System dowodów (Evidence) jako element obowiązkowy\n\n- **Evidence Index**: spis dowodów + gdzie są użyte.\n    \n- Reguły „claim → evidence”: które tezy muszą mieć dowód (szczególnie grant/inwestor).\n    \n- To jest fundament „profesjonalności” dokumentacji zewnętrznej.\n    \n\n## 4) System wyjątków (waiver / risk acceptance)\n\n- Jak legalnie i audytowalnie dopuścić odstępstwo od reguły (kto zatwierdza, do kiedy ważne).\n    \n- Bez tego walidator będzie blokował realną pracę.\n    \n\n## 5) Mechanizm triage (co jest root cause, a co symptom)\n\n- Reguły: które błędy są **agregatami** (np. Gate blocked) i nie generują pracy,\n    \n- a które są **przyczyną** i muszą generować TODO/CR/RFC.\n    \n- To chroni przed spamem w backlogu.\n    \n\n## 6) Deduplikacja i „fingerprint” problemu\n\n- Stały identyfikator problemu (hash z: code+rule+doc+section), żeby:\n    \n    - nie generować 100x tego samego TODO,\n        \n    - tylko aktualizować istniejący wpis i jego kontekst.\n        \n\n## 7) Kontrakt „outputów” również dla dokumentów (nie tylko sprintu)\n\n- Tak jak zrobiłeś „Sprint Output Contract”, analogicznie:\n    \n    - **Document Output Contract**: co dany dokument ma umożliwić (który gate odblokowuje, jaki artefakt jest wymagany dalej).\n        \n- To jest kluczowe, żeby dokumentacja „pchała produkcję”.\n    \n\n## 8) Wersjonowanie szablonów i kompatybilność\n\n- Szablony będą się rozwijać — potrzebujesz:\n    \n    - `template_version`,\n        \n    - zasad migracji (co zmieniło się między v1.1 a v1.2),\n        \n    - polityki: czy stary klient może zostać na starym profilu.\n        \n\n## 9) Polityka bezpieczeństwa i sanitizacji\n\n- Skany pod kątem sekretów/PII w dokumentach i evidence.\n    \n- Mechanizm „redaction” (wersja dla klienta vs wewnętrzna).\n    \n- To jest krytyczne przy pracy komercyjnej.\n    \n\n## 10) Packaging deliverables (pakiet do wysyłki)\n\n- „Binder”: spis treści, wersje, approvals, evidence index, checksums.\n    \n- Eksport (PDF/ZIP), nazewnictwo wersji, stopki, podpisy.\n    \n- To jest często niedopowiedziane, a u klientów jest praktycznie obowiązkowe.\n    \n\n## 11) Raporty sterujące (nie informacyjne)\n\n- `blockers.md` (top blokery per gate),\n    \n- `remediation_plan.md` (co dokładnie zrobić),\n    \n- `contradictions.md` (sprzeczności + źródła),\n    \n- `missing-deps.md` (brakujące pliki i zależności).\n    \n- Bez tego system nie jest „failure-driven”.\n    \n\n## 12) Testy samego walidatora\n\n- Fixtures „good/bad” + golden reports,\n    \n- CI, które pilnuje, że zmiana reguł nie rozwala raportowania.\n    \n- To domyka narzędzie jako „produkcyjne”.\n    \n\nJeśli potwierdzisz, kolejnym logicznym krokiem jest spisanie w repo trzech plików-specyfikacji (krótkich, ale twardych):\n\n1. `OPERATING_MODEL.md` (role, stany, approvals, waivers)\n    \n2. `EVIDENCE_MODEL.md` (claim→evidence + evidence index)\n    \n3. `TRIAGE_AND_DEDUP.md` (root cause, fingerprint, kiedy TODO/CR/RFC)\n    \n\nDopiero na tym fundamencie „polityka generowania TODO” będzie kompletna i nie będzie generować chaosu.","x":6840,"y":1260,"width":640,"height":807},
		{"id":"40011d9d32151d01","type":"text","text":"Tak — da się to złożyć z gotowych klocków. Poniżej masz **konkretną listę bibliotek / narzędzi / małych modeli**, które możesz pobrać i spiąć w jeden ekosystem: **parser → semantyka/reguły → graf → publikacje → GUI (bez terminala)**.\n\n---\n\n## 1) GUI „program” (bez komend)\n\n**Python + Qt (PySide6) + wbudowany podgląd HTML**\n\n- **PySide6 (Qt for Python)** – framework GUI. ([PyPI](https://pypi.org/project/PySide6/?utm_source=chatgpt.com \"PySide6\"))\n    \n- **QtWebEngine (QWebEngineView)** – żeby w aplikacji mieć dwa panele webowe: _graf_ i _public preview_. ([Qt Documentation](https://doc.qt.io/qtforpython-6/PySide6/QtWebEngineWidgets/index.html?utm_source=chatgpt.com \"PySide6.QtWebEngineWidgets - Qt for Python\"))\n    \n\nTo pozwala mieć jeden EXE/AppImage: startujesz ikoną, a nie terminalem.\n\n---\n\n## 2) Interaktywny graf (frontend)\n\n**Najpraktyczniej: Cytoscape.js w panelu QtWebEngine**\n\n- **Cytoscape.js** – biblioteka do wizualizacji i analizy grafów. ([js.cytoscape.org](https://js.cytoscape.org/?utm_source=chatgpt.com \"Cytoscape.js\"))\n    \n- Format danych: **JSON (Cytoscape.js JSON)** – prosty export/import grafu z backendu. ([manual.cytoscape.org](https://manual.cytoscape.org/en/stable/Cytoscape.js_and_Cytoscape.html?utm_source=chatgpt.com \"25. Cytoscape.js and Cytoscape\"))\n    \n\nBackend generuje `graph.json`, a UI tylko rysuje i koloruje braki/konflikty.\n\n---\n\n## 3) Warstwa „semantyki” i reguł\n\nTu masz dwie ścieżki — obie są sensowne, ale jedna jest „bardziej maksymalna”:\n\n### A) Policy engine (maksymalnie przyszłościowe)\n\n- **Open Policy Agent (OPA) + Rego** – silnik reguł nad danymi strukturalnymi (JSON). Bardzo dobry do Twojego „walidator/bramki/konflikty”. ([Open Policy Agent](https://openpolicyagent.org/docs?utm_source=chatgpt.com \"Open Policy Agent (OPA)\"))\n    \n\nOPA trzyma reguły w plikach `.rego`, a Twój backend odpala OPA lokalnie i odbiera wynik jako JSON.\n\n### B) Reguły w Pythonie (szybciej, mniej „enterprise”)\n\n- **Pydantic** (model danych, walidacja typów)\n    \n- **jsonschema** (kontrakty/schematy)\n    \n- plus własne reguły domenowe (kod)\n    \n\nJeśli chcesz „maksymalnie”, to i tak finalnie wygodniej mieć **OPA jako warstwę polityk** + Python jako „glue”.\n\n---\n\n## 4) Parsowanie dokumentów (Twoje .md + szablony)\n\nŻeby system nie zgadywał „z tekstu”, tylko deterministycznie wyciągał fakty:\n\n- **python-frontmatter** – YAML front-matter w plikach `.md` (ID/type/domain/provides/…)\n    \n- **ruamel.yaml** lub **PyYAML** – YAML (manifesty, słowniki, routing)\n    \n- **markdown-it-py** lub **mistune** – parser Markdown (sekcje, nagłówki, checklisty)\n    \n- **watchdog** – obserwacja zmian plików (auto-rebuild bez ręcznego odpalania)\n    \n\n---\n\n## 5) Analiza grafu i konfliktów zależności\n\n- **networkx** – cykle, topological sort, ścieżki krytyczne, wykrywanie konfliktów strukturalnych (graf).\n    \n- (opcjonalnie) **graphviz/pygraphviz** – jeśli chcesz też generować statyczne diagramy do dokumentacji.\n    \n\n---\n\n## 6) Generowanie „publicznych” wyników (Release Notes / DevLog / strona)\n\n- **Jinja2** – składanie dokumentów z danych (facts + routing) do `out/*.md` / `out/*.html`\n    \n- (opcjonalnie) **MkDocs** – szybki lokalny podgląd jako „strona projektu” (może działać offline)\n    \n\n---\n\n## 7) Lokalny LLM do ekstrakcji (opcjonalnie, ale bardzo użyteczne)\n\nJeżeli chcesz wkleić „luźny opis projektu” i dostać ustrukturyzowany plan/IR:\n\n- **Ollama** – lokalny runtime modeli + **Structured Outputs** (wymuszenie JSON Schema na odpowiedzi), co jest kluczowe dla niezawodnej ekstrakcji. ([Ollama Documentation](https://docs.ollama.com/capabilities/structured-outputs?utm_source=chatgpt.com \"Structured Outputs\"))\n    \n\nModele: wybierasz mały model instrukcyjny (3–7B) do ekstrakcji + mały embedding do wyszukiwania; ważniejsze od nazwy jest, żeby dobrze trzymał się schematu (Ollama to ułatwia przez JSON Schema).\n\n---\n\n## 8) Składowanie i indeks (żeby „pamiętało” i dało się debugować)\n\n- **SQLite (FTS5)** – indeks treści i faktów (źródła, proweniencja, wersje)\n    \n- **SQLAlchemy** (opcjonalnie) – jeśli chcesz ORM\n    \n- (opcjonalnie) **Ripgrep** jako szybkie wsparcie diagnostyczne (szukanie w repo)\n    \n\n---\n\n## 9) Pluginy i „maksymalność od startu”\n\nŻebyś nie musiał potem przebudowywać systemu:\n\n- **pluggy** albo entrypoints (`importlib.metadata`) – system pluginów:\n    \n    - `ParserPlugin` (typ dokumentu/pack),\n        \n    - `RulePack` (reguły + słowniki + kody błędów),\n        \n    - `Publisher` (release/devlog/www),\n        \n    - `GraphDecorator` (kolorowanie, etapy, pipeline).\n        \n\nTo jest sposób na „maksymalny zakres”, bez robienia monolitu.\n\n---\n\n## 10) Pakowanie jako aplikacja (ikona, klik, działa)\n\n- **PyInstaller** (spakowanie do binarki)\n    \n- **AppImage** (dystrybucja na Ubuntu jako „normalny program”)\n    \n- `.desktop` + ikona (integracja z menu)\n    \n\n---\n\n# Proponowany „zestaw obowiązkowy” (rdzeń)\n\nJeśli chcesz to składać bez ryzyka, że zabraknie fundamentów:\n\n- PySide6 + QtWebEngine ([Qt Documentation](https://doc.qt.io/qtforpython-6/PySide6/QtWebEngineWidgets/index.html?utm_source=chatgpt.com \"PySide6.QtWebEngineWidgets - Qt for Python\"))\n    \n- Cytoscape.js ([js.cytoscape.org](https://js.cytoscape.org/?utm_source=chatgpt.com \"Cytoscape.js\"))\n    \n- OPA/Rego ([Open Policy Agent](https://openpolicyagent.org/docs?utm_source=chatgpt.com \"Open Policy Agent (OPA)\"))\n    \n- watchdog + frontmatter + yaml + markdown parser\n    \n- networkx + jinja2\n    \n- SQLite jako „ledger/provenance”\n    \n\nA jako „dopalenie”: Ollama Structured Outputs do niezawodnej ekstrakcji z luźnego opisu. ([Ollama Documentation](https://docs.ollama.com/capabilities/structured-outputs?utm_source=chatgpt.com \"Structured Outputs\"))\n\n---\n\nJeśli chcesz, w kolejnym kroku mogę Ci to spiąć w **konkretne moduły ekosystemu** (foldery + interfejsy pluginów + format `facts.json/issues.json/graph.json`), tak żebyś od pierwszego dnia miał „maksymalny” kontrakt i nie wracał do pytania „czemu nie przewidziałem tej funkcji”.","x":8260,"y":340,"width":520,"height":900},
		{"id":"e86744fb8974c62e","type":"text","text":"","x":7955,"y":2067,"width":250,"height":60},
		{"id":"2f26eb7df904919c","type":"text","text":"","x":8040,"y":2067,"width":250,"height":60},
		{"id":"6f411f850792fecd","type":"text","text":"","x":8120,"y":2067,"width":250,"height":60},
		{"id":"e933c1f45a06815e","type":"text","text":"- [ ] Tak — da się to złożyć z gotowych klocków. Poniżej masz **konkretną listę bibliotek / narzędzi / małych modeli**, które możesz pobrać i spiąć w jeden ekosystem: **parser → semantyka/reguły → graf → publikacje → GUI (bez terminala)**.\n\n---\n\n## 1) GUI „program” (bez komend)\n\n**Python + Qt (PySide6) + wbudowany podgląd HTML**\n\n- **PySide6 (Qt for Python)** – framework GUI. ([PyPI](https://pypi.org/project/PySide6/?utm_source=chatgpt.com \"PySide6\"))\n    \n- **QtWebEngine (QWebEngineView)** – żeby w aplikacji mieć dwa panele webowe: _graf_ i _public preview_. ([Qt Documentation](https://doc.qt.io/qtforpython-6/PySide6/QtWebEngineWidgets/index.html?utm_source=chatgpt.com \"PySide6.QtWebEngineWidgets - Qt for Python\"))\n    \n\nTo pozwala mieć jeden EXE/AppImage: startujesz ikoną, a nie terminalem.\n\n---\n\n## 2) Interaktywny graf (frontend)\n\n**Najpraktyczniej: Cytoscape.js w panelu QtWebEngine**\n\n- **Cytoscape.js** – biblioteka do wizualizacji i analizy grafów. ([js.cytoscape.org](https://js.cytoscape.org/?utm_source=chatgpt.com \"Cytoscape.js\"))\n    \n- Format danych: **JSON (Cytoscape.js JSON)** – prosty export/import grafu z backendu. ([manual.cytoscape.org](https://manual.cytoscape.org/en/stable/Cytoscape.js_and_Cytoscape.html?utm_source=chatgpt.com \"25. Cytoscape.js and Cytoscape\"))\n    \n\nBackend generuje `graph.json`, a UI tylko rysuje i koloruje braki/konflikty.\n\n---\n\n## 3) Warstwa „semantyki” i reguł\n\nTu masz dwie ścieżki — obie są sensowne, ale jedna jest „bardziej maksymalna”:\n\n### A) Policy engine (maksymalnie przyszłościowe)\n\n- **Open Policy Agent (OPA) + Rego** – silnik reguł nad danymi strukturalnymi (JSON). Bardzo dobry do Twojego „walidator/bramki/konflikty”. ([Open Policy Agent](https://openpolicyagent.org/docs?utm_source=chatgpt.com \"Open Policy Agent (OPA)\"))\n    \n\nOPA trzyma reguły w plikach `.rego`, a Twój backend odpala OPA lokalnie i odbiera wynik jako JSON.\n\n### B) Reguły w Pythonie (szybciej, mniej „enterprise”)\n\n- **Pydantic** (model danych, walidacja typów)\n    \n- **jsonschema** (kontrakty/schematy)\n    \n- plus własne reguły domenowe (kod)\n    \n\nJeśli chcesz „maksymalnie”, to i tak finalnie wygodniej mieć **OPA jako warstwę polityk** + Python jako „glue”.\n\n---\n\n## 4) Parsowanie dokumentów (Twoje .md + szablony)\n\nŻeby system nie zgadywał „z tekstu”, tylko deterministycznie wyciągał fakty:\n\n- **python-frontmatter** – YAML front-matter w plikach `.md` (ID/type/domain/provides/…)\n    \n- **ruamel.yaml** lub **PyYAML** – YAML (manifesty, słowniki, routing)\n    \n- **markdown-it-py** lub **mistune** – parser Markdown (sekcje, nagłówki, checklisty)\n    \n- **watchdog** – obserwacja zmian plików (auto-rebuild bez ręcznego odpalania)\n    \n\n---\n\n## 5) Analiza grafu i konfliktów zależności\n\n- **networkx** – cykle, topological sort, ścieżki krytyczne, wykrywanie konfliktów strukturalnych (graf).\n    \n- (opcjonalnie) **graphviz/pygraphviz** – jeśli chcesz też generować statyczne diagramy do dokumentacji.\n    \n\n---\n\n## 6) Generowanie „publicznych” wyników (Release Notes / DevLog / strona)\n\n- **Jinja2** – składanie dokumentów z danych (facts + routing) do `out/*.md` / `out/*.html`\n    \n- (opcjonalnie) **MkDocs** – szybki lokalny podgląd jako „strona projektu” (może działać offline)\n    \n\n---\n\n## 7) Lokalny LLM do ekstrakcji (opcjonalnie, ale bardzo użyteczne)\n\nJeżeli chcesz wkleić „luźny opis projektu” i dostać ustrukturyzowany plan/IR:\n\n- **Ollama** – lokalny runtime modeli + **Structured Outputs** (wymuszenie JSON Schema na odpowiedzi), co jest kluczowe dla niezawodnej ekstrakcji. ([Ollama Documentation](https://docs.ollama.com/capabilities/structured-outputs?utm_source=chatgpt.com \"Structured Outputs\"))\n    \n\nModele: wybierasz mały model instrukcyjny (3–7B) do ekstrakcji + mały embedding do wyszukiwania; ważniejsze od nazwy jest, żeby dobrze trzymał się schematu (Ollama to ułatwia przez JSON Schema).\n\n---\n\n## 8) Składowanie i indeks (żeby „pamiętało” i dało się debugować)\n\n- **SQLite (FTS5)** – indeks treści i faktów (źródła, proweniencja, wersje)\n    \n- **SQLAlchemy** (opcjonalnie) – jeśli chcesz ORM\n    \n- (opcjonalnie) **Ripgrep** jako szybkie wsparcie diagnostyczne (szukanie w repo)\n    \n\n---\n\n## 9) Pluginy i „maksymalność od startu”\n\nŻebyś nie musiał potem przebudowywać systemu:\n\n- **pluggy** albo entrypoints (`importlib.metadata`) – system pluginów:\n    \n    - `ParserPlugin` (typ dokumentu/pack),\n        \n    - `RulePack` (reguły + słowniki + kody błędów),\n        \n    - `Publisher` (release/devlog/www),\n        \n    - `GraphDecorator` (kolorowanie, etapy, pipeline).\n        \n\nTo jest sposób na „maksymalny zakres”, bez robienia monolitu.\n\n---\n\n## 10) Pakowanie jako aplikacja (ikona, klik, działa)\n\n- **PyInstaller** (spakowanie do binarki)\n    \n- **AppImage** (dystrybucja na Ubuntu jako „normalny program”)\n    \n- `.desktop` + ikona (integracja z menu)\n    \n\n---\n\n# Proponowany „zestaw obowiązkowy” (rdzeń)\n\nJeśli chcesz to składać bez ryzyka, że zabraknie fundamentów:\n\n- PySide6 + QtWebEngine ([Qt Documentation](https://doc.qt.io/qtforpython-6/PySide6/QtWebEngineWidgets/index.html?utm_source=chatgpt.com \"PySide6.QtWebEngineWidgets - Qt for Python\"))\n    \n- Cytoscape.js ([js.cytoscape.org](https://js.cytoscape.org/?utm_source=chatgpt.com \"Cytoscape.js\"))\n    \n- OPA/Rego ([Open Policy Agent](https://openpolicyagent.org/docs?utm_source=chatgpt.com \"Open Policy Agent (OPA)\"))\n    \n- watchdog + frontmatter + yaml + markdown parser\n    \n- networkx + jinja2\n    \n- SQLite jako „ledger/provenance”\n    \n\nA jako „dopalenie”: Ollama Structured Outputs do niezawodnej ekstrakcji z luźnego opisu. ([Ollama Documentation](https://docs.ollama.com/capabilities/structured-outputs?utm_source=chatgpt.com \"Structured Outputs\"))\n\n---\n\nJeśli chcesz, w kolejnym kroku mogę Ci to spiąć w **konkretne moduły ekosystemu** (foldery + interfejsy pluginów + format `facts.json/issues.json/graph.json`), tak żebyś od pierwszego dnia miał „maksymalny” kontrakt i nie wracał do pytania „czemu nie przewidziałem tej funkcji”.","x":8205,"y":1260,"width":575,"height":807},
		{"id":"ede168a692137e08","type":"text","text":"Poniżej znajduje się uporządkowaną, praktyczną mapę **które dokumenty korzystają z jakich „satelitów”** i **w jakiej kolejności** te artefakty zwyczajowo powstają i są używane (przed-produkcyjne i produkcyjne). Każdy blok zawiera: _lista satelitów_, _kolejność / flow_, _kluczowe checkpointy_ i _gdzie trzymać_. Na końcu jest czytelny ASCII-diagram procesu.\n\n---\n\n# Zasada ogólna\n\nSatelity tworzymy proporcjonalnie do znaczenia dokumentu. Mało-ważny one-pager → mały zestaw (TODO, Approval). Dokument krytyczny/regulacyjny → pełen zestaw (DoR, TODO per sekcja, Evidence, DoD, Approval, ADR, RTM, Test Cases, Runbook).\n\n---\n\n# A. Przedprodukcyjne (Investor / Grant) — kolejność i satelity\n\n## 1. Executive Summary / Pitch Deck\n\n- Satelity: `TODO` (draft), `Evidence item` (key facts), `Approval record`, `Changelog`.\n    \n- Kolejność: TODO → draft ExecSum → attach Evidence → internal Review → Approval → publish/Pitch.\n    \n- Checkpoint: Approval (Sponsor/CFO).\n    \n- Storage: `docs/investor/executive-summary.md`, `docs/investor/evidence/`, `docs/investor/approvals/`.\n    \n\n## 2. Business Case / Feasibility Study\n\n- Satelity: `TODOs per section`, `Evidence items` (arkusze finansowe), `Risk Item` (risk register fragment), `DoR` (ready for review), `DoD` (ready for sign-off), `Approval record`.\n    \n- Kolejność: TODOs → zbiór Evidence/wykresów → draft → DoR (przed formalnym review) → review (tech/finance/legal) → uzupełnienia → DoD → Approval.\n    \n- Checkpointy: DoR przed review; Approval (CFO/Sponsor) kończy etap.\n    \n- Storage: `docs/businesscase/`, `docs/businesscase/evidence/`, `docs/businesscase/todos/`, `approvals/`.\n    \n\n## 3. Funding Application Pack / Grant Submission\n\n- Satelity: `TODO` (załączniki), `Evidence`, `Approval record`, `Change Request` (jeśli wymagane), `Changelog`.\n    \n- Kolejność: prepare attachments → assemble pack → internal sign-off → final Approval/submission.\n    \n- Checkpoint: Compliance/legal sign-off.\n    \n\n---\n\n# B. Produkcyjne / Inżynierskie — kolejność i satelity\n\n## 4. Vision Document / Product Roadmap\n\n- Satelity: `TODO per epic`, `Risk Register`, `Capacity Plan`, `KPI spec`, `Approval record`, linki do `Business Case`/`PRD`.\n    \n- Kolejność: Strategic goals → high-level epics → todos (epic discovery) → capacity & budget → risk register → DoR checks (epic-level) → Approval (CPO/CEO).\n    \n- Checkpointy: Quarterly strategic review; Pre-freeze DoR; Pre-release DoD.\n    \n- Storage: `docs/roadmaps/`, `docs/roadmaps/todos/`, `docs/roadmaps/risk-register.md`.\n    \n\n## 5. PRD (Product Requirements Document)\n\n- Satelity: `Meta front-matter`, `TODO per section`, `DoR (section or doc)`, `RTM fragment`, `Evidence`, `ADR links`, `Review checklist`, `Approval record`, `Change Request` (post-freeze).\n    \n- Kolejność: Outline PRD → create TODOs (sekcja) → zebrać wejścia (UX, Biz, Security) → weryfikacja DoR → draft PRD → tech review (TDD input) → update RTM → DoD (document) → Approval (PO + Tech Lead).\n    \n- Checkpointy: DoR per critical section; PRD DoD before handing to implementation.\n    \n- Storage: `docs/prd/`, `docs/prd/todos/`, `docs/prd/rtm.csv`, `docs/prd/approvals/`.\n    \n\n## 6. TDD / Technical Design Document\n\n- Satelity: `TODO per component`, `ADR` (decyzje architektoniczne), `Test Cases`, `Runbook link`, `DoD`, `Evidence (benchmarks/proofs)`.\n    \n- Kolejność: Input from PRD → TODOs for modules → design draft → ADRs for major choices → DoR (for implementation readiness) → implementation → tests → DoD → merge.\n    \n- Checkpoint: ADR approvals; DoD including tests green.\n    \n- Storage: `docs/tdd/`, `docs/tdd/adr/`, `docs/tdd/tests/`.\n    \n\n## 7. API Documentation / Integration Specs\n\n- Satelity: `API Contract stubs`, `TODO` (example payloads), `Approval`, `Evidence (interop tests)`.\n    \n- Kolejność: Spec sketch → contract stub → interop test → docs publish → consumer sign-off.\n    \n\n## 8. Test Plan / QA Artifacts\n\n- Satelity: `Test Cases`, `RTM fragment`, `Test data evidence`, `Postmortem template` (for failures).\n    \n- Kolejność: PRD → RTM mapping → test case creation → run tests → test summary → sign-off.\n    \n\n## 9. Runbook / Deployment Guide / Release Checklist\n\n- Satelity: `Release checklist (atom + full)`, `DoD` (release-level), `Approval record`, `Postmortem template`.\n    \n- Kolejność: prepare runbook → pre-freeze DoR check → pre-release checks (release checklist) → deploy → postmortem (if incident) → update runbook + changelog.\n    \n- Checkpoint: Pre-release DoD (ops + QA) and go/no-go approval.\n    \n\n---\n\n# C. Compliance / Regulatory / Audits — kolejność i satelity\n\nDokumenty regulacyjne (DPIA, MDR, FDA dossiers) są najsurowsze w wymaganiach satelitarnych.\n\n- Satelity: `Evidence bundles`, `TODO per section`, `Approval records (DPO / Counsel)`, `Audit trail` (commits/PR), `Risk items`, `Change Requests`, `Postmortem` (po testach klinicznych), `DoD` (regulatory sign-off).\n    \n- Kolejność: Template → TODO per required section → collect evidence → internal QA + legal review → external audits → final Approval + submission.\n    \n\n---\n\n# D. Incydenty, Post-release analizy\n\n- Satelity: `Postmortem (atom)`, `Incident Report`, `Action Items (TODOs)`, `Change Requests` (fix → back into PRD/TDD), `Changelog`.\n    \n- Kolejność: Incident detection → Incident Report → RCA → Postmortem → Action TODOs → Implement fixes → Update docs & runbooks → Close.\n    \n\n---\n\n# E. Krótka tabela — szybkie mapowanie (dokument → kluczowe satelity)\n\n```\nExecutive Summary      → TODO, Evidence, Approval\nBusiness Case          → TODO per section, Evidence, RiskItem, DoR, DoD, Approval\nRoadmap                → TODO(epic), CapacityPlan, RiskRegister, KPI spec, Approval\nPRD                    → Meta, TODO per section, DoR, RTM, Evidence, Review checklist, Approval, DoD\nTDD                    → TODO component, ADR, TestCases, Evidence (bench), DoD\nAPI Spec               → Contract stub, TODO (examples), Evidence (interop tests), Approval\nTest Plan / QA         → TestCases, RTM, TestData, TestSummary\nRelease Checklist      → Release checklist atom/full, DoD (release), Approval, Postmortem\nDPIA/Regulatory Dossier→ TODOs, Evidence bundles, Legal/DPO Approval, Audit trail\nPostmortem/Incident    → Incident report, Postmortem atom, Action TODOs, Update runbook\n```\n\n---\n\n# F. Proces i sekwencja w ujęciu chronologicznym (uniwersalny flow)\n\n1. **Discovery / Research**: TODOs per section → Evidence collection → Drafts.\n    \n2. **Readiness**: DoR (section/doc) → confirm inputs are complete.\n    \n3. **Review & Iteration**: reviewers (tech/legal/finance) → ADRs if architecture decisions.\n    \n4. **Completion**: DoD (document-level) → tests / validation / RTM mapping.\n    \n5. **Approval**: formal sign-off (approver(s) zapisane w Approval record).\n    \n6. **Publish / Release**: update changelog, link Evidence, schedule checkpoints.\n    \n7. **Operate / Monitor**: runbooks, KPIs, monitoring plan.\n    \n8. **Closure / Lessons**: postmortem, archive, update templates.\n    \n\n---\n\n# ASCII-diagram (przepływ — przykładowy dla PRD → Release)\n\n```\n[Discovery / Research]\n      |\n   TODOs (per section)\n      |\n   Evidence collected\n      |\n   Draft PRD\n      |\n   DoR (section-level) ?--NO--> fill gaps --> TODOs\n      |\n     YES\n      |\n  Review (Tech / QA / Legal)\n      |\n  ADRs (if needed) --> update TDD\n      |\n  DoD (PRD) ?--NO--> rework\n      |\n     YES\n      |\n  Approval (PO / TechLead)\n      |\n  TDD (design) -> Implementation -> Tests\n      |\n  Release DoD + Release Checklist\n      |\n  Deploy -> Postmortem -> Update docs/runbooks\n```\n\n---\n\n# G. Checkpoints (zalecane punkty kontroli)\n\n- **DoR check** przed formalnym review.\n    \n- **DoD check** przed każdą decyzją „merge/release”.\n    \n- **Approval** przy kluczowych etapach: Business Case, Roadmap final, Release go/no-go, Regulatory submission.\n    \n- **Post-release review** — planowany (np. 1 tydz. po releasie).\n    \n\n---\n\n# H. Przechowywanie i identyfikatory\n\n- Trzymaj satelity obok głównego dokumentu (np. `docs/prd/`, `docs/roadmaps/`) w strukturze zaproponowanej wcześniej.\n    \n- Używaj prefiksów ID (TODO-, ADR-, RISK-, EVID-, APPROVAL-) i front-matter `related` aby łączyć artefakty i łatwo generować manifesty/raporty.\n    \n\n","x":2500,"y":720,"width":660,"height":1206}
	],
	"edges":[
		{"id":"9fcbee0235164b0b","fromNode":"96c48e47a0e54a34","fromSide":"right","toNode":"27486be834123d58","toSide":"bottom"}
	]
}